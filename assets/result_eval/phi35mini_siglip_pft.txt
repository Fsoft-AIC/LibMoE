arning_rate': 1.7582821346551711e-07, 'epoch': 0.81}
{'loss': 1.0939, 'grad_norm': 1.820592276520772, 'learning_rate': 1.7557959162361148e-07, 'epoch': 0.81}
{'loss': 1.1928, 'grad_norm': 2.1530012063842436, 'learning_rate': 1.753311287646745e-07, 'epoch': 0.81}
{'loss': 1.1517, 'grad_norm': 2.171175245984261, 'learning_rate': 1.7508282493661918e-07, 'epoch': 0.81}
{'loss': 1.1152, 'grad_norm': 2.0385637580420233, 'learning_rate': 1.7483468018733017e-07, 'epoch': 0.81}
{'loss': 1.0913, 'grad_norm': 2.100731404771374, 'learning_rate': 1.7458669456465914e-07, 'epoch': 0.81}
{'loss': 1.1211, 'grad_norm': 1.6647490732639882, 'learning_rate': 1.7433886811642916e-07, 'epoch': 0.81}
{'loss': 1.1526, 'grad_norm': 5.4515680398995645, 'learning_rate': 1.740912008904305e-07, 'epoch': 0.82}
{'loss': 1.1531, 'grad_norm': 1.7665281008189584, 'learning_rate': 1.7384369293442501e-07, 'epoch': 0.82}
{'loss': 1.1106, 'grad_norm': 2.049702311376679, 'learning_rate': 1.7359634429614145e-07, 'epoch': 0.82}
{'loss': 1.1777, 'grad_norm': 1.756554324926667, 'learning_rate': 1.7334915502328028e-07, 'epoch': 0.82}
{'loss': 1.1563, 'grad_norm': 2.0222648115868775, 'learning_rate': 1.7310212516350908e-07, 'epoch': 0.82}
{'loss': 1.1155, 'grad_norm': 1.8071799568069142, 'learning_rate': 1.7285525476446594e-07, 'epoch': 0.82}
{'loss': 1.1074, 'grad_norm': 1.936054050606689, 'learning_rate': 1.7260854387375778e-07, 'epoch': 0.82}
{'loss': 1.1403, 'grad_norm': 2.0030644007120753, 'learning_rate': 1.7236199253896089e-07, 'epoch': 0.82}
{'loss': 1.1529, 'grad_norm': 1.7201766545626715, 'learning_rate': 1.7211560080762078e-07, 'epoch': 0.82}
{'loss': 1.1347, 'grad_norm': 51.718628632624046, 'learning_rate': 1.718693687272521e-07, 'epoch': 0.82}
{'loss': 1.1738, 'grad_norm': 2.4203903930414787, 'learning_rate': 1.716232963453389e-07, 'epoch': 0.82}
{'loss': 1.1684, 'grad_norm': 1.8104239389527421, 'learning_rate': 1.7137738370933408e-07, 'epoch': 0.82}
{'loss': 1.143, 'grad_norm': 2.2224602876166952, 'learning_rate': 1.7113163086666016e-07, 'epoch': 0.82}
{'loss': 1.1113, 'grad_norm': 1.9836608399925866, 'learning_rate': 1.7088603786470845e-07, 'epoch': 0.82}
{'loss': 1.1456, 'grad_norm': 1.6854075706738105, 'learning_rate': 1.7064060475083975e-07, 'epoch': 0.82}
{'loss': 1.1212, 'grad_norm': 1.9864872059488075, 'learning_rate': 1.7039533157238394e-07, 'epoch': 0.82}
{'loss': 1.1543, 'grad_norm': 2.093287123920618, 'learning_rate': 1.7015021837663979e-07, 'epoch': 0.82}
{'loss': 1.1493, 'grad_norm': 1.7262584611908651, 'learning_rate': 1.6990526521087567e-07, 'epoch': 0.82}
{'loss': 1.1441, 'grad_norm': 1.8879144108234591, 'learning_rate': 1.696604721223288e-07, 'epoch': 0.82}
{'loss': 1.1693, 'grad_norm': 2.597821540378448, 'learning_rate': 1.6941583915820578e-07, 'epoch': 0.82}
{'loss': 1.1303, 'grad_norm': 1.7248782709541066, 'learning_rate': 1.6917136636568176e-07, 'epoch': 0.82}
{'loss': 1.1104, 'grad_norm': 2.04911282486367, 'learning_rate': 1.6892705379190153e-07, 'epoch': 0.82}
{'loss': 1.1448, 'grad_norm': 2.283551169983214, 'learning_rate': 1.6868290148397878e-07, 'epoch': 0.82}
{'loss': 1.1968, 'grad_norm': 1.783880668493409, 'learning_rate': 1.6843890948899665e-07, 'epoch': 0.82}
{'loss': 1.1751, 'grad_norm': 1.7703987553784006, 'learning_rate': 1.6819507785400677e-07, 'epoch': 0.82}
{'loss': 1.1422, 'grad_norm': 2.045596991399769, 'learning_rate': 1.6795140662603026e-07, 'epoch': 0.82}
{'loss': 1.1217, 'grad_norm': 4.073253909366451, 'learning_rate': 1.6770789585205725e-07, 'epoch': 0.82}
{'loss': 1.0799, 'grad_norm': 1.7245784455541688, 'learning_rate': 1.6746454557904677e-07, 'epoch': 0.82}
{'loss': 1.1514, 'grad_norm': 1.8769690052646233, 'learning_rate': 1.6722135585392706e-07, 'epoch': 0.82}
{'loss': 1.1401, 'grad_norm': 3.7788252483738987, 'learning_rate': 1.6697832672359525e-07, 'epoch': 0.82}
{'loss': 1.1518, 'grad_norm': 5.546029816564097, 'learning_rate': 1.6673545823491774e-07, 'epoch': 0.82}
{'loss': 1.1497, 'grad_norm': 1.8187025774603909, 'learning_rate': 1.6649275043472965e-07, 'epoch': 0.82}
{'loss': 1.1151, 'grad_norm': 1.9830044750255114, 'learning_rate': 1.6625020336983565e-07, 'epoch': 0.82}
{'loss': 1.129, 'grad_norm': 1.8525638849900223, 'learning_rate': 1.6600781708700816e-07, 'epoch': 0.82}
{'loss': 1.1136, 'grad_norm': 1.8841484555084704, 'learning_rate': 1.6576559163299053e-07, 'epoch': 0.82}
{'loss': 1.1292, 'grad_norm': 1.784069724373243, 'learning_rate': 1.6552352705449302e-07, 'epoch': 0.82}
{'loss': 1.1176, 'grad_norm': 1.6716227174543736, 'learning_rate': 1.6528162339819685e-07, 'epoch': 0.82}
{'loss': 1.148, 'grad_norm': 1.8121966815779407, 'learning_rate': 1.6503988071075026e-07, 'epoch': 0.82}
{'loss': 1.1089, 'grad_norm': 2.221999518604163, 'learning_rate': 1.647982990387724e-07, 'epoch': 0.82}
{'loss': 1.1009, 'grad_norm': 2.550427740464439, 'learning_rate': 1.6455687842884936e-07, 'epoch': 0.82}
{'loss': 1.1783, 'grad_norm': 2.1873652901007654, 'learning_rate': 1.643156189275382e-07, 'epoch': 0.82}
{'loss': 1.118, 'grad_norm': 2.5381263144017296, 'learning_rate': 1.6407452058136294e-07, 'epoch': 0.82}
{'loss': 1.1694, 'grad_norm': 2.256516961078957, 'learning_rate': 1.6383358343681852e-07, 'epoch': 0.82}
{'loss': 1.1144, 'grad_norm': 4.176066967279017, 'learning_rate': 1.6359280754036675e-07, 'epoch': 0.82}
{'loss': 1.1245, 'grad_norm': 1.926252084630101, 'learning_rate': 1.6335219293844038e-07, 'epoch': 0.82}
{'loss': 1.1644, 'grad_norm': 3.1212381273929344, 'learning_rate': 1.6311173967743918e-07, 'epoch': 0.82}
{'loss': 1.1374, 'grad_norm': 1.8540948340977716, 'learning_rate': 1.6287144780373308e-07, 'epoch': 0.82}
{'loss': 1.1684, 'grad_norm': 1.6851101218434452, 'learning_rate': 1.6263131736366032e-07, 'epoch': 0.82}
{'loss': 1.1374, 'grad_norm': 1.928024532301526, 'learning_rate': 1.623913484035282e-07, 'epoch': 0.82}
{'loss': 1.1404, 'grad_norm': 2.518696838405431, 'learning_rate': 1.6215154096961292e-07, 'epoch': 0.82}
{'loss': 1.1335, 'grad_norm': 1.6416665728802466, 'learning_rate': 1.619118951081594e-07, 'epoch': 0.82}
{'loss': 1.1407, 'grad_norm': 3.5168326793756184, 'learning_rate': 1.616724108653813e-07, 'epoch': 0.82}
{'loss': 1.1481, 'grad_norm': 1.7733535856956042, 'learning_rate': 1.614330882874616e-07, 'epoch': 0.82}
{'loss': 1.1546, 'grad_norm': 2.5942154613560287, 'learning_rate': 1.611939274205515e-07, 'epoch': 0.82}
{'loss': 1.1482, 'grad_norm': 1.5258857398079777, 'learning_rate': 1.6095492831077128e-07, 'epoch': 0.82}
{'loss': 1.14, 'grad_norm': 1.6828121252431687, 'learning_rate': 1.6071609100421048e-07, 'epoch': 0.82}
{'loss': 1.1851, 'grad_norm': 2.844061740019552, 'learning_rate': 1.6047741554692606e-07, 'epoch': 0.82}
{'loss': 1.1716, 'grad_norm': 1.9973573999778746, 'learning_rate': 1.6023890198494584e-07, 'epoch': 0.82}
{'loss': 1.1529, 'grad_norm': 2.3955521567349014, 'learning_rate': 1.6000055036426407e-07, 'epoch': 0.82}
{'loss': 1.1214, 'grad_norm': 1.7856677209488236, 'learning_rate': 1.5976236073084627e-07, 'epoch': 0.82}
{'loss': 1.163, 'grad_norm': 1.788436033520174, 'learning_rate': 1.595243331306244e-07, 'epoch': 0.82}
{'loss': 1.127, 'grad_norm': 2.189176822650787, 'learning_rate': 1.592864676095006e-07, 'epoch': 0.82}
{'loss': 1.0947, 'grad_norm': 1.9994318811410523, 'learning_rate': 1.5904876421334534e-07, 'epoch': 0.82}
{'loss': 1.1315, 'grad_norm': 1.9247200246605887, 'learning_rate': 1.5881122298799788e-07, 'epoch': 0.82}
 82%|████▉ | 6075/7376 [15:43:08<2:13:37,  6.16s/it]/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Truncated File Read
  warnings.warn(str(msg))
{'loss': 1.1549, 'grad_norm': 1.9052765543144352, 'learning_rate': 1.585738439792661e-07, 'epoch': 0.82}
{'loss': 1.1339, 'grad_norm': 1.6563337887461316, 'learning_rate': 1.5833662723292662e-07, 'epoch': 0.82}
{'loss': 1.1342, 'grad_norm': 2.823195190228193, 'learning_rate': 1.5809957279472496e-07, 'epoch': 0.82}
{'loss': 1.1073, 'grad_norm': 1.7102354095155508, 'learning_rate': 1.578626807103751e-07, 'epoch': 0.82}
{'loss': 1.125, 'grad_norm': 2.5495391768025315, 'learning_rate': 1.5762595102555987e-07, 'epoch': 0.82}
{'loss': 1.1586, 'grad_norm': 3.5430070446187627, 'learning_rate': 1.5738938378593068e-07, 'epoch': 0.82}
{'loss': 1.1466, 'grad_norm': 2.228343572975163, 'learning_rate': 1.5715297903710767e-07, 'epoch': 0.82}
{'loss': 1.1404, 'grad_norm': 3.4764271570159107, 'learning_rate': 1.5691673682467967e-07, 'epoch': 0.82}
{'loss': 1.1659, 'grad_norm': 1.791617057306227, 'learning_rate': 1.5668065719420398e-07, 'epoch': 0.82}
{'loss': 1.1171, 'grad_norm': 2.462481596854804, 'learning_rate': 1.564447401912069e-07, 'epoch': 0.82}
{'loss': 1.1389, 'grad_norm': 1.6535886482000794, 'learning_rate': 1.5620898586118292e-07, 'epoch': 0.83}
{'loss': 1.1584, 'grad_norm': 1.597754275284057, 'learning_rate': 1.5597339424959588e-07, 'epoch': 0.83}
{'loss': 1.1464, 'grad_norm': 2.24486095784946, 'learning_rate': 1.557379654018769e-07, 'epoch': 0.83}
{'loss': 1.1069, 'grad_norm': 3.012549867023175, 'learning_rate': 1.555026993634275e-07, 'epoch': 0.83}
{'loss': 1.1532, 'grad_norm': 3.546965524894584, 'learning_rate': 1.5526759617961614e-07, 'epoch': 0.83}
{'loss': 1.1825, 'grad_norm': 1.9668119412190164, 'learning_rate': 1.5503265589578128e-07, 'epoch': 0.83}
{'loss': 1.0955, 'grad_norm': 3.5823253846420604, 'learning_rate': 1.5479787855722858e-07, 'epoch': 0.83}
{'loss': 1.1429, 'grad_norm': 1.652097801042175, 'learning_rate': 1.5456326420923382e-07, 'epoch': 0.83}
{'loss': 1.1404, 'grad_norm': 2.557641626145817, 'learning_rate': 1.543288128970399e-07, 'epoch': 0.83}
{'loss': 1.1564, 'grad_norm': 4.585339517217566, 'learning_rate': 1.5409452466585903e-07, 'epoch': 0.83}
{'loss': 1.1459, 'grad_norm': 2.7186805923899082, 'learning_rate': 1.5386039956087194e-07, 'epoch': 0.83}
{'loss': 1.1243, 'grad_norm': 1.7006467668961174, 'learning_rate': 1.5362643762722782e-07, 'epoch': 0.83}
{'loss': 1.1512, 'grad_norm': 2.312882498506986, 'learning_rate': 1.5339263891004427e-07, 'epoch': 0.83}
{'loss': 1.1588, 'grad_norm': 1.8667497931485324, 'learning_rate': 1.5315900345440757e-07, 'epoch': 0.83}
{'loss': 1.1159, 'grad_norm': 3.825162637907689, 'learning_rate': 1.5292553130537255e-07, 'epoch': 0.83}
 83%|████▉ | 6100/7376 [15:45:43<2:08:49,  6.06s/it]/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py:1898: UserWarning: Positional arg
s are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed
 explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior,
 you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.1361, 'grad_norm': 7.036385254549954, 'learning_rate': 1.526922225079623e-07, 'epoch': 0.83}
{'loss': 1.1454, 'grad_norm': 1.6016021319882088, 'learning_rate': 1.524590771071691e-07, 'epoch': 0.83}
{'loss': 1.1268, 'grad_norm': 55.14442518972997, 'learning_rate': 1.5222609514795225e-07, 'epoch': 0.83}
{'loss': 1.1502, 'grad_norm': 1.8181787434499816, 'learning_rate': 1.5199327667524154e-07, 'epoch': 0.83}
{'loss': 1.1141, 'grad_norm': 2.1005457148407123, 'learning_rate': 1.5176062173393312e-07, 'epoch': 0.83}
{'loss': 1.1299, 'grad_norm': 2.7403733951543785, 'learning_rate': 1.5152813036889378e-07, 'epoch': 0.83}
{'loss': 1.154, 'grad_norm': 1.7418110256967947, 'learning_rate': 1.5129580262495656e-07, 'epoch': 0.83}
{'loss': 1.1774, 'grad_norm': 1.7094973940662384, 'learning_rate': 1.5106363854692493e-07, 'epoch': 0.83}
{'loss': 1.1386, 'grad_norm': 2.1833724179812135, 'learning_rate': 1.5083163817956913e-07, 'epoch': 0.83}
{'loss': 1.1284, 'grad_norm': 1.7460194040849943, 'learning_rate': 1.5059980156762942e-07, 'epoch': 0.83}
{'loss': 1.1047, 'grad_norm': 1.8819636125016435, 'learning_rate': 1.5036812875581274e-07, 'epoch': 0.83}
{'loss': 1.1581, 'grad_norm': 2.5146816396003016, 'learning_rate': 1.5013661978879632e-07, 'epoch': 0.83}
{'loss': 1.1123, 'grad_norm': 7.9298130654042325, 'learning_rate': 1.4990527471122382e-07, 'epoch': 0.83}
{'loss': 1.1517, 'grad_norm': 1.8444495939073744, 'learning_rate': 1.4967409356770945e-07, 'epoch': 0.83}
{'loss': 1.1478, 'grad_norm': 2.2008811489537643, 'learning_rate': 1.4944307640283382e-07, 'epoch': 0.83}
{'loss': 1.1631, 'grad_norm': 2.0929554685094343, 'learning_rate': 1.4921222326114692e-07, 'epoch': 0.83}
{'loss': 1.1451, 'grad_norm': 1.612947245638032, 'learning_rate': 1.4898153418716708e-07, 'epoch': 0.83}
{'loss': 1.0831, 'grad_norm': 23.973497423755276, 'learning_rate': 1.4875100922538087e-07, 'epoch': 0.83}
{'loss': 1.1585, 'grad_norm': 1.9227649257591497, 'learning_rate': 1.4852064842024325e-07, 'epoch': 0.83}
{'loss': 1.1387, 'grad_norm': 1.5266000085182776, 'learning_rate': 1.4829045181617727e-07, 'epoch': 0.83}
{'loss': 1.1815, 'grad_norm': 1.6998362314526998, 'learning_rate': 1.4806041945757474e-07, 'epoch': 0.83}
{'loss': 1.1863, 'grad_norm': 2.6800215363843742, 'learning_rate': 1.4783055138879562e-07, 'epoch': 0.83}
{'loss': 1.2031, 'grad_norm': 1.9459300852005739, 'learning_rate': 1.476008476541679e-07, 'epoch': 0.83}
{'loss': 1.0931, 'grad_norm': 1.9866932347154056, 'learning_rate': 1.473713082979884e-07, 'epoch': 0.83}
{'loss': 1.132, 'grad_norm': 1.6849300703291292, 'learning_rate': 1.4714193336452174e-07, 'epoch': 0.83}
{'loss': 1.1326, 'grad_norm': 1.8292720288783921, 'learning_rate': 1.4691272289800115e-07, 'epoch': 0.83}
{'loss': 1.1884, 'grad_norm': 2.25395744907266, 'learning_rate': 1.4668367694262817e-07, 'epoch': 0.83}
{'loss': 1.1369, 'grad_norm': 2.029604244188756, 'learning_rate': 1.4645479554257267e-07, 'epoch': 0.83}
{'loss': 1.1287, 'grad_norm': 1.878389820573412, 'learning_rate': 1.4622607874197214e-07, 'epoch': 0.83}
{'loss': 1.1426, 'grad_norm': 2.8003445649669314, 'learning_rate': 1.4599752658493304e-07, 'epoch': 0.83}
{'loss': 1.1518, 'grad_norm': 1.7010976358191896, 'learning_rate': 1.457691391155298e-07, 'epoch': 0.83}
{'loss': 1.1479, 'grad_norm': 1.909828421534506, 'learning_rate': 1.4554091637780518e-07, 'epoch': 0.83}
{'loss': 1.1346, 'grad_norm': 2.1547333502841926, 'learning_rate': 1.4531285841577024e-07, 'epoch': 0.83}
{'loss': 1.0998, 'grad_norm': 1.9837580019262795, 'learning_rate': 1.4508496527340398e-07, 'epoch': 0.83}
{'loss': 1.1406, 'grad_norm': 5.136294717505057, 'learning_rate': 1.448572369946539e-07, 'epoch': 0.83}
{'loss': 1.1232, 'grad_norm': 1.7460552568405727, 'learning_rate': 1.446296736234356e-07, 'epoch': 0.83}
{'loss': 1.172, 'grad_norm': 2.2148559133649597, 'learning_rate': 1.444022752036328e-07, 'epoch': 0.83}
{'loss': 1.1454, 'grad_norm': 2.53446576413332, 'learning_rate': 1.4417504177909767e-07, 'epoch': 0.83}
{'loss': 1.135, 'grad_norm': 3.9987844554049317, 'learning_rate': 1.4394797339365017e-07, 'epoch': 0.83}
{'loss': 1.1564, 'grad_norm': 1.972625723885487, 'learning_rate': 1.437210700910787e-07, 'epoch': 0.83}
{'loss': 1.1611, 'grad_norm': 2.122733007947952, 'learning_rate': 1.4349433191513994e-07, 'epoch': 0.83}
{'loss': 1.1351, 'grad_norm': 1.9971858053620677, 'learning_rate': 1.4326775890955833e-07, 'epoch': 0.83}
{'loss': 1.166, 'grad_norm': 6.089973971366798, 'learning_rate': 1.4304135111802707e-07, 'epoch': 0.83}
{'loss': 1.1446, 'grad_norm': 3.457609475177327, 'learning_rate': 1.4281510858420632e-07, 'epoch': 0.83}
{'loss': 1.1503, 'grad_norm': 2.0932428576147726, 'learning_rate': 1.4258903135172605e-07, 'epoch': 0.83}
{'loss': 1.108, 'grad_norm': 2.071554228554578, 'learning_rate': 1.423631194641828e-07, 'epoch': 0.83}
{'loss': 1.1289, 'grad_norm': 3.7023352242125616, 'learning_rate': 1.421373729651425e-07, 'epoch': 0.83}
{'loss': 1.1087, 'grad_norm': 2.1392109627535776, 'learning_rate': 1.4191179189813796e-07, 'epoch': 0.83}
{'loss': 1.1625, 'grad_norm': 1.6700341731963986, 'learning_rate': 1.4168637630667135e-07, 'epoch': 0.83}
{'loss': 1.1543, 'grad_norm': 1.9604248646891644, 'learning_rate': 1.4146112623421158e-07, 'epoch': 0.83}
{'loss': 1.1198, 'grad_norm': 2.016027814389016, 'learning_rate': 1.4123604172419713e-07, 'epoch': 0.83}
{'loss': 1.1928, 'grad_norm': 2.399138932032356, 'learning_rate': 1.410111228200329e-07, 'epoch': 0.83}
{'loss': 1.1546, 'grad_norm': 2.17538328360098, 'learning_rate': 1.407863695650936e-07, 'epoch': 0.83}
{'loss': 1.1132, 'grad_norm': 1.8231408416218464, 'learning_rate': 1.405617820027204e-07, 'epoch': 0.83}
{'loss': 1.1744, 'grad_norm': 1.776430077512962, 'learning_rate': 1.4033736017622388e-07, 'epoch': 0.83}
{'loss': 1.165, 'grad_norm': 2.294046528556166, 'learning_rate': 1.4011310412888145e-07, 'epoch': 0.83}
{'loss': 1.1356, 'grad_norm': 2.374447136355484, 'learning_rate': 1.398890139039395e-07, 'epoch': 0.83}
{'loss': 1.1118, 'grad_norm': 1.9195651438970642, 'learning_rate': 1.3966508954461175e-07, 'epoch': 0.83}
{'loss': 1.1786, 'grad_norm': 2.003832326939662, 'learning_rate': 1.3944133109408053e-07, 'epoch': 0.83}
{'loss': 1.1404, 'grad_norm': 1.6108131389314297, 'learning_rate': 1.3921773859549569e-07, 'epoch': 0.84}
{'loss': 1.1673, 'grad_norm': 2.768327377829161, 'learning_rate': 1.389943120919753e-07, 'epoch': 0.84}
{'loss': 1.1255, 'grad_norm': 1.9264720435847351, 'learning_rate': 1.3877105162660564e-07, 'epoch': 0.84}
{'loss': 1.1161, 'grad_norm': 1.8747249517378752, 'learning_rate': 1.385479572424404e-07, 'epoch': 0.84}
{'loss': 1.1448, 'grad_norm': 2.3312562554435807, 'learning_rate': 1.3832502898250174e-07, 'epoch': 0.84}
{'loss': 1.1255, 'grad_norm': 2.5410139331907144, 'learning_rate': 1.3810226688977967e-07, 'epoch': 0.84}
{'loss': 1.1536, 'grad_norm': 1.844911724198829, 'learning_rate': 1.378796710072322e-07, 'epoch': 0.84}
{'loss': 1.1477, 'grad_norm': 1.7105364764686601, 'learning_rate': 1.3765724137778456e-07, 'epoch': 0.84}
{'loss': 1.1286, 'grad_norm': 2.3831999284176346, 'learning_rate': 1.3743497804433147e-07, 'epoch': 0.84}
{'loss': 1.1173, 'grad_norm': 1.6467922800711072, 'learning_rate': 1.3721288104973372e-07, 'epoch': 0.84}
{'loss': 1.1048, 'grad_norm': 10.496316065750152, 'learning_rate': 1.3699095043682184e-07, 'epoch': 0.84}
{'loss': 1.1588, 'grad_norm': 2.338743002300305, 'learning_rate': 1.3676918624839285e-07, 'epoch': 0.84}
{'loss': 1.1331, 'grad_norm': 1.7692540646604378, 'learning_rate': 1.3654758852721226e-07, 'epoch': 0.84}
{'loss': 1.1902, 'grad_norm': 1.6564506813316853, 'learning_rate': 1.363261573160136e-07, 'epoch': 0.84}
{'loss': 1.1514, 'grad_norm': 2.0687148250341387, 'learning_rate': 1.3610489265749801e-07, 'epoch': 0.84}
{'loss': 1.0788, 'grad_norm': 2.1194442293471063, 'learning_rate': 1.3588379459433485e-07, 'epoch': 0.84}
{'loss': 1.1458, 'grad_norm': 1.7875892741930335, 'learning_rate': 1.3566286316916087e-07, 'epoch': 0.84}
{'loss': 1.1614, 'grad_norm': 1.8035058338594765, 'learning_rate': 1.354420984245811e-07, 'epoch': 0.84}
{'loss': 1.149, 'grad_norm': 2.081858152379622, 'learning_rate': 1.3522150040316826e-07, 'epoch': 0.84}
{'loss': 1.1532, 'grad_norm': 2.2553898787920152, 'learning_rate': 1.350010691474629e-07, 'epoch': 0.84}
{'loss': 1.1683, 'grad_norm': 4.309213830017875, 'learning_rate': 1.3478080469997344e-07, 'epoch': 0.84}
{'loss': 1.1085, 'grad_norm': 1.7628074977607113, 'learning_rate': 1.3456070710317624e-07, 'epoch': 0.84}
{'loss': 1.1382, 'grad_norm': 1.6309525270441465, 'learning_rate': 1.3434077639951525e-07, 'epoch': 0.84}
{'loss': 1.1213, 'grad_norm': 1.6243596164293685, 'learning_rate': 1.341210126314024e-07, 'epoch': 0.84}
{'loss': 1.1367, 'grad_norm': 2.0987998316526473, 'learning_rate': 1.3390141584121772e-07, 'epoch': 0.84}
{'loss': 1.1509, 'grad_norm': 1.7506629178437227, 'learning_rate': 1.33681986071308e-07, 'epoch': 0.84}
{'loss': 1.1464, 'grad_norm': 3.6417171689602776, 'learning_rate': 1.3346272336398934e-07, 'epoch': 0.84}
{'loss': 1.1548, 'grad_norm': 1.636173304363034, 'learning_rate': 1.3324362776154408e-07, 'epoch': 0.84}
{'loss': 1.1797, 'grad_norm': 1.9237282314220687, 'learning_rate': 1.3302469930622383e-07, 'epoch': 0.84}
{'loss': 1.1396, 'grad_norm': 1.9168146282021248, 'learning_rate': 1.3280593804024642e-07, 'epoch': 0.84}
{'loss': 1.1274, 'grad_norm': 1.67343170281057, 'learning_rate': 1.3258734400579908e-07, 'epoch': 0.84}
{'loss': 1.1422, 'grad_norm': 2.025271275610353, 'learning_rate': 1.323689172450353e-07, 'epoch': 0.84}
{'loss': 1.1118, 'grad_norm': 1.4915206182539487, 'learning_rate': 1.3215065780007718e-07, 'epoch': 0.84}
{'loss': 1.1433, 'grad_norm': 1.9585818009460247, 'learning_rate': 1.3193256571301426e-07, 'epoch': 0.84}
{'loss': 1.0962, 'grad_norm': 1.9629476490182411, 'learning_rate': 1.3171464102590392e-07, 'epoch': 0.84}
{'loss': 1.1607, 'grad_norm': 2.4124374211889523, 'learning_rate': 1.3149688378077128e-07, 'epoch': 0.84}
{'loss': 1.1276, 'grad_norm': 2.6241956664176955, 'learning_rate': 1.3127929401960903e-07, 'epoch': 0.84}
{'loss': 1.1432, 'grad_norm': 1.5021203655214086, 'learning_rate': 1.3106187178437768e-07, 'epoch': 0.84}
{'loss': 1.1046, 'grad_norm': 1.6566756350672727, 'learning_rate': 1.3084461711700544e-07, 'epoch': 0.84}
{'loss': 1.143, 'grad_norm': 2.3153535380501373, 'learning_rate': 1.3062753005938798e-07, 'epoch': 0.84}
{'loss': 1.1583, 'grad_norm': 1.6599349763275335, 'learning_rate': 1.30410610653389e-07, 'epoch': 0.84}
 84%|█████ | 6200/7376 [16:00:06<2:00:39,  6.16s/it]/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py:1898: UserWarning: Positional arg
s are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed
 explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior,
 you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.1305, 'grad_norm': 1.9166325458696363, 'learning_rate': 1.3019385894083988e-07, 'epoch': 0.84}
{'loss': 1.1736, 'grad_norm': 1.6633963678381962, 'learning_rate': 1.2997727496353872e-07, 'epoch': 0.84}
{'loss': 1.1569, 'grad_norm': 2.607575820191517, 'learning_rate': 1.2976085876325303e-07, 'epoch': 0.84}
{'loss': 1.1104, 'grad_norm': 3.2360198165673113, 'learning_rate': 1.2954461038171603e-07, 'epoch': 0.84}
{'loss': 1.1755, 'grad_norm': 1.9246017767133297, 'learning_rate': 1.2932852986063046e-07, 'epoch': 0.84}
{'loss': 1.1383, 'grad_norm': 1.716797187428448, 'learning_rate': 1.2911261724166468e-07, 'epoch': 0.84}
{'loss': 1.1445, 'grad_norm': 2.864184995885761, 'learning_rate': 1.2889687256645686e-07, 'epoch': 0.84}
{'loss': 1.1155, 'grad_norm': 3.093442027127321, 'learning_rate': 1.286812958766106e-07, 'epoch': 0.84}
{'loss': 1.147, 'grad_norm': 2.0392169332095618, 'learning_rate': 1.284658872136991e-07, 'epoch': 0.84}
{'loss': 1.1595, 'grad_norm': 1.6062276515899507, 'learning_rate': 1.2825064661926133e-07, 'epoch': 0.84}
{'loss': 1.1861, 'grad_norm': 1.6861428657726025, 'learning_rate': 1.280355741348056e-07, 'epoch': 0.84}
{'loss': 1.1357, 'grad_norm': 1.6846780519654054, 'learning_rate': 1.278206698018064e-07, 'epoch': 0.84}
{'loss': 1.1336, 'grad_norm': 1.743740200499029, 'learning_rate': 1.2760593366170635e-07, 'epoch': 0.84}
{'loss': 1.1494, 'grad_norm': 1.8912290854118503, 'learning_rate': 1.273913657559158e-07, 'epoch': 0.84}
{'loss': 1.1686, 'grad_norm': 2.3337319659019102, 'learning_rate': 1.271769661258124e-07, 'epoch': 0.84}
{'loss': 1.142, 'grad_norm': 1.7632729363307744, 'learning_rate': 1.2696273481274144e-07, 'epoch': 0.84}
{'loss': 1.1837, 'grad_norm': 2.088141667583963, 'learning_rate': 1.2674867185801575e-07, 'epoch': 0.84}
{'loss': 1.126, 'grad_norm': 1.6474351094924657, 'learning_rate': 1.2653477730291563e-07, 'epoch': 0.84}
{'loss': 1.1766, 'grad_norm': 1.7982241845003253, 'learning_rate': 1.2632105118868896e-07, 'epoch': 0.84}
{'loss': 1.1539, 'grad_norm': 2.365699074760233, 'learning_rate': 1.2610749355655125e-07, 'epoch': 0.84}
{'loss': 1.1353, 'grad_norm': 4.195938116858856, 'learning_rate': 1.2589410444768522e-07, 'epoch': 0.84}
{'loss': 1.1411, 'grad_norm': 1.877749487346024, 'learning_rate': 1.256808839032415e-07, 'epoch': 0.84}
{'loss': 1.0877, 'grad_norm': 1.8267664270524033, 'learning_rate': 1.2546783196433774e-07, 'epoch': 0.84}
{'loss': 1.1877, 'grad_norm': 1.802383286009516, 'learning_rate': 1.2525494867205954e-07, 'epoch': 0.84}
{'loss': 1.1307, 'grad_norm': 4.068952578278857, 'learning_rate': 1.2504223406745963e-07, 'epoch': 0.84}
{'loss': 1.103, 'grad_norm': 1.9550243432563266, 'learning_rate': 1.2482968819155837e-07, 'epoch': 0.84}
{'loss': 1.1494, 'grad_norm': 1.7130013927037244, 'learning_rate': 1.2461731108534378e-07, 'epoch': 0.84}
{'loss': 1.1479, 'grad_norm': 2.3555883849550168, 'learning_rate': 1.244051027897708e-07, 'epoch': 0.84}
{'loss': 1.0942, 'grad_norm': 2.460791312406269, 'learning_rate': 1.2419306334576207e-07, 'epoch': 0.84}
{'loss': 1.1281, 'grad_norm': 1.6411719151098434, 'learning_rate': 1.2398119279420793e-07, 'epoch': 0.84}
{'loss': 1.1317, 'grad_norm': 1.7553068398578118, 'learning_rate': 1.2376949117596592e-07, 'epoch': 0.84}
{'loss': 1.1214, 'grad_norm': 1.8967769429055443, 'learning_rate': 1.2355795853186102e-07, 'epoch': 0.84}
{'loss': 1.1358, 'grad_norm': 2.144477964702437, 'learning_rate': 1.233465949026855e-07, 'epoch': 0.84}
{'loss': 1.1044, 'grad_norm': 1.8355420567476093, 'learning_rate': 1.2313540032919935e-07, 'epoch': 0.85}
{'loss': 1.2039, 'grad_norm': 1.7272711615340095, 'learning_rate': 1.2292437485212957e-07, 'epoch': 0.85}
{'loss': 1.1099, 'grad_norm': 1.6324798893020813, 'learning_rate': 1.2271351851217104e-07, 'epoch': 0.85}
{'loss': 1.1449, 'grad_norm': 3.023192974658072, 'learning_rate': 1.225028313499855e-07, 'epoch': 0.85}
{'loss': 1.1208, 'grad_norm': 4.282335992834041, 'learning_rate': 1.222923134062025e-07, 'epoch': 0.85}
{'loss': 1.1506, 'grad_norm': 3.1160075754179966, 'learning_rate': 1.220819647214185e-07, 'epoch': 0.85}
{'loss': 1.128, 'grad_norm': 1.5753553238684093, 'learning_rate': 1.2187178533619803e-07, 'epoch': 0.85}
{'loss': 1.1341, 'grad_norm': 2.289807052059847, 'learning_rate': 1.216617752910718e-07, 'epoch': 0.85}
{'loss': 1.1077, 'grad_norm': 1.7694217357869495, 'learning_rate': 1.2145193462653946e-07, 'epoch': 0.85}
{'loss': 1.1969, 'grad_norm': 1.9776776881471474, 'learning_rate': 1.212422633830663e-07, 'epoch': 0.85}
{'loss': 1.1599, 'grad_norm': 2.534932827207732, 'learning_rate': 1.2103276160108656e-07, 'epoch': 0.85}
{'loss': 1.1286, 'grad_norm': 4.995341728113508, 'learning_rate': 1.208234293210002e-07, 'epoch': 0.85}
{'loss': 1.1273, 'grad_norm': 1.8276705357367817, 'learning_rate': 1.2061426658317608e-07, 'epoch': 0.85}
{'loss': 1.1281, 'grad_norm': 1.811284831556266, 'learning_rate': 1.2040527342794872e-07, 'epoch': 0.85}
{'loss': 1.1427, 'grad_norm': 2.54231508998573, 'learning_rate': 1.2019644989562184e-07, 'epoch': 0.85}
{'loss': 1.1821, 'grad_norm': 1.9463337420541957, 'learning_rate': 1.1998779602646436e-07, 'epoch': 0.85}
{'loss': 1.0817, 'grad_norm': 1.6794637788667484, 'learning_rate': 1.1977931186071443e-07, 'epoch': 0.85}
{'loss': 1.1457, 'grad_norm': 1.8466439812740438, 'learning_rate': 1.1957099743857568e-07, 'epoch': 0.85}
{'loss': 1.1358, 'grad_norm': 1.8800809019961422, 'learning_rate': 1.1936285280022096e-07, 'epoch': 0.85}
{'loss': 1.1098, 'grad_norm': 2.2170847834003933, 'learning_rate': 1.1915487798578816e-07, 'epoch': 0.85}
{'loss': 1.1306, 'grad_norm': 3.280509684696955, 'learning_rate': 1.1894707303538476e-07, 'epoch': 0.85}
{'loss': 1.1442, 'grad_norm': 1.7824527666797443, 'learning_rate': 1.1873943798908336e-07, 'epoch': 0.85}
{'loss': 1.1653, 'grad_norm': 1.7442174274908473, 'learning_rate': 1.1853197288692518e-07, 'epoch': 0.85}
{'loss': 1.1089, 'grad_norm': 1.924292691387795, 'learning_rate': 1.183246777689182e-07, 'epoch': 0.85}
{'loss': 1.1497, 'grad_norm': 1.81597626989229, 'learning_rate': 1.1811755267503754e-07, 'epoch': 0.85}
{'loss': 1.1328, 'grad_norm': 2.007521843432338, 'learning_rate': 1.179105976452256e-07, 'epoch': 0.85}
{'loss': 1.1753, 'grad_norm': 1.8304030237452635, 'learning_rate': 1.1770381271939223e-07, 'epoch': 0.85}
{'loss': 1.1413, 'grad_norm': 1.7172665924291515, 'learning_rate': 1.1749719793741409e-07, 'epoch': 0.85}
{'loss': 1.1552, 'grad_norm': 2.1483760249566317, 'learning_rate': 1.172907533391353e-07, 'epoch': 0.85}
{'loss': 1.1047, 'grad_norm': 1.7193014925753212, 'learning_rate': 1.1708447896436724e-07, 'epoch': 0.85}
{'loss': 1.1174, 'grad_norm': 2.7699525433586523, 'learning_rate': 1.1687837485288766e-07, 'epoch': 0.85}
{'loss': 1.0927, 'grad_norm': 1.9332145308831243, 'learning_rate': 1.1667244104444308e-07, 'epoch': 0.85}
{'loss': 1.1011, 'grad_norm': 1.647036772190935, 'learning_rate': 1.1646667757874507e-07, 'epoch': 0.85}
{'loss': 1.1168, 'grad_norm': 1.7528032300548524, 'learning_rate': 1.1626108449547467e-07, 'epoch': 0.85}
{'loss': 1.1286, 'grad_norm': 1.957486194983612, 'learning_rate': 1.1605566183427807e-07, 'epoch': 0.85}
{'loss': 1.147, 'grad_norm': 2.4733106506595437, 'learning_rate': 1.1585040963476966e-07, 'epoch': 0.85}
{'loss': 1.1144, 'grad_norm': 2.9880726919665155, 'learning_rate': 1.156453279365307e-07, 'epoch': 0.85}
{'loss': 1.1006, 'grad_norm': 2.8721022861076206, 'learning_rate': 1.1544041677910954e-07, 'epoch': 0.85}
{'loss': 1.1624, 'grad_norm': 2.4463221359861826, 'learning_rate': 1.152356762020218e-07, 'epoch': 0.85}
{'loss': 1.1151, 'grad_norm': 1.7957745083622927, 'learning_rate': 1.1503110624474987e-07, 'epoch': 0.85}
{'loss': 1.1564, 'grad_norm': 1.7473221307725135, 'learning_rate': 1.1482670694674367e-07, 'epoch': 0.85}
{'loss': 1.0949, 'grad_norm': 2.0223542782033386, 'learning_rate': 1.146224783474199e-07, 'epoch': 0.85}
{'loss': 1.1524, 'grad_norm': 9.295657123096404, 'learning_rate': 1.1441842048616234e-07, 'epoch': 0.85}
{'loss': 1.1263, 'grad_norm': 2.0500926154890906, 'learning_rate': 1.1421453340232213e-07, 'epoch': 0.85}
{'loss': 1.118, 'grad_norm': 1.8187127558349458, 'learning_rate': 1.140108171352172e-07, 'epoch': 0.85}
{'loss': 1.1418, 'grad_norm': 2.238536675242392, 'learning_rate': 1.1380727172413262e-07, 'epoch': 0.85}
{'loss': 1.1475, 'grad_norm': 2.2348043381765277, 'learning_rate': 1.1360389720832042e-07, 'epoch': 0.85}
{'loss': 1.1528, 'grad_norm': 1.9298726357112934, 'learning_rate': 1.1340069362699988e-07, 'epoch': 0.85}
{'loss': 1.1492, 'grad_norm': 1.8854441908525683, 'learning_rate': 1.1319766101935724e-07, 'epoch': 0.85}
{'loss': 1.1168, 'grad_norm': 1.6817516953479215, 'learning_rate': 1.1299479942454592e-07, 'epoch': 0.85}
{'loss': 1.1305, 'grad_norm': 1.8212405147903672, 'learning_rate': 1.1279210888168544e-07, 'epoch': 0.85}
{'loss': 1.1358, 'grad_norm': 1.727949354927743, 'learning_rate': 1.1258958942986396e-07, 'epoch': 0.85}
{'loss': 1.1767, 'grad_norm': 1.9127178930728703, 'learning_rate': 1.1238724110813502e-07, 'epoch': 0.85}
{'loss': 1.1135, 'grad_norm': 2.6842924085343918, 'learning_rate': 1.1218506395552063e-07, 'epoch': 0.85}
{'loss': 1.1534, 'grad_norm': 2.039211911978617, 'learning_rate': 1.1198305801100827e-07, 'epoch': 0.85}
{'loss': 1.1736, 'grad_norm': 2.1701933733010947, 'learning_rate': 1.11781223313554e-07, 'epoch': 0.85}
{'loss': 1.0909, 'grad_norm': 2.1080493759409813, 'learning_rate': 1.1157955990207946e-07, 'epoch': 0.85}
{'loss': 1.1561, 'grad_norm': 2.6112140410293088, 'learning_rate': 1.1137806781547398e-07, 'epoch': 0.85}
{'loss': 1.1296, 'grad_norm': 2.267228609350358, 'learning_rate': 1.1117674709259372e-07, 'epoch': 0.85}
{'loss': 1.1183, 'grad_norm': 1.8999624451348438, 'learning_rate': 1.1097559777226196e-07, 'epoch': 0.85}
{'loss': 1.1585, 'grad_norm': 1.640576529805139, 'learning_rate': 1.1077461989326864e-07, 'epoch': 0.85}
{'loss': 1.1049, 'grad_norm': 1.642720406356296, 'learning_rate': 1.1057381349437067e-07, 'epoch': 0.85}
{'loss': 1.1498, 'grad_norm': 2.2010855297926746, 'learning_rate': 1.1037317861429208e-07, 'epoch': 0.85}
{'loss': 1.1334, 'grad_norm': 2.0168801242217196, 'learning_rate': 1.1017271529172367e-07, 'epoch': 0.85}
{'loss': 1.1516, 'grad_norm': 2.1637484138289356, 'learning_rate': 1.0997242356532333e-07, 'epoch': 0.85}
{'loss': 1.097, 'grad_norm': 1.6137270292324335, 'learning_rate': 1.0977230347371568e-07, 'epoch': 0.85}
{'loss': 1.1388, 'grad_norm': 1.6439147865503327, 'learning_rate': 1.0957235505549233e-07, 'epoch': 0.85}
 85%|█████ | 6300/7376 [16:15:44<1:54:57,  6.41s/it]/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py:1898: UserWarning: Positional arg
s are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed
 explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior,
 you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.1149, 'grad_norm': 1.7597881373201079, 'learning_rate': 1.0937257834921144e-07, 'epoch': 0.85}
{'loss': 1.1229, 'grad_norm': 1.5859697004669802, 'learning_rate': 1.0917297339339892e-07, 'epoch': 0.85}
{'loss': 1.123, 'grad_norm': 2.5979185706241896, 'learning_rate': 1.0897354022654648e-07, 'epoch': 0.85}
{'loss': 1.1139, 'grad_norm': 2.6648498066555324, 'learning_rate': 1.0877427888711377e-07, 'epoch': 0.85}
{'loss': 1.1648, 'grad_norm': 2.3485306609717003, 'learning_rate': 1.0857518941352605e-07, 'epoch': 0.85}
{'loss': 1.1471, 'grad_norm': 2.6491525351427367, 'learning_rate': 1.0837627184417697e-07, 'epoch': 0.85}
{'loss': 1.1234, 'grad_norm': 2.2598024614994814, 'learning_rate': 1.0817752621742537e-07, 'epoch': 0.86}
{'loss': 1.1766, 'grad_norm': 1.9493624329649903, 'learning_rate': 1.0797895257159872e-07, 'epoch': 0.86}
{'loss': 1.1925, 'grad_norm': 1.652976806590768, 'learning_rate': 1.077805509449895e-07, 'epoch': 0.86}
{'loss': 1.118, 'grad_norm': 1.7262496867383395, 'learning_rate': 1.0758232137585854e-07, 'epoch': 0.86}
{'loss': 1.1337, 'grad_norm': 2.182745860881029, 'learning_rate': 1.073842639024325e-07, 'epoch': 0.86}
{'loss': 1.1459, 'grad_norm': 1.9387103730788804, 'learning_rate': 1.0718637856290525e-07, 'epoch': 0.86}
{'loss': 1.184, 'grad_norm': 2.228608204112476, 'learning_rate': 1.069886653954375e-07, 'epoch': 0.86}
{'loss': 1.138, 'grad_norm': 2.034130003046483, 'learning_rate': 1.0679112443815652e-07, 'epoch': 0.86}
{'loss': 1.1446, 'grad_norm': 2.1237943233107, 'learning_rate': 1.0659375572915674e-07, 'epoch': 0.86}
{'loss': 1.0907, 'grad_norm': 1.8950296626129737, 'learning_rate': 1.0639655930649894e-07, 'epoch': 0.86}
{'loss': 1.1776, 'grad_norm': 2.7916809527373916, 'learning_rate': 1.0619953520821112e-07, 'epoch': 0.86}
{'loss': 1.1694, 'grad_norm': 5.287518816389908, 'learning_rate': 1.0600268347228757e-07, 'epoch': 0.86}
{'loss': 1.1423, 'grad_norm': 1.6729945935898913, 'learning_rate': 1.0580600413668983e-07, 'epoch': 0.86}
{'loss': 1.183, 'grad_norm': 2.770426669090396, 'learning_rate': 1.0560949723934587e-07, 'epoch': 0.86}
{'loss': 1.1713, 'grad_norm': 1.7512747480072508, 'learning_rate': 1.0541316281815038e-07, 'epoch': 0.86}
{'loss': 1.1351, 'grad_norm': 1.7871830063210152, 'learning_rate': 1.0521700091096508e-07, 'epoch': 0.86}
{'loss': 1.1439, 'grad_norm': 1.7631729800111149, 'learning_rate': 1.0502101155561816e-07, 'epoch': 0.86}
{'loss': 1.1473, 'grad_norm': 1.8119621020388827, 'learning_rate': 1.0482519478990481e-07, 'epoch': 0.86}
{'loss': 1.1236, 'grad_norm': 2.334020157749086, 'learning_rate': 1.0462955065158618e-07, 'epoch': 0.86}
{'loss': 1.1209, 'grad_norm': 1.8947347085363038, 'learning_rate': 1.0443407917839141e-07, 'epoch': 0.86}
{'loss': 1.1301, 'grad_norm': 1.7131857980766547, 'learning_rate': 1.0423878040801514e-07, 'epoch': 0.86}
{'loss': 1.109, 'grad_norm': 1.8981221249679556, 'learning_rate': 1.0404365437811946e-07, 'epoch': 0.86}
{'loss': 1.0993, 'grad_norm': 1.908887112063313, 'learning_rate': 1.0384870112633271e-07, 'epoch': 0.86}
{'loss': 1.1399, 'grad_norm': 1.9356801337366973, 'learning_rate': 1.0365392069025014e-07, 'epoch': 0.86}
{'loss': 1.1224, 'grad_norm': 1.5456649197934267, 'learning_rate': 1.034593131074336e-07, 'epoch': 0.86}
{'loss': 1.1489, 'grad_norm': 1.671843529343042, 'learning_rate': 1.0326487841541176e-07, 'epoch': 0.86}
{'loss': 1.1337, 'grad_norm': 1.979078078300221, 'learning_rate': 1.030706166516796e-07, 'epoch': 0.86}
{'loss': 1.1924, 'grad_norm': 2.3494944416391523, 'learning_rate': 1.0287652785369916e-07, 'epoch': 0.86}
{'loss': 1.0903, 'grad_norm': 2.5432337749061253, 'learning_rate': 1.0268261205889894e-07, 'epoch': 0.86}
{'loss': 1.1013, 'grad_norm': 5.047328447886946, 'learning_rate': 1.0248886930467393e-07, 'epoch': 0.86}
{'loss': 1.1262, 'grad_norm': 1.9769971433693727, 'learning_rate': 1.022952996283859e-07, 'epoch': 0.86}
{'loss': 1.123, 'grad_norm': 12.156495624158573, 'learning_rate': 1.0210190306736333e-07, 'epoch': 0.86}
{'loss': 1.124, 'grad_norm': 1.7220724770437112, 'learning_rate': 1.0190867965890137e-07, 'epoch': 0.86}
{'loss': 1.1365, 'grad_norm': 1.4939919567755284, 'learning_rate': 1.0171562944026102e-07, 'epoch': 0.86}
{'loss': 1.1684, 'grad_norm': 2.563604328399515, 'learning_rate': 1.0152275244867137e-07, 'epoch': 0.86}
{'loss': 1.1471, 'grad_norm': 1.9506413264923679, 'learning_rate': 1.0133004872132623e-07, 'epoch': 0.86}
{'loss': 1.1647, 'grad_norm': 1.7410399188833907, 'learning_rate': 1.0113751829538808e-07, 'epoch': 0.86}
{'loss': 1.1061, 'grad_norm': 2.562891671835255, 'learning_rate': 1.009451612079838e-07, 'epoch': 0.86}
{'loss': 1.1389, 'grad_norm': 2.4672548432147985, 'learning_rate': 1.0075297749620904e-07, 'epoch': 0.86}
{'loss': 1.1167, 'grad_norm': 1.6836298840475836, 'learning_rate': 1.0056096719712382e-07, 'epoch': 0.86}
{'loss': 1.1301, 'grad_norm': 1.9656701517726958, 'learning_rate': 1.0036913034775673e-07, 'epoch': 0.86}
{'loss': 1.1567, 'grad_norm': 3.1893518778136367, 'learning_rate': 1.0017746698510122e-07, 'epoch': 0.86}
{'loss': 1.1473, 'grad_norm': 1.925427382965406, 'learning_rate': 9.998597714611889e-08, 'epoch': 0.86}
{'loss': 1.1483, 'grad_norm': 1.7141553342379825, 'learning_rate': 9.979466086773614e-08, 'epoch': 0.86}
{'loss': 1.0986, 'grad_norm': 1.7563413633965042, 'learning_rate': 9.960351818684764e-08, 'epoch': 0.86}
{'loss': 1.1517, 'grad_norm': 3.7580000847532107, 'learning_rate': 9.941254914031316e-08, 'epoch': 0.86}
{'loss': 1.112, 'grad_norm': 1.6457730348851856, 'learning_rate': 9.922175376495979e-08, 'epoch': 0.86}
{'loss': 1.1715, 'grad_norm': 1.7960243856879712, 'learning_rate': 9.903113209758096e-08, 'epoch': 0.86}
{'loss': 1.1403, 'grad_norm': 2.161177162574391, 'learning_rate': 9.88406841749364e-08, 'epoch': 0.86}
{'loss': 1.1454, 'grad_norm': 2.477857675136244, 'learning_rate': 9.865041003375263e-08, 'epoch': 0.86}
{'loss': 1.1434, 'grad_norm': 2.5247939801819057, 'learning_rate': 9.846030971072239e-08, 'epoch': 0.86}
{'loss': 1.1194, 'grad_norm': 1.9442886068815097, 'learning_rate': 9.827038324250514e-08, 'epoch': 0.86}
{'loss': 1.1524, 'grad_norm': 1.8617089346367677, 'learning_rate': 9.80806306657267e-08, 'epoch': 0.86}
{'loss': 1.1015, 'grad_norm': 1.6561041663966538, 'learning_rate': 9.789105201697923e-08, 'epoch': 0.86}
{'loss': 1.1289, 'grad_norm': 2.1258325479319837, 'learning_rate': 9.77016473328216e-08, 'epoch': 0.86}
{'loss': 1.1697, 'grad_norm': 1.8304525955725597, 'learning_rate': 9.751241664977927e-08, 'epoch': 0.86}
{'loss': 1.16, 'grad_norm': 1.8581396037777824, 'learning_rate': 9.732336000434304e-08, 'epoch': 0.86}
{'loss': 1.1357, 'grad_norm': 1.9263089716043587, 'learning_rate': 9.713447743297198e-08, 'epoch': 0.86}
{'loss': 1.1295, 'grad_norm': 2.107126157156885, 'learning_rate': 9.694576897208984e-08, 'epoch': 0.86}
{'loss': 1.1426, 'grad_norm': 4.461028066826279, 'learning_rate': 9.675723465808827e-08, 'epoch': 0.86}
{'loss': 1.1409, 'grad_norm': 1.6190079135649131, 'learning_rate': 9.656887452732399e-08, 'epoch': 0.86}
{'loss': 1.1181, 'grad_norm': 1.616603430940407, 'learning_rate': 9.638068861612091e-08, 'epoch': 0.86}
{'loss': 1.1152, 'grad_norm': 1.7239947410629752, 'learning_rate': 9.619267696076938e-08, 'epoch': 0.86}
{'loss': 1.1572, 'grad_norm': 1.9222811970751839, 'learning_rate': 9.600483959752592e-08, 'epoch': 0.86}
{'loss': 1.1393, 'grad_norm': 3.2935946669604848, 'learning_rate': 9.581717656261335e-08, 'epoch': 0.86}
{'loss': 1.1251, 'grad_norm': 1.7907081805018734, 'learning_rate': 9.562968789222114e-08, 'epoch': 0.86}
{'loss': 1.1556, 'grad_norm': 1.978845878170512, 'learning_rate': 9.544237362250495e-08, 'epoch': 0.86}
{'loss': 1.0916, 'grad_norm': 1.6714797109457122, 'learning_rate': 9.525523378958688e-08, 'epoch': 0.86}
{'loss': 1.0988, 'grad_norm': 3.801261959337403, 'learning_rate': 9.50682684295554e-08, 'epoch': 0.86}
{'loss': 1.1187, 'grad_norm': 1.5863661813721055, 'learning_rate': 9.488147757846521e-08, 'epoch': 0.86}
{'loss': 1.1439, 'grad_norm': 2.6155321489987498, 'learning_rate': 9.46948612723375e-08, 'epoch': 0.86}
{'loss': 1.1687, 'grad_norm': 1.7861517339697166, 'learning_rate': 9.450841954715971e-08, 'epoch': 0.86}
{'loss': 1.1275, 'grad_norm': 1.758134399325192, 'learning_rate': 9.432215243888575e-08, 'epoch': 0.86}
{'loss': 1.1231, 'grad_norm': 1.9052458152073284, 'learning_rate': 9.413605998343566e-08, 'epoch': 0.86}
{'loss': 1.1287, 'grad_norm': 2.184565117915111, 'learning_rate': 9.395014221669595e-08, 'epoch': 0.87}
{'loss': 1.1479, 'grad_norm': 1.5854843609678646, 'learning_rate': 9.376439917451962e-08, 'epoch': 0.87}
{'loss': 1.1473, 'grad_norm': 2.4572859755015704, 'learning_rate': 9.357883089272512e-08, 'epoch': 0.87}
{'loss': 1.1356, 'grad_norm': 1.6240183306111986, 'learning_rate': 9.33934374070986e-08, 'epoch': 0.87}
{'loss': 1.1265, 'grad_norm': 1.6546709782261257, 'learning_rate': 9.320821875339091e-08, 'epoch': 0.87}
{'loss': 1.1219, 'grad_norm': 1.6998025954797622, 'learning_rate': 9.302317496732092e-08, 'epoch': 0.87}
{'loss': 1.1269, 'grad_norm': 1.6895620247078484, 'learning_rate': 9.283830608457199e-08, 'epoch': 0.87}
{'loss': 1.1623, 'grad_norm': 1.9937628616838519, 'learning_rate': 9.265361214079548e-08, 'epoch': 0.87}
{'loss': 1.1147, 'grad_norm': 2.0546351581087414, 'learning_rate': 9.246909317160744e-08, 'epoch': 0.87}
{'loss': 1.1745, 'grad_norm': 2.323054289802963, 'learning_rate': 9.228474921259121e-08, 'epoch': 0.87}
{'loss': 1.1462, 'grad_norm': 1.6546365065438091, 'learning_rate': 9.210058029929602e-08, 'epoch': 0.87}
{'loss': 1.1575, 'grad_norm': 2.9392586721436054, 'learning_rate': 9.191658646723732e-08, 'epoch': 0.87}
{'loss': 1.1228, 'grad_norm': 1.9747817240295014, 'learning_rate': 9.173276775189709e-08, 'epoch': 0.87}
{'loss': 1.1681, 'grad_norm': 2.340148325850363, 'learning_rate': 9.154912418872306e-08, 'epoch': 0.87}
{'loss': 1.1328, 'grad_norm': 5.148897261292847, 'learning_rate': 9.136565581312961e-08, 'epoch': 0.87}
{'loss': 1.1304, 'grad_norm': 1.914943682037645, 'learning_rate': 9.118236266049705e-08, 'epoch': 0.87}
{'loss': 1.1147, 'grad_norm': 2.999006545862084, 'learning_rate': 9.099924476617216e-08, 'epoch': 0.87}
{'loss': 1.153, 'grad_norm': 1.928247393388114, 'learning_rate': 9.081630216546766e-08, 'epoch': 0.87}
{'loss': 1.1467, 'grad_norm': 3.042587689529908, 'learning_rate': 9.063353489366287e-08, 'epoch': 0.87}
{'loss': 1.1697, 'grad_norm': 2.340097759721643, 'learning_rate': 9.045094298600232e-08, 'epoch': 0.87}
 87%|█████▏| 6400/7376 [16:30:07<1:48:04,  6.64s/it]/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py:1898: UserWarning: Positional arg
s are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed
 explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior,
 you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.1349, 'grad_norm': 2.028703833735949, 'learning_rate': 9.026852647769822e-08, 'epoch': 0.87}
 87%|████▎| 6401/7376 [16:35:17<26:26:58, 97.66s/it]/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.
 Expecting to read 4 bytes but only got 2.
  warnings.warn(str(msg))
{'loss': 1.1278, 'grad_norm': 1.76698013665226, 'learning_rate': 9.008628540392749e-08, 'epoch': 0.87}
{'loss': 1.1557, 'grad_norm': 1.7879757371794536, 'learning_rate': 8.990421979983465e-08, 'epoch': 0.87}
{'loss': 1.1216, 'grad_norm': 1.989340046430742, 'learning_rate': 8.972232970052873e-08, 'epoch': 0.87}
{'loss': 1.1597, 'grad_norm': 1.782787088586076, 'learning_rate': 8.954061514108657e-08, 'epoch': 0.87}
{'loss': 1.1471, 'grad_norm': 1.7513996925916937, 'learning_rate': 8.93590761565497e-08, 'epoch': 0.87}
{'loss': 1.1228, 'grad_norm': 1.5457106643258431, 'learning_rate': 8.917771278192709e-08, 'epoch': 0.87}
{'loss': 1.0734, 'grad_norm': 1.7618666465964525, 'learning_rate': 8.899652505219279e-08, 'epoch': 0.87}
{'loss': 1.1244, 'grad_norm': 5.1874254865094285, 'learning_rate': 8.881551300228785e-08, 'epoch': 0.87}
{'loss': 1.1262, 'grad_norm': 2.3620641852772435, 'learning_rate': 8.863467666711865e-08, 'epoch': 0.87}
{'loss': 1.1479, 'grad_norm': 2.655324727132359, 'learning_rate': 8.845401608155822e-08, 'epoch': 0.87}
{'loss': 1.1562, 'grad_norm': 1.692606843146902, 'learning_rate': 8.827353128044535e-08, 'epoch': 0.87}
{'loss': 1.1265, 'grad_norm': 1.8377327306897078, 'learning_rate': 8.809322229858529e-08, 'epoch': 0.87}
{'loss': 1.1436, 'grad_norm': 2.6947676231757844, 'learning_rate': 8.791308917074925e-08, 'epoch': 0.87}
{'loss': 1.0977, 'grad_norm': 2.2116898279113957, 'learning_rate': 8.773313193167431e-08, 'epoch': 0.87}
{'loss': 1.0865, 'grad_norm': 1.6582952821541452, 'learning_rate': 8.755335061606383e-08, 'epoch': 0.87}
{'loss': 1.1405, 'grad_norm': 1.8544930496686594, 'learning_rate': 8.737374525858743e-08, 'epoch': 0.87}
{'loss': 1.0845, 'grad_norm': 2.0228968406510592, 'learning_rate': 8.719431589388026e-08, 'epoch': 0.87}
{'loss': 1.1575, 'grad_norm': 1.7360877045597363, 'learning_rate': 8.701506255654411e-08, 'epoch': 0.87}
{'loss': 1.1129, 'grad_norm': 1.9700291786797395, 'learning_rate': 8.683598528114644e-08, 'epoch': 0.87}
{'loss': 1.1391, 'grad_norm': 1.9096262675802422, 'learning_rate': 8.665708410222095e-08, 'epoch': 0.87}
{'loss': 1.1359, 'grad_norm': 2.465454519869327, 'learning_rate': 8.647835905426726e-08, 'epoch': 0.87}
{'loss': 1.1373, 'grad_norm': 5.225017206238359, 'learning_rate': 8.629981017175136e-08, 'epoch': 0.87}
{'loss': 1.1901, 'grad_norm': 1.839816978124513, 'learning_rate': 8.61214374891045e-08, 'epoch': 0.87}
{'loss': 1.1793, 'grad_norm': 2.042411079942866, 'learning_rate': 8.59432410407248e-08, 'epoch': 0.87}
{'loss': 1.1328, 'grad_norm': 1.7334815080156525, 'learning_rate': 8.576522086097593e-08, 'epoch': 0.87}
{'loss': 1.1145, 'grad_norm': 1.95895992997314, 'learning_rate': 8.55873769841876e-08, 'epoch': 0.87}
{'loss': 1.1327, 'grad_norm': 1.8693976532888532, 'learning_rate': 8.540970944465575e-08, 'epoch': 0.87}
{'loss': 1.1345, 'grad_norm': 1.5958874915520316, 'learning_rate': 8.523221827664206e-08, 'epoch': 0.87}
{'loss': 1.1304, 'grad_norm': 2.0626016191590355, 'learning_rate': 8.505490351437438e-08, 'epoch': 0.87}
{'loss': 1.0561, 'grad_norm': 1.828040802424155, 'learning_rate': 8.487776519204637e-08, 'epoch': 0.87}
{'loss': 1.1193, 'grad_norm': 1.8124759363376035, 'learning_rate': 8.470080334381791e-08, 'epoch': 0.87}
{'loss': 1.1498, 'grad_norm': 2.9629653713029476, 'learning_rate': 8.452401800381448e-08, 'epoch': 0.87}
{'loss': 1.0985, 'grad_norm': 2.672421978927302, 'learning_rate': 8.434740920612792e-08, 'epoch': 0.87}
{'loss': 1.131, 'grad_norm': 2.2946858429954116, 'learning_rate': 8.417097698481568e-08, 'epoch': 0.87}
{'loss': 1.135, 'grad_norm': 1.6538508084236532, 'learning_rate': 8.399472137390152e-08, 'epoch': 0.87}
{'loss': 1.1387, 'grad_norm': 1.7191586861848696, 'learning_rate': 8.38186424073748e-08, 'epoch': 0.87}
{'loss': 1.1394, 'grad_norm': 1.664695984829714, 'learning_rate': 8.364274011919114e-08, 'epoch': 0.87}
{'loss': 1.1767, 'grad_norm': 1.9198441124150405, 'learning_rate': 8.346701454327143e-08, 'epoch': 0.87}
{'loss': 1.1278, 'grad_norm': 1.6533982080318481, 'learning_rate': 8.329146571350365e-08, 'epoch': 0.87}
{'loss': 1.1658, 'grad_norm': 4.208373676930938, 'learning_rate': 8.311609366374028e-08, 'epoch': 0.87}
{'loss': 1.1291, 'grad_norm': 2.164922492604288, 'learning_rate': 8.294089842780117e-08, 'epoch': 0.87}
{'loss': 1.0853, 'grad_norm': 3.826807379393319, 'learning_rate': 8.27658800394706e-08, 'epoch': 0.87}
{'loss': 1.1235, 'grad_norm': 1.749656638081257, 'learning_rate': 8.259103853250027e-08, 'epoch': 0.87}
{'loss': 1.1236, 'grad_norm': 1.747059267138261, 'learning_rate': 8.241637394060619e-08, 'epoch': 0.87}
{'loss': 1.0881, 'grad_norm': 1.7856003386082375, 'learning_rate': 8.224188629747175e-08, 'epoch': 0.87}
{'loss': 1.1514, 'grad_norm': 2.7039887116565833, 'learning_rate': 8.206757563674493e-08, 'epoch': 0.87}
{'loss': 1.1662, 'grad_norm': 1.6562534908284436, 'learning_rate': 8.189344199204073e-08, 'epoch': 0.87}
{'loss': 1.1381, 'grad_norm': 1.7498281442363768, 'learning_rate': 8.171948539693874e-08, 'epoch': 0.87}
{'loss': 1.1354, 'grad_norm': 1.957646897840696, 'learning_rate': 8.154570588498599e-08, 'epoch': 0.87}
{'loss': 1.117, 'grad_norm': 2.1346861163603745, 'learning_rate': 8.13721034896938e-08, 'epoch': 0.87}
{'loss': 1.1549, 'grad_norm': 1.7782920560225477, 'learning_rate': 8.119867824454018e-08, 'epoch': 0.87}
{'loss': 1.1417, 'grad_norm': 2.585917265718191, 'learning_rate': 8.102543018296892e-08, 'epoch': 0.87}
{'loss': 1.1012, 'grad_norm': 1.8424330122494461, 'learning_rate': 8.085235933838952e-08, 'epoch': 0.87}
{'loss': 1.0997, 'grad_norm': 1.7549300894634328, 'learning_rate': 8.067946574417739e-08, 'epoch': 0.88}
{'loss': 1.1596, 'grad_norm': 2.1083379016790214, 'learning_rate': 8.050674943367352e-08, 'epoch': 0.88}
{'loss': 1.15, 'grad_norm': 2.252809396009884, 'learning_rate': 8.033421044018496e-08, 'epoch': 0.88}
{'loss': 1.1404, 'grad_norm': 2.703081794641011, 'learning_rate': 8.016184879698462e-08, 'epoch': 0.88}
{'loss': 1.1399, 'grad_norm': 1.995642659279966, 'learning_rate': 7.998966453731093e-08, 'epoch': 0.88}
{'loss': 1.1395, 'grad_norm': 1.6484780989781318, 'learning_rate': 7.981765769436833e-08, 'epoch': 0.88}
{'loss': 1.1274, 'grad_norm': 1.712596129098464, 'learning_rate': 7.964582830132704e-08, 'epoch': 0.88}
{'loss': 1.1698, 'grad_norm': 2.4580521017153676, 'learning_rate': 7.94741763913227e-08, 'epoch': 0.88}
{'loss': 1.1398, 'grad_norm': 1.6399134766925867, 'learning_rate': 7.930270199745748e-08, 'epoch': 0.88}
{'loss': 1.1309, 'grad_norm': 2.9045496830493387, 'learning_rate': 7.913140515279837e-08, 'epoch': 0.88}
{'loss': 1.148, 'grad_norm': 1.853291485456398, 'learning_rate': 7.896028589037929e-08, 'epoch': 0.88}
{'loss': 1.1579, 'grad_norm': 1.7591583079051485, 'learning_rate': 7.87893442431985e-08, 'epoch': 0.88}
{'loss': 1.1294, 'grad_norm': 2.45903421938785, 'learning_rate': 7.86185802442212e-08, 'epoch': 0.88}
{'loss': 1.1757, 'grad_norm': 1.822865532701106, 'learning_rate': 7.844799392637769e-08, 'epoch': 0.88}
{'loss': 1.1259, 'grad_norm': 2.417590478302076, 'learning_rate': 7.827758532256435e-08, 'epoch': 0.88}
{'loss': 1.1693, 'grad_norm': 2.150272970636816, 'learning_rate': 7.810735446564298e-08, 'epoch': 0.88}
{'loss': 1.1531, 'grad_norm': 2.0816057276308984, 'learning_rate': 7.793730138844134e-08, 'epoch': 0.88}
{'loss': 1.1265, 'grad_norm': 1.6591630582596637, 'learning_rate': 7.776742612375275e-08, 'epoch': 0.88}
{'loss': 1.1219, 'grad_norm': 3.0536936167163784, 'learning_rate': 7.759772870433645e-08, 'epoch': 0.88}
{'loss': 1.1584, 'grad_norm': 2.5883130488882418, 'learning_rate': 7.742820916291714e-08, 'epoch': 0.88}
{'loss': 1.1225, 'grad_norm': 3.4460120924764244, 'learning_rate': 7.725886753218536e-08, 'epoch': 0.88}
{'loss': 1.0814, 'grad_norm': 1.611288174099806, 'learning_rate': 7.708970384479729e-08, 'epoch': 0.88}
{'loss': 1.1814, 'grad_norm': 2.7711323805834653, 'learning_rate': 7.692071813337487e-08, 'epoch': 0.88}
{'loss': 1.1443, 'grad_norm': 3.747710880594771, 'learning_rate': 7.675191043050556e-08, 'epoch': 0.88}
{'loss': 1.0902, 'grad_norm': 1.7617536711277373, 'learning_rate': 7.658328076874287e-08, 'epoch': 0.88}
{'loss': 1.1921, 'grad_norm': 2.6537771193229887, 'learning_rate': 7.641482918060504e-08, 'epoch': 0.88}
{'loss': 1.1006, 'grad_norm': 1.6796081608072557, 'learning_rate': 7.624655569857751e-08, 'epoch': 0.88}
{'loss': 1.16, 'grad_norm': 1.6613723215359724, 'learning_rate': 7.607846035510957e-08, 'epoch': 0.88}
{'loss': 1.1796, 'grad_norm': 2.660110974262545, 'learning_rate': 7.591054318261802e-08, 'epoch': 0.88}
{'loss': 1.1657, 'grad_norm': 2.1156025813259536, 'learning_rate': 7.574280421348356e-08, 'epoch': 0.88}
{'loss': 1.114, 'grad_norm': 1.7269722587174925, 'learning_rate': 7.557524348005395e-08, 'epoch': 0.88}
{'loss': 1.1473, 'grad_norm': 1.8842104957438535, 'learning_rate': 7.540786101464136e-08, 'epoch': 0.88}
{'loss': 1.1478, 'grad_norm': 2.65859677639849, 'learning_rate': 7.524065684952475e-08, 'epoch': 0.88}
{'loss': 1.134, 'grad_norm': 1.8070017846741304, 'learning_rate': 7.507363101694775e-08, 'epoch': 0.88}
{'loss': 1.1729, 'grad_norm': 4.020223199639944, 'learning_rate': 7.490678354912006e-08, 'epoch': 0.88}
{'loss': 1.1356, 'grad_norm': 2.0598342631581263, 'learning_rate': 7.474011447821704e-08, 'epoch': 0.88}
{'loss': 1.1101, 'grad_norm': 15.825380685217736, 'learning_rate': 7.457362383637922e-08, 'epoch': 0.88}
{'loss': 1.1293, 'grad_norm': 1.7537746165714558, 'learning_rate': 7.440731165571323e-08, 'epoch': 0.88}
{'loss': 1.1393, 'grad_norm': 1.668143101935234, 'learning_rate': 7.42411779682911e-08, 'epoch': 0.88}
{'loss': 1.1292, 'grad_norm': 1.5690818359806484, 'learning_rate': 7.407522280615019e-08, 'epoch': 0.88}
{'loss': 1.1852, 'grad_norm': 1.4823237802353644, 'learning_rate': 7.39094462012938e-08, 'epoch': 0.88}
{'loss': 1.1428, 'grad_norm': 3.0407982709052104, 'learning_rate': 7.374384818569069e-08, 'epoch': 0.88}
{'loss': 1.1465, 'grad_norm': 1.8365776074610398, 'learning_rate': 7.357842879127474e-08, 'epoch': 0.88}
{'loss': 1.1587, 'grad_norm': 1.9846734856987747, 'learning_rate': 7.341318804994645e-08, 'epoch': 0.88}
{'loss': 1.1083, 'grad_norm': 1.654483831605577, 'learning_rate': 7.324812599357044e-08, 'epoch': 0.88}
{'loss': 1.1476, 'grad_norm': 1.7875430980706335, 'learning_rate': 7.308324265397836e-08, 'epoch': 0.88}
 88%|█████▎| 6500/7376 [16:45:26<1:28:57,  6.09s/it]/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py:1898: UserWarning: Positional arg
s are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed
 explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior,
 you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.1415, 'grad_norm': 3.2934615211142644, 'learning_rate': 7.291853806296599e-08, 'epoch': 0.88}
{'loss': 1.1257, 'grad_norm': 1.914934823902239, 'learning_rate': 7.275401225229583e-08, 'epoch': 0.88}
{'loss': 1.1563, 'grad_norm': 2.618572614627152, 'learning_rate': 7.258966525369492e-08, 'epoch': 0.88}
{'loss': 1.0892, 'grad_norm': 1.737876806064117, 'learning_rate': 7.242549709885693e-08, 'epoch': 0.88}
{'loss': 1.1151, 'grad_norm': 1.6641941863735326, 'learning_rate': 7.226150781943963e-08, 'epoch': 0.88}
{'loss': 1.0984, 'grad_norm': 1.9977681429618914, 'learning_rate': 7.209769744706772e-08, 'epoch': 0.88}
{'loss': 1.1552, 'grad_norm': 2.7593099042880653, 'learning_rate': 7.193406601333018e-08, 'epoch': 0.88}
{'loss': 1.1416, 'grad_norm': 2.350168531900302, 'learning_rate': 7.177061354978242e-08, 'epoch': 0.88}
{'loss': 1.1387, 'grad_norm': 2.1763178973000095, 'learning_rate': 7.160734008794489e-08, 'epoch': 0.88}
{'loss': 1.1355, 'grad_norm': 2.278993588683687, 'learning_rate': 7.144424565930341e-08, 'epoch': 0.88}
{'loss': 1.1083, 'grad_norm': 2.447666937518223, 'learning_rate': 7.128133029530969e-08, 'epoch': 0.88}
{'loss': 1.1544, 'grad_norm': 2.114484884173671, 'learning_rate': 7.111859402738052e-08, 'epoch': 0.88}
{'loss': 1.1123, 'grad_norm': 1.5719108514590139, 'learning_rate': 7.095603688689833e-08, 'epoch': 0.88}
{'loss': 1.1135, 'grad_norm': 1.7742523309225513, 'learning_rate': 7.079365890521106e-08, 'epoch': 0.88}
{'loss': 1.1094, 'grad_norm': 1.9651746407183057, 'learning_rate': 7.063146011363186e-08, 'epoch': 0.88}
{'loss': 1.1547, 'grad_norm': 2.615209881918816, 'learning_rate': 7.046944054343961e-08, 'epoch': 0.88}
{'loss': 1.1615, 'grad_norm': 1.907433134097656, 'learning_rate': 7.030760022587856e-08, 'epoch': 0.88}
{'loss': 1.1269, 'grad_norm': 2.0790802240771304, 'learning_rate': 7.014593919215816e-08, 'epoch': 0.88}
{'loss': 1.1272, 'grad_norm': 1.908075534540681, 'learning_rate': 6.998445747345371e-08, 'epoch': 0.88}
{'loss': 1.1604, 'grad_norm': 2.1986979576862575, 'learning_rate': 6.982315510090542e-08, 'epoch': 0.88}
{'loss': 1.113, 'grad_norm': 3.3911291429686705, 'learning_rate': 6.966203210561927e-08, 'epoch': 0.88}
{'loss': 1.1339, 'grad_norm': 1.7389265840070545, 'learning_rate': 6.950108851866687e-08, 'epoch': 0.88}
{'loss': 1.1524, 'grad_norm': 2.192035720373438, 'learning_rate': 6.934032437108439e-08, 'epoch': 0.88}
{'loss': 1.1399, 'grad_norm': 3.066136874404219, 'learning_rate': 6.917973969387424e-08, 'epoch': 0.88}
{'loss': 1.1472, 'grad_norm': 2.0224746005259373, 'learning_rate': 6.901933451800379e-08, 'epoch': 0.88}
{'loss': 1.1356, 'grad_norm': 1.97895826145527, 'learning_rate': 6.885910887440593e-08, 'epoch': 0.88}
{'loss': 1.1434, 'grad_norm': 1.601090248128626, 'learning_rate': 6.869906279397897e-08, 'epoch': 0.88}
{'loss': 1.1499, 'grad_norm': 2.1940856573417697, 'learning_rate': 6.853919630758653e-08, 'epoch': 0.88}
{'loss': 1.1116, 'grad_norm': 1.824841480578177, 'learning_rate': 6.837950944605763e-08, 'epoch': 0.89}
{'loss': 1.1198, 'grad_norm': 1.7979957538415279, 'learning_rate': 6.822000224018653e-08, 'epoch': 0.89}
{'loss': 1.152, 'grad_norm': 2.003561416760149, 'learning_rate': 6.806067472073296e-08, 'epoch': 0.89}
{'loss': 1.1658, 'grad_norm': 2.996048103030528, 'learning_rate': 6.790152691842199e-08, 'epoch': 0.89}
{'loss': 1.1058, 'grad_norm': 1.788291637102259, 'learning_rate': 6.774255886394397e-08, 'epoch': 0.89}
{'loss': 1.1255, 'grad_norm': 2.753692137293281, 'learning_rate': 6.758377058795473e-08, 'epoch': 0.89}
{'loss': 1.1605, 'grad_norm': 2.479453658977365, 'learning_rate': 6.742516212107541e-08, 'epoch': 0.89}
{'loss': 1.1567, 'grad_norm': 1.6564878468605677, 'learning_rate': 6.726673349389201e-08, 'epoch': 0.89}
{'loss': 1.1343, 'grad_norm': 3.3952464847088426, 'learning_rate': 6.710848473695674e-08, 'epoch': 0.89}
{'loss': 1.1342, 'grad_norm': 1.6629858712160441, 'learning_rate': 6.69504158807862e-08, 'epoch': 0.89}
{'loss': 1.1402, 'grad_norm': 2.996834246674295, 'learning_rate': 6.679252695586312e-08, 'epoch': 0.89}
{'loss': 1.0753, 'grad_norm': 1.8320408840940319, 'learning_rate': 6.663481799263471e-08, 'epoch': 0.89}
{'loss': 1.1264, 'grad_norm': 1.799416343602753, 'learning_rate': 6.647728902151428e-08, 'epoch': 0.89}
{'loss': 1.1412, 'grad_norm': 5.644921978614418, 'learning_rate': 6.631994007287966e-08, 'epoch': 0.89}
{'loss': 1.1327, 'grad_norm': 1.9467233823520789, 'learning_rate': 6.616277117707492e-08, 'epoch': 0.89}
{'loss': 1.212, 'grad_norm': 2.752631504938017, 'learning_rate': 6.600578236440812e-08, 'epoch': 0.89}
{'loss': 1.1349, 'grad_norm': 1.8650024815627557, 'learning_rate': 6.584897366515407e-08, 'epoch': 0.89}
{'loss': 1.1636, 'grad_norm': 1.8721084327969897, 'learning_rate': 6.569234510955135e-08, 'epoch': 0.89}
{'loss': 1.1354, 'grad_norm': 1.8147260254436504, 'learning_rate': 6.553589672780524e-08, 'epoch': 0.89}
{'loss': 1.1304, 'grad_norm': 2.2622499676130774, 'learning_rate': 6.537962855008483e-08, 'epoch': 0.89}
{'loss': 1.149, 'grad_norm': 3.6992883622526893, 'learning_rate': 6.522354060652602e-08, 'epoch': 0.89}
{'loss': 1.109, 'grad_norm': 1.7523591993937109, 'learning_rate': 6.50676329272285e-08, 'epoch': 0.89}
{'loss': 1.0851, 'grad_norm': 1.8396252667655812, 'learning_rate': 6.491190554225811e-08, 'epoch': 0.89}
{'loss': 1.1275, 'grad_norm': 2.227804033864536, 'learning_rate': 6.475635848164562e-08, 'epoch': 0.89}
{'loss': 1.1461, 'grad_norm': 1.9614080338482218, 'learning_rate': 6.460099177538703e-08, 'epoch': 0.89}
{'loss': 1.1215, 'grad_norm': 2.8523487398204694, 'learning_rate': 6.444580545344358e-08, 'epoch': 0.89}
{'loss': 1.1296, 'grad_norm': 1.5581155224962762, 'learning_rate': 6.429079954574168e-08, 'epoch': 0.89}
{'loss': 1.1358, 'grad_norm': 2.189555394286035, 'learning_rate': 6.413597408217309e-08, 'epoch': 0.89}
{'loss': 1.0901, 'grad_norm': 1.870775255331432, 'learning_rate': 6.398132909259457e-08, 'epoch': 0.89}
{'loss': 1.143, 'grad_norm': 1.7080183908461486, 'learning_rate': 6.382686460682851e-08, 'epoch': 0.89}
{'loss': 1.1282, 'grad_norm': 1.6640441388971368, 'learning_rate': 6.367258065466152e-08, 'epoch': 0.89}
{'loss': 1.1042, 'grad_norm': 2.4341167603733562, 'learning_rate': 6.35184772658468e-08, 'epoch': 0.89}
{'loss': 1.1583, 'grad_norm': 2.2262508271214743, 'learning_rate': 6.336455447010126e-08, 'epoch': 0.89}
{'loss': 1.1387, 'grad_norm': 1.7132675678293754, 'learning_rate': 6.321081229710834e-08, 'epoch': 0.89}
{'loss': 1.1474, 'grad_norm': 1.699293696407783, 'learning_rate': 6.305725077651558e-08, 'epoch': 0.89}
{'loss': 1.1239, 'grad_norm': 2.3138363174585588, 'learning_rate': 6.290386993793617e-08, 'epoch': 0.89}
{'loss': 1.1251, 'grad_norm': 7.938951443039966, 'learning_rate': 6.275066981094857e-08, 'epoch': 0.89}
{'loss': 1.1302, 'grad_norm': 1.731927865901536, 'learning_rate': 6.259765042509602e-08, 'epoch': 0.89}
{'loss': 1.1249, 'grad_norm': 1.8137787024852847, 'learning_rate': 6.244481180988714e-08, 'epoch': 0.89}
{'loss': 1.1555, 'grad_norm': 1.5768021847889244, 'learning_rate': 6.229215399479582e-08, 'epoch': 0.89}
{'loss': 1.1296, 'grad_norm': 2.1022876264655435, 'learning_rate': 6.213967700926071e-08, 'epoch': 0.89}
{'loss': 1.1416, 'grad_norm': 1.707687202205395, 'learning_rate': 6.198738088268585e-08, 'epoch': 0.89}
{'loss': 1.1454, 'grad_norm': 1.525734732124275, 'learning_rate': 6.183526564444042e-08, 'epoch': 0.89}
{'loss': 1.1194, 'grad_norm': 1.8254856744949666, 'learning_rate': 6.16833313238585e-08, 'epoch': 0.89}
{'loss': 1.1732, 'grad_norm': 2.124334112601339, 'learning_rate': 6.153157795023956e-08, 'epoch': 0.89}
{'loss': 1.1212, 'grad_norm': 1.630922183688529, 'learning_rate': 6.138000555284806e-08, 'epoch': 0.89}
{'loss': 1.1421, 'grad_norm': 3.094909473005925, 'learning_rate': 6.12286141609134e-08, 'epoch': 0.89}
{'loss': 1.1387, 'grad_norm': 1.9596434735988246, 'learning_rate': 6.107740380363036e-08, 'epoch': 0.89}
{'loss': 1.2163, 'grad_norm': 1.6462386860690867, 'learning_rate': 6.092637451015847e-08, 'epoch': 0.89}
{'loss': 1.1617, 'grad_norm': 1.9798856243725116, 'learning_rate': 6.07755263096229e-08, 'epoch': 0.89}
{'loss': 1.1305, 'grad_norm': 3.4886553427978915, 'learning_rate': 6.062485923111293e-08, 'epoch': 0.89}
{'loss': 1.1555, 'grad_norm': 2.215085539219178, 'learning_rate': 6.047437330368421e-08, 'epoch': 0.89}
{'loss': 1.1912, 'grad_norm': 2.1693624595950016, 'learning_rate': 6.032406855635619e-08, 'epoch': 0.89}
{'loss': 1.1865, 'grad_norm': 2.086360772035384, 'learning_rate': 6.017394501811445e-08, 'epoch': 0.89}
{'loss': 1.0685, 'grad_norm': 1.9044077046260828, 'learning_rate': 6.002400271790864e-08, 'epoch': 0.89}
{'loss': 1.1633, 'grad_norm': 2.718787072555157, 'learning_rate': 5.987424168465439e-08, 'epoch': 0.89}
{'loss': 1.1509, 'grad_norm': 1.8032154851226005, 'learning_rate': 5.972466194723159e-08, 'epoch': 0.89}
{'loss': 1.1664, 'grad_norm': 1.81157372697028, 'learning_rate': 5.957526353448572e-08, 'epoch': 0.89}
{'loss': 1.1433, 'grad_norm': 3.1461924368521355, 'learning_rate': 5.9426046475226975e-08, 'epoch': 0.89}
{'loss': 1.1449, 'grad_norm': 1.776911051631953, 'learning_rate': 5.9277010798230666e-08, 'epoch': 0.89}
{'loss': 1.0813, 'grad_norm': 1.6399770431389162, 'learning_rate': 5.912815653223724e-08, 'epoch': 0.89}
{'loss': 1.1082, 'grad_norm': 1.7016064454636086, 'learning_rate': 5.897948370595207e-08, 'epoch': 0.89}
{'loss': 1.1306, 'grad_norm': 3.5845028027790433, 'learning_rate': 5.8830992348045563e-08, 'epoch': 0.89}
{'loss': 1.1133, 'grad_norm': 1.9945663226670722, 'learning_rate': 5.8682682487152915e-08, 'epoch': 0.89}
{'loss': 1.1439, 'grad_norm': 3.2356562446346175, 'learning_rate': 5.8534554151874805e-08, 'epoch': 0.89}
{'loss': 1.1237, 'grad_norm': 1.6965032774543347, 'learning_rate': 5.8386607370776274e-08, 'epoch': 0.89}
{'loss': 1.1156, 'grad_norm': 2.1087063876931573, 'learning_rate': 5.823884217238817e-08, 'epoch': 0.89}
{'loss': 1.1152, 'grad_norm': 1.9755978937932837, 'learning_rate': 5.809125858520514e-08, 'epoch': 0.89}
{'loss': 1.1371, 'grad_norm': 1.757876591401235, 'learning_rate': 5.794385663768819e-08, 'epoch': 0.89}
{'loss': 1.138, 'grad_norm': 2.0345296005755253, 'learning_rate': 5.7796636358262155e-08, 'epoch': 0.89}
{'loss': 1.1408, 'grad_norm': 1.8091866729637018, 'learning_rate': 5.764959777531775e-08, 'epoch': 0.89}
{'loss': 1.1412, 'grad_norm': 1.8656612439043583, 'learning_rate': 5.750274091720964e-08, 'epoch': 0.89}
 89%|█████▎| 6600/7376 [16:59:43<1:19:33,  6.15s/it]/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py:1898: UserWarning: Positional arg
s are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed
 explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior,
 you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.1238, 'grad_norm': 2.378265630060403, 'learning_rate': 5.7356065812258604e-08, 'epoch': 0.89}
{'loss': 1.1316, 'grad_norm': 1.7607569548391533, 'learning_rate': 5.720957248874925e-08, 'epoch': 0.9}
{'loss': 1.1048, 'grad_norm': 1.731516356115962, 'learning_rate': 5.706326097493219e-08, 'epoch': 0.9}
{'loss': 1.1437, 'grad_norm': 1.7360666607420787, 'learning_rate': 5.691713129902187e-08, 'epoch': 0.9}
{'loss': 1.1271, 'grad_norm': 1.6870836886615719, 'learning_rate': 5.677118348919874e-08, 'epoch': 0.9}
{'loss': 1.151, 'grad_norm': 1.6535337401169583, 'learning_rate': 5.662541757360739e-08, 'epoch': 0.9}
{'loss': 1.1336, 'grad_norm': 1.8917660025169987, 'learning_rate': 5.6479833580357796e-08, 'epoch': 0.9}
{'loss': 1.1002, 'grad_norm': 2.3574670123271377, 'learning_rate': 5.633443153752448e-08, 'epoch': 0.9}
{'loss': 1.1258, 'grad_norm': 1.859487138721219, 'learning_rate': 5.6189211473147256e-08, 'epoch': 0.9}
{'loss': 1.1537, 'grad_norm': 1.6828467303582308, 'learning_rate': 5.60441734152306e-08, 'epoch': 0.9}
{'loss': 1.1464, 'grad_norm': 1.941420502964534, 'learning_rate': 5.5899317391744025e-08, 'epoch': 0.9}
{'loss': 1.1542, 'grad_norm': 2.3126265533807855, 'learning_rate': 5.575464343062175e-08, 'epoch': 0.9}
{'loss': 1.1537, 'grad_norm': 2.9879123217769843, 'learning_rate': 5.561015155976312e-08, 'epoch': 0.9}
{'loss': 1.1561, 'grad_norm': 2.0612251808162534, 'learning_rate': 5.546584180703207e-08, 'epoch': 0.9}
{'loss': 1.1223, 'grad_norm': 1.862534153261607, 'learning_rate': 5.5321714200257884e-08, 'epoch': 0.9}
{'loss': 1.123, 'grad_norm': 1.8822944636441217, 'learning_rate': 5.5177768767234236e-08, 'epoch': 0.9}
{'loss': 1.1445, 'grad_norm': 1.9569473239671715, 'learning_rate': 5.50340055357198e-08, 'epoch': 0.9}
{'loss': 1.1376, 'grad_norm': 2.354764987177449, 'learning_rate': 5.4890424533438394e-08, 'epoch': 0.9}
{'loss': 1.1693, 'grad_norm': 1.9025231715447235, 'learning_rate': 5.4747025788078546e-08, 'epoch': 0.9}
{'loss': 1.1371, 'grad_norm': 1.5893995717027236, 'learning_rate': 5.460380932729303e-08, 'epoch': 0.9}
{'loss': 1.111, 'grad_norm': 2.6239962199826343, 'learning_rate': 5.4460775178700736e-08, 'epoch': 0.9}
{'loss': 1.1295, 'grad_norm': 2.298915627580696, 'learning_rate': 5.431792336988417e-08, 'epoch': 0.9}
{'loss': 1.1583, 'grad_norm': 1.7387633093914854, 'learning_rate': 5.417525392839129e-08, 'epoch': 0.9}
{'loss': 1.1219, 'grad_norm': 1.6690530045072867, 'learning_rate': 5.4032766881734745e-08, 'epoch': 0.9}
{'loss': 1.1371, 'grad_norm': 2.2031981665906573, 'learning_rate': 5.3890462257392246e-08, 'epoch': 0.9}
{'loss': 1.127, 'grad_norm': 1.6231712047336095, 'learning_rate': 5.3748340082805824e-08, 'epoch': 0.9}
{'loss': 1.1212, 'grad_norm': 1.745747735170393, 'learning_rate': 5.360640038538278e-08, 'epoch': 0.9}
{'loss': 1.1492, 'grad_norm': 1.6966457687880216, 'learning_rate': 5.3464643192495104e-08, 'epoch': 0.9}
{'loss': 1.1192, 'grad_norm': 1.723631814815818, 'learning_rate': 5.33230685314795e-08, 'epoch': 0.9}
{'loss': 1.1068, 'grad_norm': 2.321686097519481, 'learning_rate': 5.3181676429637447e-08, 'epoch': 0.9}
{'loss': 1.1435, 'grad_norm': 1.6923789046262308, 'learning_rate': 5.304046691423536e-08, 'epoch': 0.9}
{'loss': 1.164, 'grad_norm': 2.309557836247023, 'learning_rate': 5.289944001250446e-08, 'epoch': 0.9}
{'loss': 1.1867, 'grad_norm': 2.0585721584948176, 'learning_rate': 5.275859575164054e-08, 'epoch': 0.9}
{'loss': 1.158, 'grad_norm': 2.3722781670914945, 'learning_rate': 5.2617934158804557e-08, 'epoch': 0.9}
{'loss': 1.1421, 'grad_norm': 1.7682808199280535, 'learning_rate': 5.247745526112146e-08, 'epoch': 0.9}
{'loss': 1.122, 'grad_norm': 2.3593079564831156, 'learning_rate': 5.233715908568215e-08, 'epoch': 0.9}
{'loss': 1.1234, 'grad_norm': 1.7275945470365435, 'learning_rate': 5.219704565954097e-08, 'epoch': 0.9}
{'loss': 1.1504, 'grad_norm': 3.0519549920112072, 'learning_rate': 5.2057115009718434e-08, 'epoch': 0.9}
{'loss': 1.16, 'grad_norm': 1.8173020718100557, 'learning_rate': 5.191736716319828e-08, 'epoch': 0.9}
{'loss': 1.1528, 'grad_norm': 1.7239638711748004, 'learning_rate': 5.17778021469305e-08, 'epoch': 0.9}
{'loss': 1.1489, 'grad_norm': 1.8103000578313733, 'learning_rate': 5.1638419987828365e-08, 'epoch': 0.9}
{'loss': 1.0947, 'grad_norm': 2.2245950545600643, 'learning_rate': 5.149922071277146e-08, 'epoch': 0.9}
{'loss': 1.1131, 'grad_norm': 2.6871025901088754, 'learning_rate': 5.136020434860244e-08, 'epoch': 0.9}
{'loss': 1.1335, 'grad_norm': 1.8487771105279036, 'learning_rate': 5.122137092213019e-08, 'epoch': 0.9}
{'loss': 1.1772, 'grad_norm': 2.3664450257730154, 'learning_rate': 5.108272046012718e-08, 'epoch': 0.9}
{'loss': 1.1628, 'grad_norm': 2.026134079257399, 'learning_rate': 5.094425298933136e-08, 'epoch': 0.9}
{'loss': 1.1084, 'grad_norm': 1.7585068220152709, 'learning_rate': 5.080596853644492e-08, 'epoch': 0.9}
{'loss': 1.1733, 'grad_norm': 2.1189971760224235, 'learning_rate': 5.066786712813498e-08, 'epoch': 0.9}
{'loss': 1.139, 'grad_norm': 2.0238727074249496, 'learning_rate': 5.052994879103323e-08, 'epoch': 0.9}
{'loss': 1.1357, 'grad_norm': 2.1351305583368076, 'learning_rate': 5.0392213551736176e-08, 'epoch': 0.9}
{'loss': 1.1385, 'grad_norm': 1.7154285718391653, 'learning_rate': 5.0254661436805015e-08, 'epoch': 0.9}
{'loss': 1.1263, 'grad_norm': 1.963005739881801, 'learning_rate': 5.0117292472765635e-08, 'epoch': 0.9}
{'loss': 1.1519, 'grad_norm': 1.736027938415211, 'learning_rate': 4.9980106686108416e-08, 'epoch': 0.9}
{'loss': 1.1221, 'grad_norm': 1.8306759757714315, 'learning_rate': 4.9843104103288625e-08, 'epoch': 0.9}
{'loss': 1.1411, 'grad_norm': 1.8532542764763318, 'learning_rate': 4.9706284750726135e-08, 'epoch': 0.9}
{'loss': 1.1311, 'grad_norm': 2.098411706455503, 'learning_rate': 4.956964865480551e-08, 'epoch': 0.9}
{'loss': 1.1206, 'grad_norm': 1.7431500243874734, 'learning_rate': 4.9433195841875995e-08, 'epoch': 0.9}
{'loss': 1.0982, 'grad_norm': 1.6952908325892682, 'learning_rate': 4.9296926338251e-08, 'epoch': 0.9}
{'loss': 1.1244, 'grad_norm': 1.5796687856348512, 'learning_rate': 4.916084017020972e-08, 'epoch': 0.9}
{'loss': 1.1885, 'grad_norm': 1.7577827531138124, 'learning_rate': 4.9024937363994714e-08, 'epoch': 0.9}
{'loss': 1.1274, 'grad_norm': 1.7390054401446535, 'learning_rate': 4.888921794581424e-08, 'epoch': 0.9}
{'loss': 1.1243, 'grad_norm': 1.6856054831505694, 'learning_rate': 4.875368194184026e-08, 'epoch': 0.9}
{'loss': 1.1656, 'grad_norm': 2.2853822516100557, 'learning_rate': 4.8618329378210085e-08, 'epoch': 0.9}
{'loss': 1.1297, 'grad_norm': 1.9345093206253006, 'learning_rate': 4.848316028102539e-08, 'epoch': 0.9}
{'loss': 1.164, 'grad_norm': 1.8683874020510776, 'learning_rate': 4.834817467635233e-08, 'epoch': 0.9}
{'loss': 1.0837, 'grad_norm': 1.854262606286493, 'learning_rate': 4.821337259022196e-08, 'epoch': 0.9}
{'loss': 1.1454, 'grad_norm': 1.8333406241112102, 'learning_rate': 4.807875404862971e-08, 'epoch': 0.9}
{'loss': 1.1246, 'grad_norm': 1.9806527548373372, 'learning_rate': 4.794431907753571e-08, 'epoch': 0.9}
{'loss': 1.151, 'grad_norm': 2.299833609640615, 'learning_rate': 4.781006770286478e-08, 'epoch': 0.9}
{'loss': 1.1491, 'grad_norm': 1.7364376403884978, 'learning_rate': 4.767599995050609e-08, 'epoch': 0.9}
{'loss': 1.1154, 'grad_norm': 1.584234057952154, 'learning_rate': 4.7542115846313734e-08, 'epoch': 0.9}
{'loss': 1.1326, 'grad_norm': 1.5648652550606708, 'learning_rate': 4.740841541610596e-08, 'epoch': 0.9}
{'loss': 1.149, 'grad_norm': 1.7835695816855208, 'learning_rate': 4.727489868566603e-08, 'epoch': 0.9}
{'loss': 1.1349, 'grad_norm': 1.7652105146796984, 'learning_rate': 4.714156568074157e-08, 'epoch': 0.9}
{'loss': 1.1229, 'grad_norm': 2.239524077208324, 'learning_rate': 4.700841642704478e-08, 'epoch': 0.9}
{'loss': 1.1078, 'grad_norm': 3.199177820411182, 'learning_rate': 4.687545095025225e-08, 'epoch': 0.91}
{'loss': 1.1642, 'grad_norm': 1.8660126754235602, 'learning_rate': 4.6742669276005786e-08, 'epoch': 0.91}
{'loss': 1.1152, 'grad_norm': 1.923243061284446, 'learning_rate': 4.661007142991069e-08, 'epoch': 0.91}
{'loss': 1.1006, 'grad_norm': 3.730911195337825, 'learning_rate': 4.6477657437537953e-08, 'epoch': 0.91}
{'loss': 1.1282, 'grad_norm': 3.690428975327078, 'learning_rate': 4.634542732442204e-08, 'epoch': 0.91}
{'loss': 1.1213, 'grad_norm': 1.7304968224329345, 'learning_rate': 4.62133811160631e-08, 'epoch': 0.91}
{'loss': 1.0972, 'grad_norm': 1.7510334547655368, 'learning_rate': 4.608151883792466e-08, 'epoch': 0.91}
{'loss': 1.1669, 'grad_norm': 1.9058729126314788, 'learning_rate': 4.5949840515435715e-08, 'epoch': 0.91}
{'loss': 1.1201, 'grad_norm': 2.2011611555978488, 'learning_rate': 4.581834617398916e-08, 'epoch': 0.91}
{'loss': 1.1095, 'grad_norm': 1.7202256590857774, 'learning_rate': 4.568703583894262e-08, 'epoch': 0.91}
{'loss': 1.1361, 'grad_norm': 2.2890908640002343, 'learning_rate': 4.555590953561839e-08, 'epoch': 0.91}
{'loss': 1.1272, 'grad_norm': 2.1365483409288495, 'learning_rate': 4.542496728930301e-08, 'epoch': 0.91}
{'loss': 1.1104, 'grad_norm': 1.6485012261521166, 'learning_rate': 4.529420912524773e-08, 'epoch': 0.91}
{'loss': 1.1127, 'grad_norm': 3.389315682837512, 'learning_rate': 4.516363506866827e-08, 'epoch': 0.91}
{'loss': 1.16, 'grad_norm': 2.1028663023278624, 'learning_rate': 4.503324514474483e-08, 'epoch': 0.91}
{'loss': 1.1042, 'grad_norm': 1.7187201784905757, 'learning_rate': 4.4903039378621945e-08, 'epoch': 0.91}
{'loss': 1.1448, 'grad_norm': 1.8931452796830697, 'learning_rate': 4.477301779540887e-08, 'epoch': 0.91}
{'loss': 1.1197, 'grad_norm': 2.188479136327171, 'learning_rate': 4.4643180420179113e-08, 'epoch': 0.91}
{'loss': 1.1114, 'grad_norm': 1.7264198386628034, 'learning_rate': 4.451352727797109e-08, 'epoch': 0.91}
{'loss': 1.1578, 'grad_norm': 1.6235782545948454, 'learning_rate': 4.4384058393786895e-08, 'epoch': 0.91}
{'loss': 1.126, 'grad_norm': 3.435551300599336, 'learning_rate': 4.425477379259424e-08, 'epoch': 0.91}
{'loss': 1.1509, 'grad_norm': 3.0014782373326767, 'learning_rate': 4.412567349932384e-08, 'epoch': 0.91}
{'loss': 1.1398, 'grad_norm': 1.6276857092930952, 'learning_rate': 4.399675753887244e-08, 'epoch': 0.91}
{'loss': 1.1539, 'grad_norm': 1.8086736734419662, 'learning_rate': 4.386802593609984e-08, 'epoch': 0.91}
{'loss': 1.118, 'grad_norm': 2.7401486873946843, 'learning_rate': 4.37394787158315e-08, 'epoch': 0.91}
 91%|█████▍| 6700/7376 [17:15:26<1:10:16,  6.24s/it]/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py:1898: UserWarning: Positional arg
s are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed
 explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior,
 you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.1441, 'grad_norm': 2.2251449161672534, 'learning_rate': 4.3611115902856044e-08, 'epoch': 0.91}
{'loss': 1.1613, 'grad_norm': 1.971573713303151, 'learning_rate': 4.3482937521928e-08, 'epoch': 0.91}
{'loss': 1.1531, 'grad_norm': 2.5312224507395458, 'learning_rate': 4.335494359776493e-08, 'epoch': 0.91}
{'loss': 1.1199, 'grad_norm': 2.029078211829093, 'learning_rate': 4.322713415504975e-08, 'epoch': 0.91}
{'loss': 1.1056, 'grad_norm': 2.3247817531358907, 'learning_rate': 4.3099509218429416e-08, 'epoch': 0.91}
{'loss': 1.1376, 'grad_norm': 2.1365702865126552, 'learning_rate': 4.297206881251547e-08, 'epoch': 0.91}
{'loss': 1.1532, 'grad_norm': 2.1250640793205022, 'learning_rate': 4.284481296188369e-08, 'epoch': 0.91}
{'loss': 1.1219, 'grad_norm': 4.45908423288674, 'learning_rate': 4.271774169107445e-08, 'epoch': 0.91}
{'loss': 1.1496, 'grad_norm': 1.8942913999265902, 'learning_rate': 4.259085502459236e-08, 'epoch': 0.91}
{'loss': 1.1341, 'grad_norm': 2.224857629050478, 'learning_rate': 4.246415298690653e-08, 'epoch': 0.91}
{'loss': 1.1087, 'grad_norm': 3.370239913957756, 'learning_rate': 4.2337635602450514e-08, 'epoch': 0.91}
{'loss': 1.1361, 'grad_norm': 2.051396100650791, 'learning_rate': 4.2211302895622136e-08, 'epoch': 0.91}
{'loss': 1.1241, 'grad_norm': 1.8729967885577476, 'learning_rate': 4.208515489078368e-08, 'epoch': 0.91}
{'loss': 1.1442, 'grad_norm': 2.6766205245820878, 'learning_rate': 4.19591916122618e-08, 'epoch': 0.91}
{'loss': 1.1198, 'grad_norm': 2.842391656991963, 'learning_rate': 4.18334130843474e-08, 'epoch': 0.91}
{'loss': 1.1715, 'grad_norm': 1.939529707770244, 'learning_rate': 4.1707819331296076e-08, 'epoch': 0.91}
{'loss': 1.146, 'grad_norm': 4.389129614873665, 'learning_rate': 4.158241037732746e-08, 'epoch': 0.91}
{'loss': 1.1404, 'grad_norm': 3.2246100130502358, 'learning_rate': 4.1457186246625863e-08, 'epoch': 0.91}
{'loss': 1.1248, 'grad_norm': 1.6882622199562056, 'learning_rate': 4.133214696333942e-08, 'epoch': 0.91}
{'loss': 1.1367, 'grad_norm': 1.7982039672286283, 'learning_rate': 4.1207292551581284e-08, 'epoch': 0.91}
{'loss': 1.1476, 'grad_norm': 1.9894656594772344, 'learning_rate': 4.1082623035428424e-08, 'epoch': 0.91}
{'loss': 1.1274, 'grad_norm': 1.7034763843194192, 'learning_rate': 4.095813843892259e-08, 'epoch': 0.91}
{'loss': 1.1491, 'grad_norm': 1.8586218884658252, 'learning_rate': 4.08338387860695e-08, 'epoch': 0.91}
{'loss': 1.1541, 'grad_norm': 2.525110793124299, 'learning_rate': 4.0709724100839395e-08, 'epoch': 0.91}
{'loss': 1.1186, 'grad_norm': 3.152723550151487, 'learning_rate': 4.058579440716681e-08, 'epoch': 0.91}
{'loss': 1.1497, 'grad_norm': 5.891425790530256, 'learning_rate': 4.046204972895062e-08, 'epoch': 0.91}
{'loss': 1.153, 'grad_norm': 2.1838556790804766, 'learning_rate': 4.0338490090053966e-08, 'epoch': 0.91}
{'loss': 1.1506, 'grad_norm': 1.92062773796606, 'learning_rate': 4.0215115514304456e-08, 'epoch': 0.91}
{'loss': 1.1499, 'grad_norm': 1.9982728606552977, 'learning_rate': 4.009192602549383e-08, 'epoch': 0.91}
{'loss': 1.1419, 'grad_norm': 2.5402870776406266, 'learning_rate': 3.996892164737819e-08, 'epoch': 0.91}
{'loss': 1.1215, 'grad_norm': 1.95310097232544, 'learning_rate': 3.9846102403678027e-08, 'epoch': 0.91}
{'loss': 1.1826, 'grad_norm': 1.9404171046598466, 'learning_rate': 3.972346831807793e-08, 'epoch': 0.91}
{'loss': 1.1235, 'grad_norm': 10.177903367878796, 'learning_rate': 3.960101941422711e-08, 'epoch': 0.91}
{'loss': 1.1401, 'grad_norm': 2.319576829504312, 'learning_rate': 3.947875571573867e-08, 'epoch': 0.91}
{'loss': 1.154, 'grad_norm': 6.382250682287488, 'learning_rate': 3.93566772461904e-08, 'epoch': 0.91}
{'loss': 1.1428, 'grad_norm': 3.106609920965618, 'learning_rate': 3.923478402912395e-08, 'epoch': 0.91}
{'loss': 1.103, 'grad_norm': 2.150533133388726, 'learning_rate': 3.911307608804582e-08, 'epoch': 0.91}
{'loss': 1.1731, 'grad_norm': 1.5631573668021042, 'learning_rate': 3.899155344642579e-08, 'epoch': 0.91}
{'loss': 1.1423, 'grad_norm': 1.8374147334362587, 'learning_rate': 3.887021612769936e-08, 'epoch': 0.91}
{'loss': 1.1267, 'grad_norm': 1.5724103422967883, 'learning_rate': 3.8749064155264685e-08, 'epoch': 0.91}
{'loss': 1.1376, 'grad_norm': 1.5937695420165996, 'learning_rate': 3.862809755248564e-08, 'epoch': 0.91}
{'loss': 1.1185, 'grad_norm': 1.9586743358670977, 'learning_rate': 3.850731634268911e-08, 'epoch': 0.91}
{'loss': 1.1577, 'grad_norm': 2.0042061126677035, 'learning_rate': 3.838672054916725e-08, 'epoch': 0.91}
{'loss': 1.1373, 'grad_norm': 2.0969132607015277, 'learning_rate': 3.826631019517568e-08, 'epoch': 0.91}
{'loss': 1.1771, 'grad_norm': 2.5644128888915603, 'learning_rate': 3.814608530393493e-08, 'epoch': 0.91}
{'loss': 1.1467, 'grad_norm': 2.6036624015569116, 'learning_rate': 3.802604589862912e-08, 'epoch': 0.91}
{'loss': 1.098, 'grad_norm': 1.670205811967, 'learning_rate': 3.790619200240697e-08, 'epoch': 0.91}
{'loss': 1.1417, 'grad_norm': 1.7127575021340928, 'learning_rate': 3.7786523638381306e-08, 'epoch': 0.91}
{'loss': 1.1599, 'grad_norm': 1.6776741841280904, 'learning_rate': 3.766704082962935e-08, 'epoch': 0.91}
{'loss': 1.1622, 'grad_norm': 1.807898442740659, 'learning_rate': 3.754774359919244e-08, 'epoch': 0.92}
{'loss': 1.1574, 'grad_norm': 1.6467925965655623, 'learning_rate': 3.7428631970076065e-08, 'epoch': 0.92}
{'loss': 1.1353, 'grad_norm': 1.917071630693933, 'learning_rate': 3.730970596524985e-08, 'epoch': 0.92}
{'loss': 1.1107, 'grad_norm': 2.046378326439752, 'learning_rate': 3.719096560764778e-08, 'epoch': 0.92}
{'loss': 1.1154, 'grad_norm': 2.0481151952768686, 'learning_rate': 3.707241092016811e-08, 'epoch': 0.92}
{'loss': 1.1679, 'grad_norm': 1.7127272574589487, 'learning_rate': 3.69540419256732e-08, 'epoch': 0.92}
{'loss': 1.17, 'grad_norm': 1.7772297205583394, 'learning_rate': 3.683585864698946e-08, 'epoch': 0.92}
{'loss': 1.1487, 'grad_norm': 1.6159590743781607, 'learning_rate': 3.6717861106907447e-08, 'epoch': 0.92}
{'loss': 1.1042, 'grad_norm': 1.8259846693584356, 'learning_rate': 3.66000493281825e-08, 'epoch': 0.92}
{'loss': 1.142, 'grad_norm': 1.9623037182725351, 'learning_rate': 3.648242333353324e-08, 'epoch': 0.92}
{'loss': 1.1425, 'grad_norm': 3.2422427216206575, 'learning_rate': 3.6364983145643066e-08, 'epoch': 0.92}
{'loss': 1.1378, 'grad_norm': 2.1503040391854777, 'learning_rate': 3.624772878715954e-08, 'epoch': 0.92}
{'loss': 1.0864, 'grad_norm': 2.3688964824272816, 'learning_rate': 3.6130660280694005e-08, 'epoch': 0.92}
{'loss': 1.0992, 'grad_norm': 2.2323044522078486, 'learning_rate': 3.6013777648822406e-08, 'epoch': 0.92}
{'loss': 1.1435, 'grad_norm': 1.811161660560687, 'learning_rate': 3.58970809140845e-08, 'epoch': 0.92}
{'loss': 1.1552, 'grad_norm': 1.7565840607616288, 'learning_rate': 3.5780570098984273e-08, 'epoch': 0.92}
{'loss': 1.142, 'grad_norm': 2.8560792460807276, 'learning_rate': 3.5664245225990206e-08, 'epoch': 0.92}
{'loss': 1.1406, 'grad_norm': 3.052114712161826, 'learning_rate': 3.554810631753436e-08, 'epoch': 0.92}
{'loss': 1.1301, 'grad_norm': 1.579131655898127, 'learning_rate': 3.543215339601324e-08, 'epoch': 0.92}
{'loss': 1.1077, 'grad_norm': 1.6184266285785587, 'learning_rate': 3.531638648378754e-08, 'epoch': 0.92}
{'loss': 1.1424, 'grad_norm': 2.237218027919577, 'learning_rate': 3.520080560318195e-08, 'epoch': 0.92}
{'loss': 1.1859, 'grad_norm': 1.7733242148302064, 'learning_rate': 3.508541077648541e-08, 'epoch': 0.92}
{'loss': 1.1288, 'grad_norm': 1.8756202306463075, 'learning_rate': 3.497020202595069e-08, 'epoch': 0.92}
{'loss': 1.1188, 'grad_norm': 1.5612943356511677, 'learning_rate': 3.485517937379512e-08, 'epoch': 0.92}
{'loss': 1.1259, 'grad_norm': 1.9822898368698996, 'learning_rate': 3.474034284219995e-08, 'epoch': 0.92}
{'loss': 1.1383, 'grad_norm': 1.8980818055545816, 'learning_rate': 3.462569245331004e-08, 'epoch': 0.92}
{'loss': 1.1124, 'grad_norm': 1.7659213500819209, 'learning_rate': 3.451122822923547e-08, 'epoch': 0.92}
{'loss': 1.0907, 'grad_norm': 2.1420286865167, 'learning_rate': 3.4396950192049134e-08, 'epoch': 0.92}
{'loss': 1.1104, 'grad_norm': 1.7397366423522125, 'learning_rate': 3.4282858363789194e-08, 'epoch': 0.92}
{'loss': 1.134, 'grad_norm': 4.048698982777152, 'learning_rate': 3.4168952766456924e-08, 'epoch': 0.92}
{'loss': 1.1227, 'grad_norm': 2.3218781437866847, 'learning_rate': 3.405523342201855e-08, 'epoch': 0.92}
{'loss': 1.1656, 'grad_norm': 2.97876038378886, 'learning_rate': 3.39417003524034e-08, 'epoch': 0.92}
{'loss': 1.1236, 'grad_norm': 1.8402537013654527, 'learning_rate': 3.3828353579505975e-08, 'epoch': 0.92}
{'loss': 1.16, 'grad_norm': 1.751309305858762, 'learning_rate': 3.3715193125184005e-08, 'epoch': 0.92}
{'loss': 1.1229, 'grad_norm': 2.044409515282348, 'learning_rate': 3.3602219011259595e-08, 'epoch': 0.92}
{'loss': 1.1342, 'grad_norm': 1.951260092938747, 'learning_rate': 3.3489431259518975e-08, 'epoch': 0.92}
{'loss': 1.1753, 'grad_norm': 2.186052273908093, 'learning_rate': 3.337682989171242e-08, 'epoch': 0.92}
{'loss': 1.0976, 'grad_norm': 2.427809461362353, 'learning_rate': 3.326441492955412e-08, 'epoch': 0.92}
{'loss': 1.1411, 'grad_norm': 1.990865647139709, 'learning_rate': 3.3152186394722506e-08, 'epoch': 0.92}
{'loss': 1.1544, 'grad_norm': 2.2732316454494046, 'learning_rate': 3.304014430885982e-08, 'epoch': 0.92}
{'loss': 1.1686, 'grad_norm': 1.6686973102120475, 'learning_rate': 3.292828869357267e-08, 'epoch': 0.92}
{'loss': 1.1588, 'grad_norm': 1.5426195116262198, 'learning_rate': 3.281661957043147e-08, 'epoch': 0.92}
{'loss': 1.1492, 'grad_norm': 1.7696359493689175, 'learning_rate': 3.270513696097055e-08, 'epoch': 0.92}
{'loss': 1.1289, 'grad_norm': 1.750511394979674, 'learning_rate': 3.2593840886688815e-08, 'epoch': 0.92}
{'loss': 1.1257, 'grad_norm': 2.848300440391529, 'learning_rate': 3.248273136904844e-08, 'epoch': 0.92}
{'loss': 1.1397, 'grad_norm': 1.98093897571148, 'learning_rate': 3.23718084294764e-08, 'epoch': 0.92}
{'loss': 1.1115, 'grad_norm': 1.6123166048598938, 'learning_rate': 3.226107208936279e-08, 'epoch': 0.92}
{'loss': 1.1136, 'grad_norm': 2.0196969107777507, 'learning_rate': 3.2150522370062886e-08, 'epoch': 0.92}
{'loss': 1.1422, 'grad_norm': 1.8613624302227993, 'learning_rate': 3.204015929289483e-08, 'epoch': 0.92}
{'loss': 1.1419, 'grad_norm': 1.7810486443904543, 'learning_rate': 3.1929982879141613e-08, 'epoch': 0.92}
{'loss': 1.1091, 'grad_norm': 1.7129776309861038, 'learning_rate': 3.181999315004946e-08, 'epoch': 0.92}
 92%|███████▍| 6800/7376 [17:29:49<58:43,  6.12s/it]/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py:1898: UserWarning: Positional arg
s are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packa
ges/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_re
entrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details
 on the differences between the two variants.
  warnings.warn(
{'loss': 1.1579, 'grad_norm': 1.7204309514291232, 'learning_rate': 3.171019012682952e-08, 'epoch': 0.92}
{'loss': 1.1164, 'grad_norm': 2.22523272633456, 'learning_rate': 3.160057383065606e-08, 'epoch': 0.92}
{'loss': 1.1498, 'grad_norm': 2.0148327423351775, 'learning_rate': 3.149114428266786e-08, 'epoch': 0.92}
{'loss': 1.1331, 'grad_norm': 1.776210426508428, 'learning_rate': 3.138190150396758e-08, 'epoch': 0.92}
{'loss': 1.1786, 'grad_norm': 1.7950243100049472, 'learning_rate': 3.1272845515621816e-08, 'epoch': 0.92}
{'loss': 1.1465, 'grad_norm': 1.9109759083167919, 'learning_rate': 3.116397633866108e-08, 'epoch': 0.92}
{'loss': 1.1497, 'grad_norm': 1.771218505107996, 'learning_rate': 3.1055293994080024e-08, 'epoch': 0.92}
{'loss': 1.1814, 'grad_norm': 2.437395680128072, 'learning_rate': 3.09467985028371e-08, 'epoch': 0.92}
{'loss': 1.1417, 'grad_norm': 2.2110223094988495, 'learning_rate': 3.08384898858548e-08, 'epoch': 0.92}
{'loss': 1.1444, 'grad_norm': 2.0199221953603197, 'learning_rate': 3.073036816401975e-08, 'epoch': 0.92}
{'loss': 1.116, 'grad_norm': 4.3340064602782675, 'learning_rate': 3.062243335818215e-08, 'epoch': 0.92}
{'loss': 1.1371, 'grad_norm': 1.726484029838967, 'learning_rate': 3.051468548915648e-08, 'epoch': 0.92}
{'loss': 1.1411, 'grad_norm': 1.8185202444177868, 'learning_rate': 3.04071245777211e-08, 'epoch': 0.92}
{'loss': 1.1076, 'grad_norm': 3.3429491674859237, 'learning_rate': 3.0299750644618205e-08, 'epoch': 0.92}
{'loss': 1.1458, 'grad_norm': 2.5038977779091525, 'learning_rate': 3.019256371055423e-08, 'epoch': 0.92}
{'loss': 1.1735, 'grad_norm': 2.4657391865545706, 'learning_rate': 3.0085563796198866e-08, 'epoch': 0.92}
{'loss': 1.1331, 'grad_norm': 1.9884787925324277, 'learning_rate': 2.997875092218671e-08, 'epoch': 0.92}
{'loss': 1.1348, 'grad_norm': 1.7716327427950362, 'learning_rate': 2.987212510911541e-08, 'epoch': 0.92}
{'loss': 1.1293, 'grad_norm': 6.269151175891285, 'learning_rate': 2.976568637754717e-08, 'epoch': 0.92}
{'loss': 1.0671, 'grad_norm': 2.047245238254759, 'learning_rate': 2.9659434748007696e-08, 'epoch': 0.92}
{'loss': 1.116, 'grad_norm': 1.6816327095543238, 'learning_rate': 2.9553370240986808e-08, 'epoch': 0.92}
{'loss': 1.1438, 'grad_norm': 2.327560928863812, 'learning_rate': 2.944749287693815e-08, 'epoch': 0.92}
{'loss': 1.1396, 'grad_norm': 2.9062100778391637, 'learning_rate': 2.9341802676279505e-08, 'epoch': 0.92}
{'loss': 1.1216, 'grad_norm': 1.8039429394412034, 'learning_rate': 2.923629965939234e-08, 'epoch': 0.93}
{'loss': 1.0967, 'grad_norm': 1.8127809456494959, 'learning_rate': 2.913098384662205e-08, 'epoch': 0.93}
{'loss': 1.1411, 'grad_norm': 1.8277794425893759, 'learning_rate': 2.902585525827783e-08, 'epoch': 0.93}
{'loss': 1.1316, 'grad_norm': 3.8828209027243474, 'learning_rate': 2.8920913914633138e-08, 'epoch': 0.93}
{'loss': 1.1547, 'grad_norm': 3.178378394793029, 'learning_rate': 2.881615983592489e-08, 'epoch': 0.93}
{'loss': 1.1213, 'grad_norm': 1.6133305815922394, 'learning_rate': 2.8711593042354154e-08, 'epoch': 0.93}
{'loss': 1.1318, 'grad_norm': 1.8087989045534467, 'learning_rate': 2.8607213554086018e-08, 'epoch': 0.93}
{'loss': 1.1466, 'grad_norm': 2.866951810474464, 'learning_rate': 2.8503021391248718e-08, 'epoch': 0.93}
{'loss': 1.1625, 'grad_norm': 2.082200122855003, 'learning_rate': 2.839901657393551e-08, 'epoch': 0.93}
{'loss': 1.1207, 'grad_norm': 1.5106208523740738, 'learning_rate': 2.829519912220235e-08, 'epoch': 0.93}
{'loss': 1.1832, 'grad_norm': 1.5158302703618614, 'learning_rate': 2.819156905607012e-08, 'epoch': 0.93}
{'loss': 1.1349, 'grad_norm': 2.084230626346103, 'learning_rate': 2.8088126395522495e-08, 'epoch': 0.93}
{'loss': 1.0957, 'grad_norm': 1.8562191838890199, 'learning_rate': 2.7984871160508185e-08, 'epoch': 0.93}
{'loss': 1.1272, 'grad_norm': 2.088886053574346, 'learning_rate': 2.7881803370938595e-08, 'epoch': 0.93}
{'loss': 1.1504, 'grad_norm': 1.5848438232636406, 'learning_rate': 2.777892304669005e-08, 'epoch': 0.93}
{'loss': 1.1905, 'grad_norm': 1.831691446207229, 'learning_rate': 2.7676230207601793e-08, 'epoch': 0.93}
{'loss': 1.1293, 'grad_norm': 3.28745843023518, 'learning_rate': 2.757372487347753e-08, 'epoch': 0.93}
{'loss': 1.1547, 'grad_norm': 1.6548176560435084, 'learning_rate': 2.747140706408446e-08, 'epoch': 0.93}
{'loss': 1.156, 'grad_norm': 2.128323728474654, 'learning_rate': 2.7369276799154017e-08, 'epoch': 0.93}
{'loss': 1.1291, 'grad_norm': 1.9018231023899768, 'learning_rate': 2.7267334098381e-08, 'epoch': 0.93}
{'loss': 1.1583, 'grad_norm': 1.8560482886284062, 'learning_rate': 2.7165578981424354e-08, 'epoch': 0.93}
{'loss': 1.1368, 'grad_norm': 1.95529296343071, 'learning_rate': 2.70640114679066e-08, 'epoch': 0.93}
{'loss': 1.1686, 'grad_norm': 1.6269638532701818, 'learning_rate': 2.696263157741441e-08, 'epoch': 0.93}
{'loss': 1.1527, 'grad_norm': 1.675691674172511, 'learning_rate': 2.6861439329498026e-08, 'epoch': 0.93}
{'loss': 1.1375, 'grad_norm': 1.9707502021410623, 'learning_rate': 2.6760434743671623e-08, 'epoch': 0.93}
{'loss': 1.151, 'grad_norm': 1.7404616024522532, 'learning_rate': 2.665961783941306e-08, 'epoch': 0.93}
{'loss': 1.1391, 'grad_norm': 1.835193279327664, 'learning_rate': 2.6558988636164127e-08, 'epoch': 0.93}
{'loss': 1.1539, 'grad_norm': 1.6991882002803618, 'learning_rate': 2.645854715333029e-08, 'epoch': 0.93}
{'loss': 1.1386, 'grad_norm': 1.962438970804226, 'learning_rate': 2.6358293410281062e-08, 'epoch': 0.93}
{'loss': 1.1405, 'grad_norm': 2.178803325814055, 'learning_rate': 2.6258227426349533e-08, 'epoch': 0.93}
{'loss': 1.1296, 'grad_norm': 1.762549554054437, 'learning_rate': 2.6158349220832375e-08, 'epoch': 0.93}
{'loss': 1.1039, 'grad_norm': 3.4493844744436912, 'learning_rate': 2.605865881299074e-08, 'epoch': 0.93}
{'loss': 1.1568, 'grad_norm': 1.925040637453337, 'learning_rate': 2.5959156222048805e-08, 'epoch': 0.93}
{'loss': 1.1309, 'grad_norm': 4.34685512108383, 'learning_rate': 2.585984146719511e-08, 'epoch': 0.93}
{'loss': 1.1608, 'grad_norm': 3.3031479786372784, 'learning_rate': 2.5760714567581554e-08, 'epoch': 0.93}
{'loss': 1.1134, 'grad_norm': 1.739838771242186, 'learning_rate': 2.566177554232396e-08, 'epoch': 0.93}
{'loss': 1.1505, 'grad_norm': 1.9571368010333459, 'learning_rate': 2.5563024410501954e-08, 'epoch': 0.93}
{'loss': 1.1669, 'grad_norm': 1.717404957919265, 'learning_rate': 2.546446119115908e-08, 'epoch': 0.93}
{'loss': 1.1656, 'grad_norm': 2.537868329941339, 'learning_rate': 2.5366085903302247e-08, 'epoch': 0.93}
{'loss': 1.0956, 'grad_norm': 1.9643660254556317, 'learning_rate': 2.5267898565902503e-08, 'epoch': 0.93}
{'loss': 1.1183, 'grad_norm': 1.7869932097113084, 'learning_rate': 2.5169899197894363e-08, 'epoch': 0.93}
{'loss': 1.1464, 'grad_norm': 1.901733352324411, 'learning_rate': 2.507208781817638e-08, 'epoch': 0.93}
{'loss': 1.1511, 'grad_norm': 2.3651970921871714, 'learning_rate': 2.4974464445610688e-08, 'epoch': 0.93}
{'loss': 1.1262, 'grad_norm': 1.8103947369626654, 'learning_rate': 2.4877029099023116e-08, 'epoch': 0.93}
{'loss': 1.1345, 'grad_norm': 1.8280264985419534, 'learning_rate': 2.4779781797203303e-08, 'epoch': 0.93}
{'loss': 1.1009, 'grad_norm': 1.8218317969386808, 'learning_rate': 2.468272255890469e-08, 'epoch': 0.93}
{'loss': 1.1107, 'grad_norm': 1.7932746614402184, 'learning_rate': 2.4585851402844305e-08, 'epoch': 0.93}
{'loss': 1.1533, 'grad_norm': 2.542615210765025, 'learning_rate': 2.4489168347703093e-08, 'epoch': 0.93}
{'loss': 1.1304, 'grad_norm': 1.7745052020229946, 'learning_rate': 2.4392673412125476e-08, 'epoch': 0.93}
{'loss': 1.1403, 'grad_norm': 2.078624031567002, 'learning_rate': 2.429636661472001e-08, 'epoch': 0.93}
{'loss': 1.1289, 'grad_norm': 2.7216472384038726, 'learning_rate': 2.4200247974058175e-08, 'epoch': 0.93}
{'loss': 1.1503, 'grad_norm': 1.711170297561451, 'learning_rate': 2.4104317508676363e-08, 'epoch': 0.93}
{'loss': 1.156, 'grad_norm': 1.862530584499513, 'learning_rate': 2.4008575237073335e-08, 'epoch': 0.93}
{'loss': 1.1451, 'grad_norm': 2.2103852909149557, 'learning_rate': 2.3913021177712876e-08, 'epoch': 0.93}
{'loss': 1.1445, 'grad_norm': 2.4456831800011845, 'learning_rate': 2.3817655349021247e-08, 'epoch': 0.93}
{'loss': 1.1304, 'grad_norm': 1.9492494143784334, 'learning_rate': 2.3722477769389515e-08, 'epoch': 0.93}
{'loss': 1.143, 'grad_norm': 2.4696454206086953, 'learning_rate': 2.362748845717155e-08, 'epoch': 0.93}
{'loss': 1.1087, 'grad_norm': 2.363083109531296, 'learning_rate': 2.3532687430685373e-08, 'epoch': 0.93}
{'loss': 1.144, 'grad_norm': 1.9165571429815318, 'learning_rate': 2.3438074708212795e-08, 'epoch': 0.93}
{'loss': 1.1076, 'grad_norm': 1.6980258655677667, 'learning_rate': 2.3343650307998896e-08, 'epoch': 0.93}
{'loss': 1.1799, 'grad_norm': 2.2308221747683175, 'learning_rate': 2.3249414248252775e-08, 'epoch': 0.93}
{'loss': 1.1463, 'grad_norm': 1.6699595482536234, 'learning_rate': 2.3155366547147115e-08, 'epoch': 0.93}
{'loss': 1.1203, 'grad_norm': 2.452585204522459, 'learning_rate': 2.30615072228183e-08, 'epoch': 0.93}
{'loss': 1.0882, 'grad_norm': 1.7403767397338177, 'learning_rate': 2.2967836293366405e-08, 'epoch': 0.93}
{'loss': 1.1397, 'grad_norm': 1.7467343294237476, 'learning_rate': 2.287435377685498e-08, 'epoch': 0.93}
{'loss': 1.1608, 'grad_norm': 1.9557078302268331, 'learning_rate': 2.2781059691311498e-08, 'epoch': 0.93}
{'loss': 1.1576, 'grad_norm': 2.902787786547701, 'learning_rate': 2.268795405472701e-08, 'epoch': 0.93}
{'loss': 1.1644, 'grad_norm': 2.290168789714428, 'learning_rate': 2.259503688505593e-08, 'epoch': 0.93}
{'loss': 1.1184, 'grad_norm': 1.8939687482467362, 'learning_rate': 2.2502308200217037e-08, 'epoch': 0.93}
{'loss': 1.1189, 'grad_norm': 1.6797150465376367, 'learning_rate': 2.2409768018092024e-08, 'epoch': 0.93}
{'loss': 1.116, 'grad_norm': 1.8576885246249426, 'learning_rate': 2.231741635652673e-08, 'epoch': 0.93}
{'loss': 1.1118, 'grad_norm': 1.535018694439724, 'learning_rate': 2.222525323333013e-08, 'epoch': 0.93}
{'loss': 1.1472, 'grad_norm': 2.1188028927618285, 'learning_rate': 2.2133278666275567e-08, 'epoch': 0.93}
{'loss': 1.1507, 'grad_norm': 1.8670034207217914, 'learning_rate': 2.2041492673099182e-08, 'epoch': 0.93}
{'loss': 1.1046, 'grad_norm': 1.8946151025241826, 'learning_rate': 2.1949895271501596e-08, 'epoch': 0.94}
{'loss': 1.1294, 'grad_norm': 2.6975917300713292, 'learning_rate': 2.1858486479146344e-08, 'epoch': 0.94}
{'loss': 1.1483, 'grad_norm': 1.735319367240506, 'learning_rate': 2.1767266313661102e-08, 'epoch': 0.94}
 94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏        | 6900/7376 [17:44:48<48:35,  6.13s/it]
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py:1898: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to
 https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed
 explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior,
 you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.145, 'grad_norm': 1.7995553989055044, 'learning_rate': 2.1676234792636693e-08, 'epoch': 0.94}
{'loss': 1.1067, 'grad_norm': 1.7732586655078162, 'learning_rate': 2.1585391933628073e-08, 'epoch': 0.94}
{'loss': 1.173, 'grad_norm': 2.0226701692941944, 'learning_rate': 2.1494737754153558e-08, 'epoch': 0.94}
{'loss': 1.1586, 'grad_norm': 1.7891232941482291, 'learning_rate': 2.1404272271694945e-08, 'epoch': 0.94}
{'loss': 1.1458, 'grad_norm': 1.5961686547486846, 'learning_rate': 2.1313995503697833e-08, 'epoch': 0.94}
{'loss': 1.1498, 'grad_norm': 3.000187444611773, 'learning_rate': 2.122390746757141e-08, 'epoch': 0.94}
{'loss': 1.1318, 'grad_norm': 1.9142283780630402, 'learning_rate': 2.1134008180688445e-08, 'epoch': 0.94}
{'loss': 1.1549, 'grad_norm': 1.6876385532871037, 'learning_rate': 2.1044297660385292e-08, 'epoch': 0.94}
{'loss': 1.1349, 'grad_norm': 1.4891656539128921, 'learning_rate': 2.0954775923961997e-08, 'epoch': 0.94}
{'loss': 1.1643, 'grad_norm': 1.862896655631254, 'learning_rate': 2.086544298868198e-08, 'epoch': 0.94}
{'loss': 1.1662, 'grad_norm': 1.8456062238871969, 'learning_rate': 2.077629887177257e-08, 'epoch': 0.94}
{'loss': 1.1072, 'grad_norm': 1.924071625404914, 'learning_rate': 2.0687343590424232e-08, 'epoch': 0.94}
{'loss': 1.1237, 'grad_norm': 1.7592654598353512, 'learning_rate': 2.0598577161791587e-08, 'epoch': 0.94}
{'loss': 1.1699, 'grad_norm': 2.369608943034893, 'learning_rate': 2.050999960299249e-08, 'epoch': 0.94}
{'loss': 1.191, 'grad_norm': 1.8822085786386176, 'learning_rate': 2.0421610931108168e-08, 'epoch': 0.94}
{'loss': 1.1198, 'grad_norm': 1.9877700447920412, 'learning_rate': 2.033341116318399e-08, 'epoch': 0.94}
{'loss': 1.1495, 'grad_norm': 2.0870354093419787, 'learning_rate': 2.0245400316228344e-08, 'epoch': 0.94}
{'loss': 1.1302, 'grad_norm': 2.4777632547636173, 'learning_rate': 2.015757840721366e-08, 'epoch': 0.94}
{'loss': 1.119, 'grad_norm': 1.7908763790691276, 'learning_rate': 2.006994545307539e-08, 'epoch': 0.94}
{'loss': 1.1272, 'grad_norm': 3.774737456799614, 'learning_rate': 1.998250147071323e-08, 'epoch': 0.94}
{'loss': 1.1463, 'grad_norm': 2.8303396722741243, 'learning_rate': 1.9895246476989703e-08, 'epoch': 0.94}
{'loss': 1.1539, 'grad_norm': 1.8664219190330837, 'learning_rate': 1.9808180488731564e-08, 'epoch': 0.94}
{'loss': 1.1579, 'grad_norm': 1.688992586889786, 'learning_rate': 1.9721303522728605e-08, 'epoch': 0.94}
{'loss': 1.1422, 'grad_norm': 1.8772836316430965, 'learning_rate': 1.9634615595734316e-08, 'epoch': 0.94}
{'loss': 1.132, 'grad_norm': 1.7489675838451046, 'learning_rate': 1.954811672446599e-08, 'epoch': 0.94}
{'loss': 1.1551, 'grad_norm': 2.26611186751172, 'learning_rate': 1.9461806925604064e-08, 'epoch': 0.94}
{'loss': 1.1057, 'grad_norm': 2.103901723259491, 'learning_rate': 1.9375686215792886e-08, 'epoch': 0.94}
{'loss': 1.1359, 'grad_norm': 2.713724088499566, 'learning_rate': 1.9289754611639954e-08, 'epoch': 0.94}
{'loss': 1.1317, 'grad_norm': 2.033421066145491, 'learning_rate': 1.9204012129716672e-08, 'epoch': 0.94}
{'loss': 1.1398, 'grad_norm': 2.2059877715820635, 'learning_rate': 1.911845878655749e-08, 'epoch': 0.94}
{'loss': 1.1076, 'grad_norm': 1.7752555490244546, 'learning_rate': 1.9033094598661204e-08, 'epoch': 0.94}
{'loss': 1.1489, 'grad_norm': 3.2471027977685547, 'learning_rate': 1.89479195824892e-08, 'epoch': 0.94}
{'loss': 1.1839, 'grad_norm': 5.440286132529354, 'learning_rate': 1.8862933754467013e-08, 'epoch': 0.94}
{'loss': 1.1501, 'grad_norm': 1.7355356364704846, 'learning_rate': 1.8778137130983307e-08, 'epoch': 0.94}
{'loss': 1.173, 'grad_norm': 1.919402699262792, 'learning_rate': 1.8693529728390667e-08, 'epoch': 0.94}
{'loss': 1.098, 'grad_norm': 1.7316093233571355, 'learning_rate': 1.860911156300482e-08, 'epoch': 0.94}
{'loss': 1.0817, 'grad_norm': 3.284965697888466, 'learning_rate': 1.8524882651105188e-08, 'epoch': 0.94}
{'loss': 1.1013, 'grad_norm': 2.1472700068977026, 'learning_rate': 1.844084300893456e-08, 'epoch': 0.94}
{'loss': 1.1463, 'grad_norm': 1.9840750576210957, 'learning_rate': 1.835699265269963e-08, 'epoch': 0.94}
{'loss': 1.1719, 'grad_norm': 2.1738906294926346, 'learning_rate': 1.827333159856981e-08, 'epoch': 0.94}
{'loss': 1.1608, 'grad_norm': 2.0308316207471933, 'learning_rate': 1.8189859862678848e-08, 'epoch': 0.94}
{'loss': 1.1122, 'grad_norm': 1.9370863539363992, 'learning_rate': 1.8106577461123428e-08, 'epoch': 0.94}
{'loss': 1.1362, 'grad_norm': 2.203339329233159, 'learning_rate': 1.802348440996393e-08, 'epoch': 0.94}
{'loss': 1.1469, 'grad_norm': 1.9416454441657267, 'learning_rate': 1.794058072522431e-08, 'epoch': 0.94}
{'loss': 1.1662, 'grad_norm': 2.846051036813186, 'learning_rate': 1.7857866422891665e-08, 'epoch': 0.94}
{'loss': 1.1596, 'grad_norm': 1.779798083380636, 'learning_rate': 1.777534151891702e-08, 'epoch': 0.94}
{'loss': 1.1329, 'grad_norm': 2.363044545138007, 'learning_rate': 1.7693006029214418e-08, 'epoch': 0.94}
{'loss': 1.1166, 'grad_norm': 2.7061875879634267, 'learning_rate': 1.7610859969661827e-08, 'epoch': 0.94}
{'loss': 1.125, 'grad_norm': 2.194515223505337, 'learning_rate': 1.7528903356100466e-08, 'epoch': 0.94}
{'loss': 1.135, 'grad_norm': 1.8195470780970924, 'learning_rate': 1.74471362043348e-08, 'epoch': 0.94}
{'loss': 1.1218, 'grad_norm': 2.7612413581298583, 'learning_rate': 1.7365558530133218e-08, 'epoch': 0.94}
{'loss': 1.1172, 'grad_norm': 3.2266513314366225, 'learning_rate': 1.7284170349227246e-08, 'epoch': 0.94}
{'loss': 1.0933, 'grad_norm': 3.5159798617210134, 'learning_rate': 1.7202971677311774e-08, 'epoch': 0.94}
{'loss': 1.1615, 'grad_norm': 3.5327038355153424, 'learning_rate': 1.712196253004572e-08, 'epoch': 0.94}
{'loss': 1.1531, 'grad_norm': 1.7585772719278248, 'learning_rate': 1.704114292305059e-08, 'epoch': 0.94}
{'loss': 1.1168, 'grad_norm': 1.86877238984571, 'learning_rate': 1.6960512871912246e-08, 'epoch': 0.94}
{'loss': 1.1307, 'grad_norm': 1.6819469991223563, 'learning_rate': 1.6880072392179146e-08, 'epoch': 0.94}
{'loss': 1.145, 'grad_norm': 2.7747726876746706, 'learning_rate': 1.6799821499363987e-08, 'epoch': 0.94}
{'loss': 1.1357, 'grad_norm': 1.7290762828703408, 'learning_rate': 1.671976020894228e-08, 'epoch': 0.94}
{'loss': 1.1295, 'grad_norm': 1.8228748559075059, 'learning_rate': 1.663988853635323e-08, 'epoch': 0.94}
{'loss': 1.1658, 'grad_norm': 2.2142945637365887, 'learning_rate': 1.6560206496999517e-08, 'epoch': 0.94}
{'loss': 1.1178, 'grad_norm': 3.020636043307101, 'learning_rate': 1.6480714106247186e-08, 'epoch': 0.94}
{'loss': 1.1615, 'grad_norm': 1.6941810237411519, 'learning_rate': 1.6401411379425746e-08, 'epoch': 0.94}
{'loss': 1.0874, 'grad_norm': 1.5446260933398057, 'learning_rate': 1.6322298331827967e-08, 'epoch': 0.94}
{'loss': 1.1801, 'grad_norm': 1.8234866414264035, 'learning_rate': 1.624337497871042e-08, 'epoch': 0.94}
{'loss': 1.0911, 'grad_norm': 1.754968326877625, 'learning_rate': 1.6164641335292606e-08, 'epoch': 0.94}
{'loss': 1.1802, 'grad_norm': 1.8336802197995663, 'learning_rate': 1.6086097416757816e-08, 'epoch': 0.94}
{'loss': 1.1052, 'grad_norm': 2.0802067344766404, 'learning_rate': 1.60077432382526e-08, 'epoch': 0.94}
{'loss': 1.106, 'grad_norm': 4.72101787165864, 'learning_rate': 1.5929578814886878e-08, 'epoch': 0.94}
{'loss': 1.1445, 'grad_norm': 1.8141055611958274, 'learning_rate': 1.5851604161734256e-08, 'epoch': 0.94}
{'loss': 1.1252, 'grad_norm': 1.8216916805665189, 'learning_rate': 1.5773819293831148e-08, 'epoch': 0.95}
{'loss': 1.12, 'grad_norm': 2.2372030621021133, 'learning_rate': 1.5696224226178224e-08, 'epoch': 0.95}
{'loss': 1.1779, 'grad_norm': 2.205413499010483, 'learning_rate': 1.5618818973738625e-08, 'epoch': 0.95}
{'loss': 1.0964, 'grad_norm': 1.9440829633253416, 'learning_rate': 1.554160355143974e-08, 'epoch': 0.95}
{'loss': 1.1126, 'grad_norm': 2.002965530141726, 'learning_rate': 1.5464577974171554e-08, 'epoch': 0.95}
{'loss': 1.1808, 'grad_norm': 1.7901586764242787, 'learning_rate': 1.5387742256788294e-08, 'epoch': 0.95}
{'loss': 1.1412, 'grad_norm': 2.2703274387346837, 'learning_rate': 1.531109641410666e-08, 'epoch': 0.95}
{'loss': 1.1217, 'grad_norm': 1.6001567846534281, 'learning_rate': 1.523464046090761e-08, 'epoch': 0.95}
{'loss': 1.1257, 'grad_norm': 1.6990621409752729, 'learning_rate': 1.5158374411934793e-08, 'epoch': 0.95}
{'loss': 1.1106, 'grad_norm': 1.669524103608102, 'learning_rate': 1.5082298281895666e-08, 'epoch': 0.95}
{'loss': 1.113, 'grad_norm': 1.5863239390742812, 'learning_rate': 1.500641208546072e-08, 'epoch': 0.95}
{'loss': 1.1523, 'grad_norm': 4.280678976862245, 'learning_rate': 1.493071583726424e-08, 'epoch': 0.95}
{'loss': 1.1463, 'grad_norm': 2.0488304767090084, 'learning_rate': 1.4855209551903559e-08, 'epoch': 0.95}
{'loss': 1.1437, 'grad_norm': 2.0439372347140323, 'learning_rate': 1.4779893243939356e-08, 'epoch': 0.95}
{'loss': 1.1714, 'grad_norm': 3.0399210180305802, 'learning_rate': 1.4704766927895907e-08, 'epoch': 0.95}
{'loss': 1.0996, 'grad_norm': 1.9515203524608462, 'learning_rate': 1.462983061826084e-08, 'epoch': 0.95}
{'loss': 1.1608, 'grad_norm': 2.5086691871497613, 'learning_rate': 1.4555084329484713e-08, 'epoch': 0.95}
{'loss': 1.1496, 'grad_norm': 1.8233217193573024, 'learning_rate': 1.4480528075982102e-08, 'epoch': 0.95}
{'loss': 1.1581, 'grad_norm': 2.0718632925361526, 'learning_rate': 1.4406161872130396e-08, 'epoch': 0.95}
{'loss': 1.154, 'grad_norm': 1.7648878389501153, 'learning_rate': 1.4331985732270457e-08, 'epoch': 0.95}
{'loss': 1.1686, 'grad_norm': 1.848753289491071, 'learning_rate': 1.4257999670706844e-08, 'epoch': 0.95}
{'loss': 1.0974, 'grad_norm': 1.6152853496607054, 'learning_rate': 1.418420370170681e-08, 'epoch': 0.95}
{'loss': 1.1417, 'grad_norm': 2.013960122478299, 'learning_rate': 1.4110597839501748e-08, 'epoch': 0.95}
{'loss': 1.1446, 'grad_norm': 2.684719916886598, 'learning_rate': 1.4037182098285639e-08, 'epoch': 0.95}
{'loss': 1.1754, 'grad_norm': 3.008734320871962, 'learning_rate': 1.3963956492216377e-08, 'epoch': 0.95}
{'loss': 1.1248, 'grad_norm': 3.4852794351577012, 'learning_rate': 1.389092103541456e-08, 'epoch': 0.95}
{'loss': 1.1595, 'grad_norm': 2.176884639495488, 'learning_rate': 1.3818075741965029e-08, 'epoch': 0.95}
{'loss': 1.1259, 'grad_norm': 1.655017368704315, 'learning_rate': 1.3745420625914995e-08, 'epoch': 0.95}
{'loss': 1.137, 'grad_norm': 1.9455270821178177, 'learning_rate': 1.3672955701275579e-08, 'epoch': 0.95}
{'loss': 1.0789, 'grad_norm': 1.6853734385937251, 'learning_rate': 1.360068098202105e-08, 'epoch': 0.95}
 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████       | 7000/7376 [17:58:57<39:03,  6.23s/it]
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py:1898: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to
 https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed
 explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior,
 you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.0966, 'grad_norm': 1.5498830572300537, 'learning_rate': 1.3528596482089039e-08, 'epoch': 0.95}
{'loss': 1.1122, 'grad_norm': 2.1913145722527463, 'learning_rate': 1.3456702215380534e-08, 'epoch': 0.95}
{'loss': 1.1315, 'grad_norm': 1.8057344012744119, 'learning_rate': 1.3384998195759667e-08, 'epoch': 0.95}
{'loss': 1.1677, 'grad_norm': 2.0470968559223945, 'learning_rate': 1.3313484437053935e-08, 'epoch': 0.95}
{'loss': 1.1236, 'grad_norm': 4.187847604262615, 'learning_rate': 1.3242160953054415e-08, 'epoch': 0.95}
{'loss': 1.1432, 'grad_norm': 2.120356601142119, 'learning_rate': 1.3171027757515107e-08, 'epoch': 0.95}
{'loss': 1.1749, 'grad_norm': 2.532041528004807, 'learning_rate': 1.3100084864153593e-08, 'epoch': 0.95}
{'loss': 1.1305, 'grad_norm': 12.448740258487252, 'learning_rate': 1.3029332286650596e-08, 'epoch': 0.95}
{'loss': 1.0989, 'grad_norm': 1.9639389849595956, 'learning_rate': 1.295877003865009e-08, 'epoch': 0.95}
{'loss': 1.1565, 'grad_norm': 1.9346069528753618, 'learning_rate': 1.2888398133759637e-08, 'epoch': 0.95}
{'loss': 1.0972, 'grad_norm': 2.063197309211194, 'learning_rate': 1.2818216585549824e-08, 'epoch': 0.95}
{'loss': 1.148, 'grad_norm': 2.0533877688805315, 'learning_rate': 1.2748225407554603e-08, 'epoch': 0.95}
{'loss': 1.1556, 'grad_norm': 1.928102401267399, 'learning_rate': 1.2678424613271288e-08, 'epoch': 0.95}
{'loss': 1.1349, 'grad_norm': 3.5676462342355593, 'learning_rate': 1.2608814216160223e-08, 'epoch': 0.95}
{'loss': 1.1115, 'grad_norm': 2.271542622335616, 'learning_rate': 1.253939422964545e-08, 'epoch': 0.95}
{'loss': 1.1308, 'grad_norm': 2.1706975919175737, 'learning_rate': 1.2470164667113926e-08, 'epoch': 0.95}
{'loss': 1.1331, 'grad_norm': 1.7003750051179638, 'learning_rate': 1.2401125541915968e-08, 'epoch': 0.95}
{'loss': 1.1136, 'grad_norm': 1.7264547477997738, 'learning_rate': 1.2332276867365377e-08, 'epoch': 0.95}
{'loss': 1.1337, 'grad_norm': 1.5997464145241345, 'learning_rate': 1.2263618656739083e-08, 'epoch': 0.95}
{'loss': 1.119, 'grad_norm': 2.089422058263286, 'learning_rate': 1.2195150923277054e-08, 'epoch': 0.95}
{'loss': 1.1369, 'grad_norm': 2.5145646361873872, 'learning_rate': 1.2126873680183058e-08, 'epoch': 0.95}
{'loss': 1.1163, 'grad_norm': 1.5617611334829617, 'learning_rate': 1.2058786940623678e-08, 'epoch': 0.95}
{'loss': 1.1376, 'grad_norm': 2.5738030675386194, 'learning_rate': 1.1990890717728852e-08, 'epoch': 0.95}
{'loss': 1.1313, 'grad_norm': 2.254749918130236, 'learning_rate': 1.1923185024591775e-08, 'epoch': 0.95}
{'loss': 1.1316, 'grad_norm': 4.805540605508889, 'learning_rate': 1.1855669874269225e-08, 'epoch': 0.95}
{'loss': 1.1268, 'grad_norm': 2.1431881314145502, 'learning_rate': 1.1788345279780786e-08, 'epoch': 0.95}
{'loss': 1.1375, 'grad_norm': 1.6988868700391506, 'learning_rate': 1.1721211254109408e-08, 'epoch': 0.95}
{'loss': 1.1463, 'grad_norm': 1.8625418956702569, 'learning_rate': 1.1654267810201512e-08, 'epoch': 0.95}
{'loss': 1.1725, 'grad_norm': 2.10671041466994, 'learning_rate': 1.1587514960966437e-08, 'epoch': 0.95}
{'loss': 1.1809, 'grad_norm': 2.0519737179686826, 'learning_rate': 1.1520952719277222e-08, 'epoch': 0.95}
{'loss': 1.1478, 'grad_norm': 1.8939482730639412, 'learning_rate': 1.1454581097969595e-08, 'epoch': 0.95}
{'loss': 1.1177, 'grad_norm': 2.694049841480372, 'learning_rate': 1.1388400109842878e-08, 'epoch': 0.95}
{'loss': 1.17, 'grad_norm': 1.8262563504496143, 'learning_rate': 1.1322409767659525e-08, 'epoch': 0.95}
{'loss': 1.0999, 'grad_norm': 1.6412469747657927, 'learning_rate': 1.1256610084145468e-08, 'epoch': 0.95}
{'loss': 1.1452, 'grad_norm': 1.6932266549242765, 'learning_rate': 1.1191001071989336e-08, 'epoch': 0.95}
{'loss': 1.1096, 'grad_norm': 1.5147238692773428, 'learning_rate': 1.1125582743843564e-08, 'epoch': 0.95}
{'loss': 1.2032, 'grad_norm': 2.710436923581871, 'learning_rate': 1.1060355112323395e-08, 'epoch': 0.95}
{'loss': 1.1311, 'grad_norm': 2.78132438712321, 'learning_rate': 1.0995318190007652e-08, 'epoch': 0.95}
{'loss': 1.0945, 'grad_norm': 2.1467123783105637, 'learning_rate': 1.0930471989437862e-08, 'epoch': 0.95}
{'loss': 1.1604, 'grad_norm': 1.7779671001667414, 'learning_rate': 1.0865816523119464e-08, 'epoch': 0.95}
{'loss': 1.1206, 'grad_norm': 2.0125435249022874, 'learning_rate': 1.0801351803520598e-08, 'epoch': 0.95}
{'loss': 1.125, 'grad_norm': 3.3483019286061086, 'learning_rate': 1.0737077843072762e-08, 'epoch': 0.95}
{'loss': 1.134, 'grad_norm': 2.0787074272651647, 'learning_rate': 1.0672994654170598e-08, 'epoch': 0.95}
{'loss': 1.1235, 'grad_norm': 2.048604796744923, 'learning_rate': 1.060910224917222e-08, 'epoch': 0.95}
{'loss': 1.1256, 'grad_norm': 1.6932143382881781, 'learning_rate': 1.054540064039866e-08, 'epoch': 0.96}
{'loss': 1.1276, 'grad_norm': 2.0393500565562226, 'learning_rate': 1.0481889840134428e-08, 'epoch': 0.96}
{'loss': 1.1293, 'grad_norm': 1.5907907406506145, 'learning_rate': 1.0418569860626836e-08, 'epoch': 0.96}
{'loss': 1.1553, 'grad_norm': 1.8284772667785045, 'learning_rate': 1.0355440714086782e-08, 'epoch': 0.96}
{'loss': 1.1325, 'grad_norm': 1.8160024045330152, 'learning_rate': 1.0292502412688198e-08, 'epoch': 0.96}
{'loss': 1.1313, 'grad_norm': 1.7053576567700564, 'learning_rate': 1.0229754968568261e-08, 'epoch': 0.96}
{'loss': 1.1288, 'grad_norm': 1.7939137779330394, 'learning_rate': 1.0167198393827403e-08, 'epoch': 0.96}
{'loss': 1.1226, 'grad_norm': 2.6539030120886644, 'learning_rate': 1.0104832700528975e-08, 'epoch': 0.96}
{'loss': 1.1548, 'grad_norm': 1.6180374547004746, 'learning_rate': 1.0042657900699803e-08, 'epoch': 0.96}
{'loss': 1.1062, 'grad_norm': 1.9190843815959049, 'learning_rate': 9.980674006329848e-09, 'epoch': 0.96}
{'loss': 1.1107, 'grad_norm': 2.005584241952583, 'learning_rate': 9.918881029372106e-09, 'epoch': 0.96}
{'loss': 1.1757, 'grad_norm': 4.002874096915869, 'learning_rate': 9.857278981742934e-09, 'epoch': 0.96}
{'loss': 1.1396, 'grad_norm': 1.6416117741463765, 'learning_rate': 9.795867875321829e-09, 'epoch': 0.96}
{'loss': 1.1456, 'grad_norm': 1.9659243723326478, 'learning_rate': 9.734647721951427e-09, 'epoch': 0.96}
{'loss': 1.1548, 'grad_norm': 3.9065235680995123, 'learning_rate': 9.673618533437511e-09, 'epoch': 0.96}
{'loss': 1.1579, 'grad_norm': 2.533238201143718, 'learning_rate': 9.612780321549108e-09, 'epoch': 0.96}
{'loss': 1.1512, 'grad_norm': 1.7745794174447374, 'learning_rate': 9.552133098018389e-09, 'epoch': 0.96}
{'loss': 1.1082, 'grad_norm': 1.7936810324167212, 'learning_rate': 9.491676874540666e-09, 'epoch': 0.96}
{'loss': 1.1663, 'grad_norm': 2.348406464551202, 'learning_rate': 9.431411662774502e-09, 'epoch': 0.96}
{'loss': 1.1517, 'grad_norm': 5.033606966428257, 'learning_rate': 9.37133747434149e-09, 'epoch': 0.96}
{'loss': 1.1556, 'grad_norm': 3.3816640842392656, 'learning_rate': 9.311454320826473e-09, 'epoch': 0.96}
{'loss': 1.1495, 'grad_norm': 1.8597851995454844, 'learning_rate': 9.251762213777437e-09, 'epoch': 0.96}
{'loss': 1.1452, 'grad_norm': 1.6675096774145546, 'learning_rate': 9.192261164705617e-09, 'epoch': 0.96}
{'loss': 1.1351, 'grad_norm': 1.9690953592060858, 'learning_rate': 9.132951185085281e-09, 'epoch': 0.96}
{'loss': 1.1672, 'grad_norm': 1.6543699912164465, 'learning_rate': 9.073832286353944e-09, 'epoch': 0.96}
{'loss': 1.1521, 'grad_norm': 3.9189126623209325, 'learning_rate': 9.014904479912044e-09, 'epoch': 0.96}
{'loss': 1.1183, 'grad_norm': 4.398596819852975, 'learning_rate': 8.956167777123602e-09, 'epoch': 0.96}
{'loss': 1.1456, 'grad_norm': 2.112354013330604, 'learning_rate': 8.897622189315224e-09, 'epoch': 0.96}
{'loss': 1.1726, 'grad_norm': 4.05104311964079, 'learning_rate': 8.839267727777211e-09, 'epoch': 0.96}
{'loss': 1.1015, 'grad_norm': 1.7150371875444694, 'learning_rate': 8.781104403762563e-09, 'epoch': 0.96}
{'loss': 1.1663, 'grad_norm': 1.829558904246851, 'learning_rate': 8.723132228487861e-09, 'epoch': 0.96}
{'loss': 1.1338, 'grad_norm': 1.8298592462057324, 'learning_rate': 8.665351213132278e-09, 'epoch': 0.96}
{'loss': 1.1184, 'grad_norm': 2.0884126933675873, 'learning_rate': 8.607761368838785e-09, 'epoch': 0.96}
{'loss': 1.1416, 'grad_norm': 1.8630947558960034, 'learning_rate': 8.550362706712832e-09, 'epoch': 0.96}
{'loss': 1.1645, 'grad_norm': 1.9705393429666025, 'learning_rate': 8.493155237823347e-09, 'epoch': 0.96}
{'loss': 1.1238, 'grad_norm': 1.7985469285680158, 'learning_rate': 8.4361389732025e-09, 'epoch': 0.96}
{'loss': 1.1234, 'grad_norm': 1.7620251976349552, 'learning_rate': 8.379313923845277e-09, 'epoch': 0.96}
{'loss': 1.1209, 'grad_norm': 1.9278140813188984, 'learning_rate': 8.322680100710022e-09, 'epoch': 0.96}
{'loss': 1.1512, 'grad_norm': 1.7798828450277955, 'learning_rate': 8.266237514718e-09, 'epoch': 0.96}
{'loss': 1.1071, 'grad_norm': 1.6484551187322167, 'learning_rate': 8.209986176753948e-09, 'epoch': 0.96}
{'loss': 1.1393, 'grad_norm': 4.37035681128153, 'learning_rate': 8.153926097665186e-09, 'epoch': 0.96}
{'loss': 1.1399, 'grad_norm': 2.3075110115934123, 'learning_rate': 8.098057288262738e-09, 'epoch': 0.96}
{'loss': 1.1649, 'grad_norm': 2.591754966749492, 'learning_rate': 8.042379759320317e-09, 'epoch': 0.96}
{'loss': 1.1488, 'grad_norm': 2.184420257654729, 'learning_rate': 7.986893521574888e-09, 'epoch': 0.96}
{'loss': 1.1378, 'grad_norm': 1.6451961343757149, 'learning_rate': 7.931598585726562e-09, 'epoch': 0.96}
{'loss': 1.1601, 'grad_norm': 1.7786967170302748, 'learning_rate': 7.876494962438585e-09, 'epoch': 0.96}
{'loss': 1.1298, 'grad_norm': 2.229346964287714, 'learning_rate': 7.821582662337123e-09, 'epoch': 0.96}
{'loss': 1.1244, 'grad_norm': 1.8324337023153168, 'learning_rate': 7.766861696011816e-09, 'epoch': 0.96}
{'loss': 1.1234, 'grad_norm': 1.7570643809727389, 'learning_rate': 7.712332074014893e-09, 'epoch': 0.96}
{'loss': 1.1525, 'grad_norm': 1.8768396203950253, 'learning_rate': 7.657993806862162e-09, 'epoch': 0.96}
{'loss': 1.1287, 'grad_norm': 2.411277975340872, 'learning_rate': 7.603846905032129e-09, 'epoch': 0.96}
{'loss': 1.1529, 'grad_norm': 1.8432216788968894, 'learning_rate': 7.549891378966888e-09, 'epoch': 0.96}
{'loss': 1.1491, 'grad_norm': 1.9746781783553498, 'learning_rate': 7.496127239071003e-09, 'epoch': 0.96}
{'loss': 1.1324, 'grad_norm': 6.841311442388723, 'learning_rate': 7.442554495712738e-09, 'epoch': 0.96}
{'loss': 1.1028, 'grad_norm': 1.6406583294499049, 'learning_rate': 7.3891731592230496e-09, 'epoch': 0.96}
{'loss': 1.1378, 'grad_norm': 1.8905034352281835, 'learning_rate': 7.335983239896148e-09, 'epoch': 0.96}
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉     | 7100/7376 [18:14:37<28:40,  6.23s/it]
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py:1898: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to
 https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed
 explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior,
 you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.136, 'grad_norm': 1.7391519239719095, 'learning_rate': 7.282984747989163e-09, 'epoch': 0.96}
{'loss': 1.125, 'grad_norm': 2.011011054578179, 'learning_rate': 7.230177693722583e-09, 'epoch': 0.96}
{'loss': 1.14, 'grad_norm': 9.23959867767666, 'learning_rate': 7.17756208727982e-09, 'epoch': 0.96}
{'loss': 1.1171, 'grad_norm': 1.7181093561135274, 'learning_rate': 7.125137938807424e-09, 'epoch': 0.96}
{'loss': 1.1278, 'grad_norm': 2.2596503734716826, 'learning_rate': 7.072905258414752e-09, 'epoch': 0.96}
{'loss': 1.1042, 'grad_norm': 2.2982495973583084, 'learning_rate': 7.020864056174635e-09, 'epoch': 0.96}
{'loss': 1.1174, 'grad_norm': 2.0891636476055138, 'learning_rate': 6.969014342122825e-09, 'epoch': 0.96}
{'loss': 1.1622, 'grad_norm': 2.1825350728760387, 'learning_rate': 6.9173561262581e-09, 'epoch': 0.96}
{'loss': 1.1407, 'grad_norm': 2.1683471333804345, 'learning_rate': 6.86588941854227e-09, 'epoch': 0.96}
{'loss': 1.1416, 'grad_norm': 2.0036892537934046, 'learning_rate': 6.814614228900506e-09, 'epoch': 0.96}
{'loss': 1.1753, 'grad_norm': 1.568422220924218, 'learning_rate': 6.763530567220455e-09, 'epoch': 0.96}
{'loss': 1.1345, 'grad_norm': 1.996888215992166, 'learning_rate': 6.712638443353569e-09, 'epoch': 0.96}
{'loss': 1.1533, 'grad_norm': 1.6323792018612153, 'learning_rate': 6.661937867113665e-09, 'epoch': 0.96}
{'loss': 1.1412, 'grad_norm': 1.6909594469680715, 'learning_rate': 6.611428848278256e-09, 'epoch': 0.96}
{'loss': 1.1922, 'grad_norm': 2.9148001494258606, 'learning_rate': 6.5611113965873265e-09, 'epoch': 0.96}
{'loss': 1.1923, 'grad_norm': 2.037237811421171, 'learning_rate': 6.51098552174445e-09, 'epoch': 0.96}
{'loss': 1.1359, 'grad_norm': 1.6622369457882873, 'learning_rate': 6.461051233415782e-09, 'epoch': 0.96}
{'loss': 1.1415, 'grad_norm': 1.9031471637359685, 'learning_rate': 6.4113085412309535e-09, 'epoch': 0.96}
{'loss': 1.1275, 'grad_norm': 1.5614359585616724, 'learning_rate': 6.361757454782291e-09, 'epoch': 0.97}
{'loss': 1.1613, 'grad_norm': 2.115348997815399, 'learning_rate': 6.312397983625483e-09, 'epoch': 0.97}
{'loss': 1.1417, 'grad_norm': 1.6600504512769036, 'learning_rate': 6.2632301372789185e-09, 'epoch': 0.97}
{'loss': 1.1242, 'grad_norm': 2.1429278196362067, 'learning_rate': 6.214253925224455e-09, 'epoch': 0.97}
{'loss': 1.1435, 'grad_norm': 1.9775991056243183, 'learning_rate': 6.165469356906539e-09, 'epoch': 0.97}
{'loss': 1.1618, 'grad_norm': 1.747268269195497, 'learning_rate': 6.116876441733087e-09, 'epoch': 0.97}
{'loss': 1.1458, 'grad_norm': 2.77042327408537, 'learning_rate': 6.068475189074829e-09, 'epoch': 0.97}
{'loss': 1.142, 'grad_norm': 1.6845251987792689, 'learning_rate': 6.020265608265407e-09, 'epoch': 0.97}
{'loss': 1.1971, 'grad_norm': 2.9162894668172514, 'learning_rate': 5.97224770860183e-09, 'epoch': 0.97}
{'loss': 1.1243, 'grad_norm': 2.5544552243037026, 'learning_rate': 5.924421499343801e-09, 'epoch': 0.97}
{'loss': 1.1742, 'grad_norm': 1.9602520992841506, 'learning_rate': 5.8767869897145e-09, 'epoch': 0.97}
{'loss': 1.1163, 'grad_norm': 3.186700305856264, 'learning_rate': 5.8293441888994655e-09, 'epoch': 0.97}
{'loss': 1.1191, 'grad_norm': 2.0264628189611567, 'learning_rate': 5.7820931060481585e-09, 'epoch': 0.97}
{'loss': 1.1146, 'grad_norm': 1.8193651508859305, 'learning_rate': 5.735033750272067e-09, 'epoch': 0.97}
{'loss': 1.1632, 'grad_norm': 2.173192138214751, 'learning_rate': 5.68816613064671e-09, 'epoch': 0.97}
{'loss': 1.1556, 'grad_norm': 1.8991509152845314, 'learning_rate': 5.6414902562096356e-09, 'epoch': 0.97}
{'loss': 1.1464, 'grad_norm': 2.2766238620158945, 'learning_rate': 5.595006135962421e-09, 'epoch': 0.97}
{'loss': 1.1549, 'grad_norm': 1.735284475341264, 'learning_rate': 5.548713778868786e-09, 'epoch': 0.97}
{'loss': 1.1192, 'grad_norm': 1.7073978818400524, 'learning_rate': 5.502613193856031e-09, 'epoch': 0.97}
{'loss': 1.1459, 'grad_norm': 1.855572696679519, 'learning_rate': 5.45670438981416e-09, 'epoch': 0.97}
{'loss': 1.1434, 'grad_norm': 4.02562793628154, 'learning_rate': 5.4109873755964205e-09, 'epoch': 0.97}
{'loss': 1.1421, 'grad_norm': 1.7214924596199257, 'learning_rate': 5.365462160018985e-09, 'epoch': 0.97}
{'loss': 1.1191, 'grad_norm': 2.7245005876692425, 'learning_rate': 5.3201287518610525e-09, 'epoch': 0.97}
{'loss': 1.1365, 'grad_norm': 15.150072059147984, 'learning_rate': 5.274987159864741e-09, 'epoch': 0.97}
{'loss': 1.1901, 'grad_norm': 2.3386527463763653, 'learning_rate': 5.2300373927351984e-09, 'epoch': 0.97}
{'loss': 1.1644, 'grad_norm': 2.299623358277266, 'learning_rate': 5.185279459140823e-09, 'epoch': 0.97}
{'loss': 1.1404, 'grad_norm': 2.0329961132726826, 'learning_rate': 5.140713367712601e-09, 'epoch': 0.97}
{'loss': 1.1598, 'grad_norm': 1.7832082021786617, 'learning_rate': 5.09633912704488e-09, 'epoch': 0.97}
{'loss': 1.1294, 'grad_norm': 1.6376291365491504, 'learning_rate': 5.052156745694924e-09, 'epoch': 0.97}
{'loss': 1.18, 'grad_norm': 1.7365066134442486, 'learning_rate': 5.00816623218292e-09, 'epoch': 0.97}
{'loss': 1.1361, 'grad_norm': 1.8663383800459186, 'learning_rate': 4.964367594991969e-09, 'epoch': 0.97}
{'loss': 1.1334, 'grad_norm': 2.328539794063838, 'learning_rate': 4.920760842568539e-09, 'epoch': 0.97}
{'loss': 1.1668, 'grad_norm': 1.5827489966837187, 'learning_rate': 4.877345983321568e-09, 'epoch': 0.97}
{'loss': 1.1714, 'grad_norm': 1.8536877591821892, 'learning_rate': 4.834123025623471e-09, 'epoch': 0.97}
{'loss': 1.1257, 'grad_norm': 2.086608826575171, 'learning_rate': 4.791091977809358e-09, 'epoch': 0.97}
{'loss': 1.0766, 'grad_norm': 1.6747684108715788, 'learning_rate': 4.7482528481774805e-09, 'epoch': 0.97}
{'loss': 1.1536, 'grad_norm': 1.6105800102303338, 'learning_rate': 4.705605644988897e-09, 'epoch': 0.97}
{'loss': 1.1249, 'grad_norm': 5.469234824667813, 'learning_rate': 4.663150376468028e-09, 'epoch': 0.97}
{'loss': 1.1883, 'grad_norm': 4.82574201765184, 'learning_rate': 4.62088705080177e-09, 'epoch': 0.97}
{'loss': 1.149, 'grad_norm': 1.563313250387079, 'learning_rate': 4.5788156761404906e-09, 'epoch': 0.97}
{'loss': 1.1481, 'grad_norm': 2.010942505398286, 'learning_rate': 4.536936260597257e-09, 'epoch': 0.97}
{'loss': 1.1312, 'grad_norm': 1.6562810574586375, 'learning_rate': 4.495248812248054e-09, 'epoch': 0.97}
{'loss': 1.1245, 'grad_norm': 1.7368394035724355, 'learning_rate': 4.453753339132116e-09, 'epoch': 0.97}
{'loss': 1.122, 'grad_norm': 2.0801761688424865, 'learning_rate': 4.412449849251598e-09, 'epoch': 0.97}
{'loss': 1.1387, 'grad_norm': 3.081142690999182, 'learning_rate': 4.371338350571352e-09, 'epoch': 0.97}
{'loss': 1.1518, 'grad_norm': 5.002942842803807, 'learning_rate': 4.3304188510194795e-09, 'epoch': 0.97}
{'loss': 1.1814, 'grad_norm': 2.1917339871372996, 'learning_rate': 4.289691358486891e-09, 'epoch': 0.97}
{'loss': 1.1433, 'grad_norm': 1.7099846884508807, 'learning_rate': 4.249155880827859e-09, 'epoch': 0.97}
{'loss': 1.1404, 'grad_norm': 3.937469043120042, 'learning_rate': 4.2088124258590205e-09, 'epoch': 0.97}
{'loss': 1.1241, 'grad_norm': 3.0733420626476455, 'learning_rate': 4.168661001360485e-09, 'epoch': 0.97}
{'loss': 1.1448, 'grad_norm': 2.6151311712438052, 'learning_rate': 4.128701615074947e-09, 'epoch': 0.97}
{'loss': 1.1288, 'grad_norm': 1.7002443906561184, 'learning_rate': 4.088934274708466e-09, 'epoch': 0.97}
{'loss': 1.1314, 'grad_norm': 1.840219349913103, 'learning_rate': 4.049358987929685e-09, 'epoch': 0.97}
{'loss': 1.1554, 'grad_norm': 1.8241169536750832, 'learning_rate': 4.00997576237061e-09, 'epoch': 0.97}
{'loss': 1.1247, 'grad_norm': 2.243689171142017, 'learning_rate': 3.970784605625721e-09, 'epoch': 0.97}
{'loss': 1.1137, 'grad_norm': 1.5712422843457416, 'learning_rate': 3.931785525252862e-09, 'epoch': 0.97}
{'loss': 1.1219, 'grad_norm': 1.8665461514830444, 'learning_rate': 3.892978528772684e-09, 'epoch': 0.97}
{'loss': 1.1379, 'grad_norm': 7.598621427516209, 'learning_rate': 3.854363623668866e-09, 'epoch': 0.97}
{'loss': 1.1406, 'grad_norm': 1.7772543613432263, 'learning_rate': 3.815940817387786e-09, 'epoch': 0.97}
{'loss': 1.1109, 'grad_norm': 1.8250275959089104, 'learning_rate': 3.777710117339183e-09, 'epoch': 0.97}
{'loss': 1.1359, 'grad_norm': 1.7492700774593921, 'learning_rate': 3.739671530895605e-09, 'epoch': 0.97}
{'loss': 1.1345, 'grad_norm': 3.2421072488956537, 'learning_rate': 3.7018250653921834e-09, 'epoch': 0.97}
{'loss': 1.139, 'grad_norm': 1.768868032608592, 'learning_rate': 3.6641707281276357e-09, 'epoch': 0.97}
{'loss': 1.1188, 'grad_norm': 2.08672006186654, 'learning_rate': 3.6267085263631537e-09, 'epoch': 0.97}
{'loss': 1.1465, 'grad_norm': 1.62689356155613, 'learning_rate': 3.589438467322958e-09, 'epoch': 0.97}
{'loss': 1.1515, 'grad_norm': 1.935427220439092, 'learning_rate': 3.5523605581944115e-09, 'epoch': 0.97}
{'loss': 1.1515, 'grad_norm': 1.6480547118391864, 'learning_rate': 3.5154748061276828e-09, 'epoch': 0.97}
{'loss': 1.15, 'grad_norm': 2.9121013438995917, 'learning_rate': 3.47878121823586e-09, 'epoch': 0.97}
{'loss': 1.1258, 'grad_norm': 1.8425909909589555, 'learning_rate': 3.4422798015949496e-09, 'epoch': 0.97}
{'loss': 1.1297, 'grad_norm': 2.01591511697042, 'learning_rate': 3.405970563244098e-09, 'epoch': 0.97}
{'loss': 1.0689, 'grad_norm': 1.7836883475748668, 'learning_rate': 3.36985351018515e-09, 'epoch': 0.97}
{'loss': 1.1639, 'grad_norm': 1.6944162355889227, 'learning_rate': 3.3339286493830886e-09, 'epoch': 0.97}
{'loss': 1.1323, 'grad_norm': 1.5172132881764009, 'learning_rate': 3.2981959877657063e-09, 'epoch': 0.97}
{'loss': 1.1528, 'grad_norm': 1.6102555959423932, 'learning_rate': 3.2626555322236014e-09, 'epoch': 0.97}
{'loss': 1.104, 'grad_norm': 1.9318904294140031, 'learning_rate': 3.227307289610737e-09, 'epoch': 0.98}
{'loss': 1.1657, 'grad_norm': 1.8177695185402667, 'learning_rate': 3.192151266743548e-09, 'epoch': 0.98}
{'loss': 1.1623, 'grad_norm': 2.070692220488257, 'learning_rate': 3.157187470401723e-09, 'epoch': 0.98}
{'loss': 1.1579, 'grad_norm': 1.7506594018289297, 'learning_rate': 3.122415907327647e-09, 'epoch': 0.98}
{'loss': 1.1569, 'grad_norm': 2.355842709171441, 'learning_rate': 3.0878365842268437e-09, 'epoch': 0.98}
{'loss': 1.1419, 'grad_norm': 1.8490888226452398, 'learning_rate': 3.053449507767536e-09, 'epoch': 0.98}
{'loss': 1.1693, 'grad_norm': 1.9370376576799004, 'learning_rate': 3.019254684581085e-09, 'epoch': 0.98}
{'loss': 1.1405, 'grad_norm': 2.058146745789947, 'learning_rate': 2.985252121261661e-09, 'epoch': 0.98}
 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 7200/7376 [18:29:07<18:30,  6.31s/it]
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py:1898: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to
 https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed
 explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior,
 you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.1212, 'grad_norm': 1.7413677137156276, 'learning_rate': 2.951441824366463e-09, 'epoch': 0.98}
{'loss': 1.1222, 'grad_norm': 1.7497241526906495, 'learning_rate': 2.9178238004154975e-09, 'epoch': 0.98}
{'loss': 1.1257, 'grad_norm': 2.0478553777516164, 'learning_rate': 2.88439805589169e-09, 'epoch': 0.98}
{'loss': 1.1452, 'grad_norm': 1.7930925409406233, 'learning_rate': 2.851164597240996e-09, 'epoch': 0.98}
{'loss': 1.1023, 'grad_norm': 1.9023445158329266, 'learning_rate': 2.8181234308721767e-09, 'epoch': 0.98}
{'loss': 1.1207, 'grad_norm': 1.7676241118100382, 'learning_rate': 2.7852745631570253e-09, 'epoch': 0.98}
{'loss': 1.1477, 'grad_norm': 2.2835700435704442, 'learning_rate': 2.7526180004300294e-09, 'epoch': 0.98}
{'loss': 1.139, 'grad_norm': 1.993779861409688, 'learning_rate': 2.720153748988929e-09, 'epoch': 0.98}
{'loss': 1.1561, 'grad_norm': 2.0564120065020686, 'learning_rate': 2.6878818150941616e-09, 'epoch': 0.98}
{'loss': 1.1534, 'grad_norm': 1.7617558992976297, 'learning_rate': 2.655802204968971e-09, 'epoch': 0.98}
{'loss': 1.1249, 'grad_norm': 1.569259650089582, 'learning_rate': 2.6239149247999635e-09, 'epoch': 0.98}
{'loss': 1.1342, 'grad_norm': 2.0583119171328765, 'learning_rate': 2.592219980735999e-09, 'epoch': 0.98}
{'loss': 1.1431, 'grad_norm': 1.9190665853981144, 'learning_rate': 2.5607173788894097e-09, 'epoch': 0.98}
{'loss': 1.1414, 'grad_norm': 2.1520084360330562, 'learning_rate': 2.5294071253351146e-09, 'epoch': 0.98}
{'loss': 1.1195, 'grad_norm': 1.8943750862736246, 'learning_rate': 2.498289226111061e-09, 'epoch': 0.98}
{'loss': 1.1712, 'grad_norm': 1.7986542565288057, 'learning_rate': 2.467363687218227e-09, 'epoch': 0.98}
{'loss': 1.1181, 'grad_norm': 1.6732476417496203, 'learning_rate': 2.436630514620286e-09, 'epoch': 0.98}
{'loss': 1.1453, 'grad_norm': 1.7831274982927694, 'learning_rate': 2.4060897142438308e-09, 'epoch': 0.98}
{'loss': 1.1635, 'grad_norm': 2.430034644895944, 'learning_rate': 2.3757412919783725e-09, 'epoch': 0.98}
{'loss': 1.1488, 'grad_norm': 3.3884050202263265, 'learning_rate': 2.345585253676452e-09, 'epoch': 0.98}
{'loss': 1.1019, 'grad_norm': 2.0490940308181074, 'learning_rate': 2.3156216051535284e-09, 'epoch': 0.98}
{'loss': 1.1228, 'grad_norm': 1.8160320765347415, 'learning_rate': 2.285850352187646e-09, 'epoch': 0.98}
{'loss': 1.1459, 'grad_norm': 1.8512312364129713, 'learning_rate': 2.2562715005201016e-09, 'epoch': 0.98}
{'loss': 1.183, 'grad_norm': 3.220731267524111, 'learning_rate': 2.226885055854777e-09, 'epoch': 0.98}
{'loss': 1.163, 'grad_norm': 1.8846093023551764, 'learning_rate': 2.1976910238588055e-09, 'epoch': 0.98}
{'loss': 1.1115, 'grad_norm': 1.6958886312172636, 'learning_rate': 2.168689410162017e-09, 'epoch': 0.98}
{'loss': 1.1538, 'grad_norm': 1.6840520503070422, 'learning_rate': 2.1398802203569375e-09, 'epoch': 0.98}
{'loss': 1.1176, 'grad_norm': 1.6883993770277839, 'learning_rate': 2.111263459999457e-09, 'epoch': 0.98}
{'loss': 1.1384, 'grad_norm': 1.7843039146594757, 'learning_rate': 2.0828391346078277e-09, 'epoch': 0.98}
{'loss': 1.1477, 'grad_norm': 15.317713192365474, 'learning_rate': 2.054607249663665e-09, 'epoch': 0.98}
{'loss': 1.1646, 'grad_norm': 1.6680572031121492, 'learning_rate': 2.0265678106111685e-09, 'epoch': 0.98}
{'loss': 1.1283, 'grad_norm': 1.9666698837543557, 'learning_rate': 1.9987208228575693e-09, 'epoch': 0.98}
{'loss': 1.1627, 'grad_norm': 1.9311813803018716, 'learning_rate': 1.971066291772905e-09, 'epoch': 0.98}
{'loss': 1.1566, 'grad_norm': 4.642162521894147, 'learning_rate': 1.9436042226901315e-09, 'epoch': 0.98}
{'loss': 1.1238, 'grad_norm': 1.6951795124326932, 'learning_rate': 1.9163346209051246e-09, 'epoch': 0.98}
{'loss': 1.1048, 'grad_norm': 1.6884053593944854, 'learning_rate': 1.889257491676677e-09, 'epoch': 0.98}
{'loss': 1.1208, 'grad_norm': 1.7251300380453687, 'learning_rate': 1.8623728402261674e-09, 'epoch': 0.98}
{'loss': 1.1598, 'grad_norm': 1.8092506902857715, 'learning_rate': 1.8356806717383377e-09, 'epoch': 0.98}
{'loss': 1.1369, 'grad_norm': 2.032709813093778, 'learning_rate': 1.809180991360404e-09, 'epoch': 0.98}
{'loss': 1.1527, 'grad_norm': 1.783943213788109, 'learning_rate': 1.7828738042027225e-09, 'epoch': 0.98}
{'loss': 1.1571, 'grad_norm': 2.0389027175904038, 'learning_rate': 1.7567591153383466e-09, 'epoch': 0.98}
{'loss': 1.1526, 'grad_norm': 1.991990803078623, 'learning_rate': 1.7308369298033587e-09, 'epoch': 0.98}
{'loss': 1.1442, 'grad_norm': 1.8966558248654597, 'learning_rate': 1.7051072525965382e-09, 'epoch': 0.98}
{'loss': 1.1397, 'grad_norm': 2.027849315381984, 'learning_rate': 1.6795700886798049e-09, 'epoch': 0.98}
{'loss': 1.072, 'grad_norm': 1.7155614056182429, 'learning_rate': 1.6542254429776636e-09, 'epoch': 0.98}
{'loss': 1.1672, 'grad_norm': 2.108213829059701, 'learning_rate': 1.6290733203776497e-09, 'epoch': 0.98}
{'loss': 1.1269, 'grad_norm': 2.25294253488452, 'learning_rate': 1.6041137257303272e-09, 'epoch': 0.98}
{'loss': 1.1407, 'grad_norm': 1.7647821601430227, 'learning_rate': 1.5793466638486242e-09, 'epoch': 0.98}
{'loss': 1.1228, 'grad_norm': 1.547335322668067, 'learning_rate': 1.554772139509053e-09, 'epoch': 0.98}
{'loss': 1.1137, 'grad_norm': 3.062829255690299, 'learning_rate': 1.5303901574502675e-09, 'epoch': 0.98}
{'loss': 1.1518, 'grad_norm': 2.023128309062777, 'learning_rate': 1.5062007223743956e-09, 'epoch': 0.98}
{'loss': 1.1236, 'grad_norm': 1.8375182714604354, 'learning_rate': 1.482203838946039e-09, 'epoch': 0.98}
{'loss': 1.1734, 'grad_norm': 1.8198285258749562, 'learning_rate': 1.4583995117929404e-09, 'epoch': 0.98}
{'loss': 1.1601, 'grad_norm': 2.0084987846373803, 'learning_rate': 1.434787745505317e-09, 'epoch': 0.98}
{'loss': 1.1061, 'grad_norm': 1.826919425880202, 'learning_rate': 1.4113685446368595e-09, 'epoch': 0.98}
{'loss': 1.1447, 'grad_norm': 2.382496547237129, 'learning_rate': 1.388141913703511e-09, 'epoch': 0.98}
{'loss': 1.1184, 'grad_norm': 1.6502329430617906, 'learning_rate': 1.3651078571844664e-09, 'epoch': 0.98}
{'loss': 1.1398, 'grad_norm': 2.0212168422761905, 'learning_rate': 1.3422663795215062e-09, 'epoch': 0.98}
{'loss': 1.1098, 'grad_norm': 1.8317893266416365, 'learning_rate': 1.3196174851196617e-09, 'epoch': 0.98}
{'loss': 1.1038, 'grad_norm': 1.6702671674806389, 'learning_rate': 1.2971611783465507e-09, 'epoch': 0.98}
{'loss': 1.1452, 'grad_norm': 2.0421262488195278, 'learning_rate': 1.274897463532487e-09, 'epoch': 0.98}
{'loss': 1.1478, 'grad_norm': 1.8575980645149806, 'learning_rate': 1.2528263449710363e-09, 'epoch': 0.98}
{'loss': 1.1487, 'grad_norm': 1.7988368281987863, 'learning_rate': 1.2309478269184602e-09, 'epoch': 0.98}
{'loss': 1.1803, 'grad_norm': 1.8415272450298705, 'learning_rate': 1.2092619135937177e-09, 'epoch': 0.98}
{'loss': 1.1236, 'grad_norm': 1.9597125053735975, 'learning_rate': 1.1877686091787963e-09, 'epoch': 0.98}
{'loss': 1.0957, 'grad_norm': 1.8605610168095932, 'learning_rate': 1.1664679178186032e-09, 'epoch': 0.99}
{'loss': 1.1614, 'grad_norm': 2.016151484730992, 'learning_rate': 1.1453598436208522e-09, 'epoch': 0.99}
{'loss': 1.1411, 'grad_norm': 1.670927310419065, 'learning_rate': 1.1244443906558432e-09, 'epoch': 0.99}
{'loss': 1.1573, 'grad_norm': 2.1507624467807163, 'learning_rate': 1.1037215629571272e-09, 'epoch': 0.99}
{'loss': 1.1489, 'grad_norm': 1.7214105884849327, 'learning_rate': 1.0831913645209522e-09, 'epoch': 0.99}
{'loss': 1.1921, 'grad_norm': 2.231917277772765, 'learning_rate': 1.0628537993063736e-09, 'epoch': 0.99}
{'loss': 1.1505, 'grad_norm': 2.338680453383897, 'learning_rate': 1.042708871235143e-09, 'epoch': 0.99}
{'loss': 1.1156, 'grad_norm': 1.8540238924447394, 'learning_rate': 1.0227565841923746e-09, 'epoch': 0.99}
{'loss': 1.1387, 'grad_norm': 1.9919953016226941, 'learning_rate': 1.002996942025547e-09, 'epoch': 0.99}
{'loss': 1.1572, 'grad_norm': 1.7873706147698667, 'learning_rate': 9.834299485450559e-10, 'epoch': 0.99}
{'loss': 1.1572, 'grad_norm': 2.19883412918489, 'learning_rate': 9.640556075244388e-10, 'epoch': 0.99}
{'loss': 1.1509, 'grad_norm': 2.1226419794684905, 'learning_rate': 9.448739226997072e-10, 'epoch': 0.99}
{'loss': 1.1448, 'grad_norm': 10.332641516010355, 'learning_rate': 9.258848977700129e-10, 'epoch': 0.99}
{'loss': 1.1823, 'grad_norm': 1.994524055982041, 'learning_rate': 9.070885363972047e-10, 'epoch': 0.99}
{'loss': 1.1727, 'grad_norm': 2.752814520179471, 'learning_rate': 8.884848422060498e-10, 'epoch': 0.99}
{'loss': 1.154, 'grad_norm': 2.765542193530241, 'learning_rate': 8.700738187840118e-10, 'epoch': 0.99}
{'loss': 1.1809, 'grad_norm': 2.735748624346094, 'learning_rate': 8.518554696815838e-10, 'epoch': 0.99}
{'loss': 1.1173, 'grad_norm': 2.6563484526647363, 'learning_rate': 8.338297984121778e-10, 'epoch': 0.99}
{'loss': 1.1186, 'grad_norm': 1.564464218201518, 'learning_rate': 8.159968084515689e-10, 'epoch': 0.99}
{'loss': 1.1092, 'grad_norm': 2.604208185989026, 'learning_rate': 7.983565032390061e-10, 'epoch': 0.99}
{'loss': 1.1177, 'grad_norm': 1.735012107279987, 'learning_rate': 7.809088861762125e-10, 'epoch': 0.99}
{'loss': 1.1861, 'grad_norm': 1.9791858862464926, 'learning_rate': 7.636539606277192e-10, 'epoch': 0.99}
{'loss': 1.1234, 'grad_norm': 1.9247409444314534, 'learning_rate': 7.465917299210866e-10, 'epoch': 0.99}
{'loss': 1.1364, 'grad_norm': 1.9628582241886547, 'learning_rate': 7.297221973465717e-10, 'epoch': 0.99}
{'loss': 1.1391, 'grad_norm': 2.631197619377059, 'learning_rate': 7.130453661573499e-10, 'epoch': 0.99}
{'loss': 1.1688, 'grad_norm': 2.02425886436325, 'learning_rate': 6.965612395695153e-10, 'epoch': 0.99}
{'loss': 1.1384, 'grad_norm': 2.0019577618428297, 'learning_rate': 6.802698207617474e-10, 'epoch': 0.99}
{'loss': 1.1112, 'grad_norm': 4.282581386472536, 'learning_rate': 6.641711128758665e-10, 'epoch': 0.99}
{'loss': 1.1049, 'grad_norm': 1.8654958013145784, 'learning_rate': 6.48265119016278e-10, 'epoch': 0.99}
{'loss': 1.1388, 'grad_norm': 1.9482769424608362, 'learning_rate': 6.325518422503063e-10, 'epoch': 0.99}
{'loss': 1.164, 'grad_norm': 1.8414429459403316, 'learning_rate': 6.170312856083048e-10, 'epoch': 0.99}
{'loss': 1.183, 'grad_norm': 1.7505508049535863, 'learning_rate': 6.017034520831021e-10, 'epoch': 0.99}
{'loss': 1.1336, 'grad_norm': 1.5063407863257874, 'learning_rate': 5.865683446305558e-10, 'epoch': 0.99}
{'loss': 1.1496, 'grad_norm': 3.163983140138284, 'learning_rate': 5.716259661695533e-10, 'epoch': 0.99}
{'loss': 1.1385, 'grad_norm': 1.9081258299409787, 'learning_rate': 5.568763195813453e-10, 'epoch': 0.99}
 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 7300/7376 [18:44:45<07:49,  6.18s/it]
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py:1898: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to
 https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed
 explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior,
 you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
{'loss': 1.0931, 'grad_norm': 1.8103920104841729, 'learning_rate': 5.423194077104343e-10, 'epoch': 0.99}
{'loss': 1.0998, 'grad_norm': 2.1155749207718206, 'learning_rate': 5.279552333640191e-10, 'epoch': 0.99}
{'loss': 1.1158, 'grad_norm': 1.9374002587149286, 'learning_rate': 5.137837993121064e-10, 'epoch': 0.99}
{'loss': 1.2179, 'grad_norm': 3.2854455112470444, 'learning_rate': 4.998051082875099e-10, 'epoch': 0.99}
{'loss': 1.1625, 'grad_norm': 1.8362492058751527, 'learning_rate': 4.860191629859623e-10, 'epoch': 0.99}
{'loss': 1.1587, 'grad_norm': 3.182519325635339, 'learning_rate': 4.724259660658924e-10, 'epoch': 0.99}
{'loss': 1.1127, 'grad_norm': 1.6508731591149417, 'learning_rate': 4.5902552014864815e-10, 'epoch': 0.99}
{'loss': 1.1242, 'grad_norm': 1.7845776181795554, 'learning_rate': 4.458178278184954e-10, 'epoch': 0.99}
{'loss': 1.1448, 'grad_norm': 2.2883477616474845, 'learning_rate': 4.328028916222859e-10, 'epoch': 0.99}
{'loss': 1.1545, 'grad_norm': 1.9515104839537334, 'learning_rate': 4.199807140700118e-10, 'epoch': 0.99}
{'loss': 1.1227, 'grad_norm': 2.9219158373296468, 'learning_rate': 4.073512976342508e-10, 'epoch': 0.99}
{'loss': 1.1635, 'grad_norm': 1.846093623520437, 'learning_rate': 3.9491464475049916e-10, 'epoch': 0.99}
{'loss': 1.1462, 'grad_norm': 1.907541158713146, 'learning_rate': 3.826707578170607e-10, 'epoch': 0.99}
{'loss': 1.1498, 'grad_norm': 1.6876607120411955, 'learning_rate': 3.7061963919504667e-10, 'epoch': 0.99}
{'loss': 1.1479, 'grad_norm': 1.786196291472633, 'learning_rate': 3.5876129120837596e-10, 'epoch': 0.99}
{'loss': 1.1249, 'grad_norm': 1.757647514034416, 'learning_rate': 3.470957161439969e-10, 'epoch': 0.99}
{'loss': 1.1518, 'grad_norm': 1.9396051907071463, 'learning_rate': 3.3562291625133245e-10, 'epoch': 0.99}
{'loss': 1.126, 'grad_norm': 1.9590896526900903, 'learning_rate': 3.24342893742946e-10, 'epoch': 0.99}
{'loss': 1.138, 'grad_norm': 6.783881307879676, 'learning_rate': 3.1325565079409755e-10, 'epoch': 0.99}
{'loss': 1.1097, 'grad_norm': 1.6412255667183278, 'learning_rate': 3.023611895428546e-10, 'epoch': 0.99}
{'loss': 1.124, 'grad_norm': 1.771098771953571, 'learning_rate': 2.9165951209020325e-10, 'epoch': 0.99}
{'loss': 1.1096, 'grad_norm': 1.9584679213800282, 'learning_rate': 2.8115062049971493e-10, 'epoch': 0.99}
{'loss': 1.0953, 'grad_norm': 2.320416204196344, 'learning_rate': 2.7083451679799084e-10, 'epoch': 0.99}
{'loss': 1.1678, 'grad_norm': 2.535446348754648, 'learning_rate': 2.6071120297443963e-10, 'epoch': 0.99}
{'loss': 1.1228, 'grad_norm': 1.7399411007265313, 'learning_rate': 2.507806809813884e-10, 'epoch': 0.99}
{'loss': 1.146, 'grad_norm': 5.753471712813689, 'learning_rate': 2.410429527336388e-10, 'epoch': 0.99}
{'loss': 1.1507, 'grad_norm': 2.1087133633289263, 'learning_rate': 2.3149802010913322e-10, 'epoch': 0.99}
{'loss': 1.1665, 'grad_norm': 1.792617709652166, 'learning_rate': 2.221458849486213e-10, 'epoch': 0.99}
{'loss': 1.1247, 'grad_norm': 1.8087370367430278, 'learning_rate': 2.1298654905543834e-10, 'epoch': 0.99}
{'loss': 1.1313, 'grad_norm': 3.500286553444128, 'learning_rate': 2.0402001419594917e-10, 'epoch': 0.99}
{'loss': 1.1653, 'grad_norm': 2.2688191222990337, 'learning_rate': 1.9524628209943718e-10, 'epoch': 0.99}
{'loss': 1.1399, 'grad_norm': 1.7817587538255701, 'learning_rate': 1.8666535445754917e-10, 'epoch': 0.99}
{'loss': 1.129, 'grad_norm': 1.6594429755653881, 'learning_rate': 1.7827723292518358e-10, 'epoch': 0.99}
{'loss': 1.1355, 'grad_norm': 1.7153080301246038, 'learning_rate': 1.7008191912004645e-10, 'epoch': 0.99}
{'loss': 1.1346, 'grad_norm': 2.3809254266349353, 'learning_rate': 1.6207941462242912e-10, 'epoch': 0.99}
{'loss': 1.1427, 'grad_norm': 1.9925602755589376, 'learning_rate': 1.5426972097543068e-10, 'epoch': 0.99}
{'loss': 1.0949, 'grad_norm': 2.366951558052229, 'learning_rate': 1.4665283968529062e-10, 'epoch': 0.99}
{'loss': 1.1532, 'grad_norm': 2.043757166157033, 'learning_rate': 1.3922877222083407e-10, 'epoch': 0.99}
{'loss': 1.1647, 'grad_norm': 1.7999573284973465, 'learning_rate': 1.3199752001369359e-10, 'epoch': 0.99}
{'loss': 1.1164, 'grad_norm': 1.7607229207042296, 'learning_rate': 1.2495908445830928e-10, 'epoch': 1.0}
{'loss': 1.1102, 'grad_norm': 2.090543528327042, 'learning_rate': 1.1811346691203982e-10, 'epoch': 1.0}
{'loss': 1.1517, 'grad_norm': 2.223970705835262, 'learning_rate': 1.1146066869494042e-10, 'epoch': 1.0}
{'loss': 1.1492, 'grad_norm': 1.7421977433070037, 'learning_rate': 1.0500069109009579e-10, 'epoch': 1.0}
{'loss': 1.1195, 'grad_norm': 2.010284720460006, 'learning_rate': 9.873353534317619e-11, 'epoch': 1.0}
{'loss': 1.1314, 'grad_norm': 1.9021729551988797, 'learning_rate': 9.265920266265936e-11, 'epoch': 1.0}
{'loss': 1.1595, 'grad_norm': 2.557912110139075, 'learning_rate': 8.677769422005266e-11, 'epoch': 1.0}
{'loss': 1.1384, 'grad_norm': 1.9705092337859373, 'learning_rate': 8.108901114955991e-11, 'epoch': 1.0}
{'loss': 1.116, 'grad_norm': 2.317661464057254, 'learning_rate': 7.559315454819249e-11, 'epoch': 1.0}
{'loss': 1.143, 'grad_norm': 4.255659747032378, 'learning_rate': 7.029012547576929e-11, 'epoch': 1.0}
{'loss': 1.1476, 'grad_norm': 3.088343846915634, 'learning_rate': 6.517992495491676e-11, 'epoch': 1.0}
{'loss': 1.1338, 'grad_norm': 2.4496356914929382, 'learning_rate': 6.026255397106884e-11, 'epoch': 1.0}
{'loss': 1.1599, 'grad_norm': 1.75491575677336, 'learning_rate': 5.553801347257803e-11, 'epoch': 1.0}
{'loss': 1.1271, 'grad_norm': 5.763547571866006, 'learning_rate': 5.1006304370493355e-11, 'epoch': 1.0}
{'loss': 1.1188, 'grad_norm': 1.8186002182049237, 'learning_rate': 4.6667427538782386e-11, 'epoch': 1.0}
{'loss': 1.145, 'grad_norm': 1.6047628504113367, 'learning_rate': 4.252138381399817e-11, 'epoch': 1.0}
{'loss': 1.1313, 'grad_norm': 5.34619219346154, 'learning_rate': 3.856817399594536e-11, 'epoch': 1.0}
{'loss': 1.1717, 'grad_norm': 1.8252090449795022, 'learning_rate': 3.4807798846681055e-11, 'epoch': 1.0}
{'loss': 1.157, 'grad_norm': 1.8016472093910534, 'learning_rate': 3.124025909151395e-11, 'epoch': 1.0}
{'loss': 1.1902, 'grad_norm': 2.234540081987162, 'learning_rate': 2.7865555418338238e-11, 'epoch': 1.0}
{'loss': 1.1498, 'grad_norm': 1.8174943252200455, 'learning_rate': 2.4683688477966647e-11, 'epoch': 1.0}
{'loss': 1.1655, 'grad_norm': 2.0443003966003768, 'learning_rate': 2.1694658884130468e-11, 'epoch': 1.0}
{'loss': 1.1536, 'grad_norm': 1.603413057242596, 'learning_rate': 1.8898467213146473e-11, 'epoch': 1.0}
{'loss': 1.1717, 'grad_norm': 2.642116028144747, 'learning_rate': 1.6295114004138965e-11, 'epoch': 1.0}
{'loss': 1.1629, 'grad_norm': 2.057298997204857, 'learning_rate': 1.3884599759261818e-11, 'epoch': 1.0}
{'loss': 1.1393, 'grad_norm': 1.642314821711257, 'learning_rate': 1.1666924943254386e-11, 'epoch': 1.0}
{'loss': 1.1493, 'grad_norm': 2.635002491447392, 'learning_rate': 9.642089983885604e-12, 'epoch': 1.0}
{'loss': 1.1404, 'grad_norm': 2.2070672294804945, 'learning_rate': 7.810095271620908e-12, 'epoch': 1.0}
{'loss': 1.1353, 'grad_norm': 1.9558195291189124, 'learning_rate': 6.170941159733267e-12, 'epoch': 1.0}
{'loss': 1.1286, 'grad_norm': 2.1382536372668706, 'learning_rate': 4.724627964303174e-12, 'epoch': 1.0}
{'loss': 1.1216, 'grad_norm': 1.5819700923347995, 'learning_rate': 3.4711559642186527e-12, 'epoch': 1.0}
{'loss': 1.1138, 'grad_norm': 1.9338220648810571, 'learning_rate': 2.4105254012862784e-12, 'epoch': 1.0}
{'loss': 1.1568, 'grad_norm': 1.6863376048661736, 'learning_rate': 1.5427364800091325e-12, 'epoch': 1.0}
{'loss': 1.1171, 'grad_norm': 1.862167391360977, 'learning_rate': 8.67789367586802e-13, 'epoch': 1.0}
{'loss': 1.156, 'grad_norm': 2.3849054097089897, 'learning_rate': 3.856841943594702e-13, 'epoch': 1.0}
{'loss': 1.1113, 'grad_norm': 2.225893687063196, 'learning_rate': 9.642105325280425e-14, 'epoch': 1.0}
{'loss': 1.1698, 'grad_norm': 1.7501244366708446, 'learning_rate': 0.0, 'epoch': 1.0}
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7376/7376 [18:56:30<00:00,  6.16s/it]
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py:1898: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to
 https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
Traceback (most recent call last):
OSError: [Errno 16] Device or resource busy: '.nfs000000014e360231000a060b'
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs000000014dc2ed74000a060a'
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
Traceback (most recent call last):
OSError: [Errno 16] Device or resource busy: '.nfs000000014e360235000a060c'
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
Traceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
OSError: [Errno 16] Device or resource busy: '.nfs000000014e360233000a0614'
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
Traceback (most recent call last):
Traceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
Traceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
OSError: [Errno 16] Device or resource busy: '.nfs000000014dc2ed6d000a0612'
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
OSError: [Errno 16] Device or resource busy: '.nfs000000014e36022a000a0615'
Traceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
Traceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
Traceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
OSError: [Errno 16] Device or resource busy: '.nfs000000014dc2ed6f000a060f'
OSError: [Errno 16] Device or resource busy: '.nfs000000014c83fa38000a060e'
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
OSError: [Errno 16] Device or resource busy: '.nfs000000014dc2ed6e000a0613'
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
OSError: [Errno 16] Device or resource busy: '.nfs000000014dc2ed71000a0611'
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs000000014e360230000a0610'
OSError: [Errno 16] Device or resource busy: '.nfs000000014e36022f000a060d'
Traceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs000000014e36023a000a0617'
Traceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs000000014e360237000a0618'
Traceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs000000014e360238000a0616'
Traceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs000000014dc2ed77000a0619'
{'train_runtime': 68441.7673, 'train_samples_per_second': 10.347, 'train_steps_per_second': 0.108, 'train_loss': 1.1986228312303084, 'epoch': 1.0}
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7376/7376 [19:00:41<00:00,  9.28s/it]
[2024-08-30 14:07:32,190] [INFO] [launch.py:348:main] Process 1158087 exits successfully.
[2024-08-30 14:07:32,190] [INFO] [launch.py:348:main] Process 1158086 exits successfully.
[2024-08-30 14:07:33,192] [INFO] [launch.py:348:main] Process 1158089 exits successfully.
[2024-08-30 14:08:22,249] [INFO] [launch.py:348:main] Process 1158085 exits successfully.

