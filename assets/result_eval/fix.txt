    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs00000001501fea9f0021e9dd'
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs000000014fe25b710021e9de'
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
OSError: [Errno 16] Device or resource busy: '.nfs00000001501fea9e0021e9e1'
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs000000014fe25b700021e9df'
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs0000000158240db30021e9e0'
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs000000015315dcd20021e9e2'
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs0000000158240dab0021e9e3'
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs000000014fe25b6b0021e9e4'
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs0000000158240da90021e9e5'
[rank3]: Traceback (most recent call last):
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/train_mem.py", line 11, in <module>
[rank3]:     train(attn_implementation="flash_attention_2")
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/train.py", line 1465, in train
[rank3]:     trainer.train()
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/transformers/trainer.py", line 1938, in train
[rank3]:     return inner_training_loop(
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 765, in _inner_training_loop
[rank3]:     tr_loss_step, ouput = self.training_step(model, inputs)
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 393, in training_step
[rank3]:     loss, ouput = self.compute_loss(model, inputs, return_outputs=True)
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 341, in compute_loss
[rank3]:     outputs = model(**inputs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank3]:     ret_val = func(*args, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1899, in forward
[rank3]:     loss = self.module(*inputs, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/language_model/llava_phi.py", line 89, in forward
[rank3]:     ) = self.prepare_inputs_labels_for_multimodal(
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/llava_arch.py", line 251, in prepare_inputs_labels_for_multimodal
[rank3]:     image_features, auxiliary_loss_clip, vision_id_experts, balance_losses_clip = self.get_model().get_vision_tower()(images, return_id_experts = kwargs['return_id_experts'])
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_encoder.py", line 113, in forward
[rank3]:     out_x, auxilarity_loss, vision_id_experts, balance_loss = self.vision_model( pixel_values = x,   return_id_experts = return_id_experts)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 275, in forward
[rank3]:     encoder_outputs, auxiliary_losses, stored_history_experts, balance_losses = self.encoder(inputs_embeds = hidden_states, return_id_experts = return_id_experts)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 180, in forward
[rank3]:     layer_outputs = encoder_layer(hidden_states = hidden_states)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 141, in forward
[rank3]:     results, auxiliary_loss, id_experts, balance_loss = self.moelayer(hidden_states, return_id_experts, is_vision=True)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/moe/competesmoev27.py", line 299, in forward
[rank3]:     output = self.compute_moe(
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/moe/moe.py", line 159, in compute_moe
[rank3]:     results[batch_idx, token_idx] += weights[batch_idx, token_idx, topk_idx].unsqueeze(0).T * out_exp
[rank3]: RuntimeError: The size of tensor a (1152) must match the size of tensor b (1153) at non-singleton dimension 1
[rank2]: Traceback (most recent call last):
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/train_mem.py", line 11, in <module>
[rank2]:     train(attn_implementation="flash_attention_2")
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/train.py", line 1465, in train
[rank2]:     trainer.train()
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/transformers/trainer.py", line 1938, in train
[rank2]:     return inner_training_loop(
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 765, in _inner_training_loop
[rank2]:     tr_loss_step, ouput = self.training_step(model, inputs)
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 393, in training_step
[rank2]:     loss, ouput = self.compute_loss(model, inputs, return_outputs=True)
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 341, in compute_loss
[rank2]:     outputs = model(**inputs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank2]:     ret_val = func(*args, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1899, in forward
[rank2]:     loss = self.module(*inputs, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank2]:     result = forward_call(*args, **kwargs)
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/language_model/llava_phi.py", line 89, in forward
[rank2]:     ) = self.prepare_inputs_labels_for_multimodal(
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/llava_arch.py", line 251, in prepare_inputs_labels_for_multimodal
[rank2]:     image_features, auxiliary_loss_clip, vision_id_experts, balance_losses_clip = self.get_model().get_vision_tower()(images, return_id_experts = kwargs['return_id_experts'])
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank2]:     result = forward_call(*args, **kwargs)
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_encoder.py", line 113, in forward
[rank2]:     out_x, auxilarity_loss, vision_id_experts, balance_loss = self.vision_model( pixel_values = x,   return_id_experts = return_id_experts)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank2]:     result = forward_call(*args, **kwargs)
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 275, in forward
[rank2]:     encoder_outputs, auxiliary_losses, stored_history_experts, balance_losses = self.encoder(inputs_embeds = hidden_states, return_id_experts = return_id_experts)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank2]:     result = forward_call(*args, **kwargs)
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 180, in forward
[rank2]:     layer_outputs = encoder_layer(hidden_states = hidden_states)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank2]:     result = forward_call(*args, **kwargs)
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 141, in forward
[rank2]:     results, auxiliary_loss, id_experts, balance_loss = self.moelayer(hidden_states, return_id_experts, is_vision=True)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank2]:     result = forward_call(*args, **kwargs)
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/moe/competesmoev27.py", line 299, in forward
[rank2]:     output = self.compute_moe(
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/moe/moe.py", line 159, in compute_moe
[rank2]:     results[batch_idx, token_idx] += weights[batch_idx, token_idx, topk_idx].unsqueeze(0).T * out_exp
[rank2]: RuntimeError: The size of tensor a (1152) must match the size of tensor b (1153) at non-singleton dimension 1
[rank1]: Traceback (most recent call last):
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/train_mem.py", line 11, in <module>
[rank1]:     train(attn_implementation="flash_attention_2")
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/train.py", line 1465, in train
[rank1]:     trainer.train()
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/transformers/trainer.py", line 1938, in train
[rank1]:     return inner_training_loop(
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 765, in _inner_training_loop
[rank1]:     tr_loss_step, ouput = self.training_step(model, inputs)
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 393, in training_step
[rank1]:     loss, ouput = self.compute_loss(model, inputs, return_outputs=True)
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 341, in compute_loss
[rank1]:     outputs = model(**inputs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank1]:     ret_val = func(*args, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1899, in forward
[rank1]:     loss = self.module(*inputs, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank1]:     result = forward_call(*args, **kwargs)
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/language_model/llava_phi.py", line 89, in forward
[rank1]:     ) = self.prepare_inputs_labels_for_multimodal(
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/llava_arch.py", line 251, in prepare_inputs_labels_for_multimodal
[rank1]:     image_features, auxiliary_loss_clip, vision_id_experts, balance_losses_clip = self.get_model().get_vision_tower()(images, return_id_experts = kwargs['return_id_experts'])
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank1]:     result = forward_call(*args, **kwargs)
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_encoder.py", line 113, in forward
[rank1]:     out_x, auxilarity_loss, vision_id_experts, balance_loss = self.vision_model( pixel_values = x,   return_id_experts = return_id_experts)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank1]:     result = forward_call(*args, **kwargs)
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 275, in forward
[rank1]:     encoder_outputs, auxiliary_losses, stored_history_experts, balance_losses = self.encoder(inputs_embeds = hidden_states, return_id_experts = return_id_experts)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank1]:     result = forward_call(*args, **kwargs)
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 180, in forward
[rank1]:     layer_outputs = encoder_layer(hidden_states = hidden_states)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank1]:     result = forward_call(*args, **kwargs)
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 141, in forward
[rank1]:     results, auxiliary_loss, id_experts, balance_loss = self.moelayer(hidden_states, return_id_experts, is_vision=True)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank1]:     result = forward_call(*args, **kwargs)
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/moe/competesmoev27.py", line 299, in forward
[rank1]:     output = self.compute_moe(
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/moe/moe.py", line 159, in compute_moe
[rank1]:     results[batch_idx, token_idx] += weights[batch_idx, token_idx, topk_idx].unsqueeze(0).T * out_exp
[rank1]: RuntimeError: The size of tensor a (1152) must match the size of tensor b (1153) at non-singleton dimension 1
[rank0]: Traceback (most recent call last):
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/train_mem.py", line 11, in <module>
[rank0]:     train(attn_implementation="flash_attention_2")
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/train.py", line 1465, in train
[rank0]:     trainer.train()
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/transformers/trainer.py", line 1938, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 765, in _inner_training_loop
[rank0]:     tr_loss_step, ouput = self.training_step(model, inputs)
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 393, in training_step
[rank0]:     loss, ouput = self.compute_loss(model, inputs, return_outputs=True)
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 341, in compute_loss
[rank0]:     outputs = model(**inputs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank0]:     ret_val = func(*args, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1899, in forward
[rank0]:     loss = self.module(*inputs, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/language_model/llava_phi.py", line 89, in forward
[rank0]:     ) = self.prepare_inputs_labels_for_multimodal(
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/llava_arch.py", line 251, in prepare_inputs_labels_for_multimodal
[rank0]:     image_features, auxiliary_loss_clip, vision_id_experts, balance_losses_clip = self.get_model().get_vision_tower()(images, return_id_experts = kwargs['return_id_experts'])
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_encoder.py", line 113, in forward
[rank0]:     out_x, auxilarity_loss, vision_id_experts, balance_loss = self.vision_model( pixel_values = x,   return_id_experts = return_id_experts)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 275, in forward
[rank0]:     encoder_outputs, auxiliary_losses, stored_history_experts, balance_losses = self.encoder(inputs_embeds = hidden_states, return_id_experts = return_id_experts)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 180, in forward
[rank0]:     layer_outputs = encoder_layer(hidden_states = hidden_states)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 141, in forward
[rank0]:     results, auxiliary_loss, id_experts, balance_loss = self.moelayer(hidden_states, return_id_experts, is_vision=True)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/moe/competesmoev27.py", line 299, in forward
[rank0]:     output = self.compute_moe(
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/moe/moe.py", line 159, in compute_moe
[rank0]:     results[batch_idx, token_idx] += weights[batch_idx, token_idx, topk_idx].unsqueeze(0).T * out_exp
[rank0]: RuntimeError: The size of tensor a (1152) must match the size of tensor b (1153) at non-singleton dimension 1
  0%|                                                                                                                                                                                                                                                                           | 0/16632 [00:07<?, ?it/s]
[2025-01-30 18:12:32,001] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 4124864
[2025-01-30 18:12:32,734] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 4124865
[2025-01-30 18:12:33,010] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 4124866
[2025-01-30 18:12:33,167] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 4124867
[2025-01-30 18:12:33,167] [ERROR] [launch.py:325:sigkill_handler] ['/home/anonymous/miniconda3/envs/moe/bin/python', '-u', 'moe_model/train/train_mem.py', '--local_rank=3', '--deepspeed', './scripts/zero3.json', '--model_name_or_path', '/cm/archive/anonymous/checkpoints/phi35-siglip224/pft', '--versio
n', 'phi35', '--data_path', '/cm/archive/anonymous/data/jsons/llava_v1_5_mix665k.json', '--image_folder', '/cm/archive/anonymous/data', '--vision_tower', 'google/siglip-so400m-patch14-224', '--vision_tower_dir', '/cm/archive/anonymous/checkpoints/phi35-siglip224/pft/clip.bin', '--scales', '1,3', '--norm
alization', 'true', '--pretrain_mm_mlp_adapter', '/cm/archive/anonymous/checkpoints/phi35-siglip224/pft/mm_projector.bin', '--mm_projector_type', 'moe', '--mlp_smoe', 'true', '--clip_smoe', 'true', '--moe_name', 'competesmoev27', '--num_experts', '4', '--num_selected', '2', '--warm_up', '0.0', '--ra
te_flip', '0.07', '--luna', 'true', '--sparse_upcycling', 'true', '--router_loss_coef', '0.01', '--balance_loss_coef', '0.01', '--router_z_loss_coef', '0.001', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--
group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', '/cm/archive/anonymous/checkpoints/Xphi35-siglip224/sft/Full_competesmoev27', '--num_train_epochs', '1', '--per_device_train_batch_size', '5', '--per_device_eval_batch_size', '1', '--gradient_accumulation_steps', '2', '--evaluation
_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '3328', '--save_total_limit', '16', '--learning_rate', '4e-6', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2048', '--gradient_checkp
ointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none', '--max_steps', '-1'] exits with return code = 1
Training failed. Restarting...
Staring stage sft
[2025-01-30 18:12:42,657] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-30 18:12:45,090] [WARNING] [runner.py:215:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2025-01-30 18:12:45,091] [INFO] [runner.py:607:main] cmd = /home/anonymous/miniconda3/envs/moe/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=29521 --enable_each_rank_log=None moe_model/train/train_mem.py --deepspee
d ./scripts/zero3.json --model_name_or_path /cm/archive/anonymous/checkpoints/phi35-siglip224/pft --version phi35 --data_path /cm/archive/anonymous/data/jsons/llava_v1_5_mix665k.json --image_folder /cm/archive/anonymous/data --vision_tower google/siglip-so400m-patch14-224 --vision_tower_dir /cm/archive/
anonymous/checkpoints/phi35-siglip224/pft/clip.bin --scales 1,3 --normalization true --pretrain_mm_mlp_adapter /cm/archive/anonymous/checkpoints/phi35-siglip224/pft/mm_projector.bin --mm_projector_type moe --mlp_smoe true --clip_smoe true --moe_name competesmoev27 --num_experts 4 --num_selected 2 --wa
rm_up 0.0 --rate_flip 0.07 --luna true --sparse_upcycling true --router_loss_coef 0.01 --balance_loss_coef 0.01 --router_z_loss_coef 0.001 --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True --ou
tput_dir /cm/archive/anonymous/checkpoints/Xphi35-siglip224/sft/Full_competesmoev27 --num_train_epochs 1 --per_device_train_batch_size 5 --per_device_eval_batch_size 1 --gradient_accumulation_steps 2 --evaluation_strategy no --save_strategy steps --save_steps 3328 --save_total_limit 16 --learning_ra
te 4e-6 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to none --max_steps -1
[2025-01-30 18:12:47,204] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-30 18:12:49,425] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}
[2025-01-30 18:12:49,425] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=4, node_rank=0
[2025-01-30 18:12:49,425] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2025-01-30 18:12:49,425] [INFO] [launch.py:164:main] dist_world_size=4
[2025-01-30 18:12:49,425] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
[2025-01-30 18:12:49,438] [INFO] [launch.py:256:main] process 4130575 spawned with command: ['/home/anonymous/miniconda3/envs/moe/bin/python', '-u', 'moe_model/train/train_mem.py', '--local_rank=0', '--deepspeed', './scripts/zero3.json', '--model_name_or_path', '/cm/archive/anonymous/checkpoints/phi35
-siglip224/pft', '--version', 'phi35', '--data_path', '/cm/archive/anonymous/data/jsons/llava_v1_5_mix665k.json', '--image_folder', '/cm/archive/anonymous/data', '--vision_tower', 'google/siglip-so400m-patch14-224', '--vision_tower_dir', '/cm/archive/anonymous/checkpoints/phi35-siglip224/pft/clip.bin',
'--scales', '1,3', '--normalization', 'true', '--pretrain_mm_mlp_adapter', '/cm/archive/anonymous/checkpoints/phi35-siglip224/pft/mm_projector.bin', '--mm_projector_type', 'moe', '--mlp_smoe', 'true', '--clip_smoe', 'true', '--moe_name', 'competesmoev27', '--num_experts', '4', '--num_selected', '2',
 '--warm_up', '0.0', '--rate_flip', '0.07', '--luna', 'true', '--sparse_upcycling', 'true', '--router_loss_coef', '0.01', '--balance_loss_coef', '0.01', '--router_z_loss_coef', '0.001', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image
_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', '/cm/archive/anonymous/checkpoints/Xphi35-siglip224/sft/Full_competesmoev27', '--num_train_epochs', '1', '--per_device_train_batch_size', '5', '--per_device_eval_batch_size', '1', '--gradient_accumulation_
steps', '2', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '3328', '--save_total_limit', '16', '--learning_rate', '4e-6', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length',
'2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none', '--max_steps', '-1']
[2025-01-30 18:12:49,448] [INFO] [launch.py:256:main] process 4130577 spawned with command: ['/home/anonymous/miniconda3/envs/moe/bin/python', '-u', 'moe_model/train/train_mem.py', '--local_rank=1', '--deepspeed', './scripts/zero3.json', '--model_name_or_path', '/cm/archive/anonymous/checkpoints/phi35
-siglip224/pft', '--version', 'phi35', '--data_path', '/cm/archive/anonymous/data/jsons/llava_v1_5_mix665k.json', '--image_folder', '/cm/archive/anonymous/data', '--vision_tower', 'google/siglip-so400m-patch14-224', '--vision_tower_dir', '/cm/archive/anonymous/checkpoints/phi35-siglip224/pft/clip.bin',
'--scales', '1,3', '--normalization', 'true', '--pretrain_mm_mlp_adapter', '/cm/archive/anonymous/checkpoints/phi35-siglip224/pft/mm_projector.bin', '--mm_projector_type', 'moe', '--mlp_smoe', 'true', '--clip_smoe', 'true', '--moe_name', 'competesmoev27', '--num_experts', '4', '--num_selected', '2',
 '--warm_up', '0.0', '--rate_flip', '0.07', '--luna', 'true', '--sparse_upcycling', 'true', '--router_loss_coef', '0.01', '--balance_loss_coef', '0.01', '--router_z_loss_coef', '0.001', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image
_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', '/cm/archive/anonymous/checkpoints/Xphi35-siglip224/sft/Full_competesmoev27', '--num_train_epochs', '1', '--per_device_train_batch_size', '5', '--per_device_eval_batch_size', '1', '--gradient_accumulation_
steps', '2', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '3328', '--save_total_limit', '16', '--learning_rate', '4e-6', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length',
'2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none', '--max_steps', '-1']
[2025-01-30 18:12:49,456] [INFO] [launch.py:256:main] process 4130578 spawned with command: ['/home/anonymous/miniconda3/envs/moe/bin/python', '-u', 'moe_model/train/train_mem.py', '--local_rank=2', '--deepspeed', './scripts/zero3.json', '--model_name_or_path', '/cm/archive/anonymous/checkpoints/phi35
-siglip224/pft', '--version', 'phi35', '--data_path', '/cm/archive/anonymous/data/jsons/llava_v1_5_mix665k.json', '--image_folder', '/cm/archive/anonymous/data', '--vision_tower', 'google/siglip-so400m-patch14-224', '--vision_tower_dir', '/cm/archive/anonymous/checkpoints/phi35-siglip224/pft/clip.bin',
'--scales', '1,3', '--normalization', 'true', '--pretrain_mm_mlp_adapter', '/cm/archive/anonymous/checkpoints/phi35-siglip224/pft/mm_projector.bin', '--mm_projector_type', 'moe', '--mlp_smoe', 'true', '--clip_smoe', 'true', '--moe_name', 'competesmoev27', '--num_experts', '4', '--num_selected', '2',
 '--warm_up', '0.0', '--rate_flip', '0.07', '--luna', 'true', '--sparse_upcycling', 'true', '--router_loss_coef', '0.01', '--balance_loss_coef', '0.01', '--router_z_loss_coef', '0.001', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image
_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', '/cm/archive/anonymous/checkpoints/Xphi35-siglip224/sft/Full_competesmoev27', '--num_train_epochs', '1', '--per_device_train_batch_size', '5', '--per_device_eval_batch_size', '1', '--gradient_accumulation_
steps', '2', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '3328', '--save_total_limit', '16', '--learning_rate', '4e-6', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length',
'2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none', '--max_steps', '-1']
[2025-01-30 18:12:49,464] [INFO] [launch.py:256:main] process 4130579 spawned with command: ['/home/anonymous/miniconda3/envs/moe/bin/python', '-u', 'moe_model/train/train_mem.py', '--local_rank=3', '--deepspeed', './scripts/zero3.json', '--model_name_or_path', '/cm/archive/anonymous/checkpoints/phi35
-siglip224/pft', '--version', 'phi35', '--data_path', '/cm/archive/anonymous/data/jsons/llava_v1_5_mix665k.json', '--image_folder', '/cm/archive/anonymous/data', '--vision_tower', 'google/siglip-so400m-patch14-224', '--vision_tower_dir', '/cm/archive/anonymous/checkpoints/phi35-siglip224/pft/clip.bin',
'--scales', '1,3', '--normalization', 'true', '--pretrain_mm_mlp_adapter', '/cm/archive/anonymous/checkpoints/phi35-siglip224/pft/mm_projector.bin', '--mm_projector_type', 'moe', '--mlp_smoe', 'true', '--clip_smoe', 'true', '--moe_name', 'competesmoev27', '--num_experts', '4', '--num_selected', '2',
 '--warm_up', '0.0', '--rate_flip', '0.07', '--luna', 'true', '--sparse_upcycling', 'true', '--router_loss_coef', '0.01', '--balance_loss_coef', '0.01', '--router_z_loss_coef', '0.001', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image
_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', '/cm/archive/anonymous/checkpoints/Xphi35-siglip224/sft/Full_competesmoev27', '--num_train_epochs', '1', '--per_device_train_batch_size', '5', '--per_device_eval_batch_size', '1', '--gradient_accumulation_
steps', '2', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '3328', '--save_total_limit', '16', '--learning_rate', '4e-6', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length',
'2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none', '--max_steps', '-1']
[2025-01-30 18:12:55,293] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-30 18:12:55,563] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-30 18:12:55,685] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-30 18:12:55,936] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /home/anonymous/.cache/huggingface/token
Login successful
/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[2025-01-30 18:12:56,817] [INFO] [comm.py:652:init_distributed] cdb=None
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /home/anonymous/.cache/huggingface/token
Login successful
/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[2025-01-30 18:12:57,100] [INFO] [comm.py:652:init_distributed] cdb=None
Token is valid (permission: fineGrained).
Your token has been saved to /home/anonymous/.cache/huggingface/token
Login successful
/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[2025-01-30 18:12:57,212] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-01-30 18:12:57,212] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Token is valid (permission: fineGrained).
Your token has been saved to /home/anonymous/.cache/huggingface/token
Login successful
/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[2025-01-30 18:12:57,400] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-01-30 18:12:58,783] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[2025-01-30 18:12:58,881] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[2025-01-30 18:12:59,504] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[2025-01-30 18:12:59,523] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
=========================================
=============SigLIP-vision_tower=========
=========================================
=========================================
=============SigLIP-vision_tower=========
=========================================
=========================================
=============SigLIP-vision_tower=========
=========================================
=========================================
=============SigLIP-vision_tower=========
=========================================
[2025-01-30 18:13:06,416] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 634, num_elems = 4.25B
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.13s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.13s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.13s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.15s/it]
Model: phi35
=========================================
=============SigLIP-vision_tower=========
=========================================
Model: phi35
=========================================
=============SigLIP-vision_tower=========
=========================================
Using Siglip Encoder MoE Layer
Model: phi35
=========================================
=============SigLIP-vision_tower=========
=========================================
Using Siglip Encoder MoE Layer
Using Siglip Encoder MoE Layer
Model: phi35
=========================================
=============SigLIP-vision_tower=========
=========================================
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Initializing weights and bias of the gating layer succefull
Initializing weights and bias of the gating layer succefull
Using Siglip Encoder MoE Layer
Initializing weights and bias of the gating layer succefull
Initializing weights and bias of the gating layer succefull
Loading weight MLP SMoE:   0%|                                                                                                                                                                                                                                                      | 0/4 [00:00<?, ?it/s]
Initializing weights and bias of the gating layer succefull
Loading weight MLP SMoE:  75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                           | 3/4 [00:00<00:00, 21.90it/s]
Initializing weights and bias of the gating layer succefull
Loading weight MLP SMoE: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 23.55it/s]
Initialization Luna:   0%|                                                                                                                                                                                                                                                          | 0/4 [00:00<?, ?it/s]
Initializing weights and bias of the gating layer succefull
Loading weight MLP SMoE: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 276.61it/s]
Loading weight MLP SMoE: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 38.41it/s]
Initialization Luna:  25%|████████████████████████████████████████████████████████████▌                                                                                                                                                                                     | 1/4 [00:00<00:00,  9.99it/s]
Initializing weights and bias of the gating layer succefull
Loading weight MLP SMoE: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 271.96it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 12.71it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 13.60it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 13.69it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 16.73it/s]
Loading weight /cm/archive/anonymous/checkpoints/phi35-siglip224/pft/clip.bin SMoE: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 813/813 [00:00<00:00, 1069962.08it/s]
Loading weight /cm/archive/anonymous/checkpoints/phi35-siglip224/pft/clip.bin SMoE: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 813/813 [00:00<00:00, 173473.53it/s]
Loading weight /cm/archive/anonymous/checkpoints/phi35-siglip224/pft/clip.bin SMoE: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 813/813 [00:00<00:00, 1013665.03it/s]
Loading weight /cm/archive/anonymous/checkpoints/phi35-siglip224/pft/clip.bin SMoE: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 813/813 [00:00<00:00, 1018509.30it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.13it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.10it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.83it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  6.20it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  7.14it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  7.59it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.14it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.23it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  7.96it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  7.74it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.05it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.97it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.29it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  7.98it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.63it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.28it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.35it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.30it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.14it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.37it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.78it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.28it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.34it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.18it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.10it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.40it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.92it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.50it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.11it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.73it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.35it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.25it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.28it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.51it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.94it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.73it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.60it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.68it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.62it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.42it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.87it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.71it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.07it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.04it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.21it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.48it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.58it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.90it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.53it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.07it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.87it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.35it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.15it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.59it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.30it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.03it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.12it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.33it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.70it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.90it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.58it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.95it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.36it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.44it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  7.84it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.46it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.73it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.53it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.73it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.27it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.48it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.41it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.71it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.34it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.52it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.62it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.62it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.98it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.33it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.77it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.03it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.30it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.30it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.76it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.43it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.66it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.52it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.47it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.17it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.83it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.04it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.79it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.56it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.33it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.77it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.08it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.09it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.75it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.96it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.03it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.02it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.58it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.73it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.73it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.44it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.68it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.13it/s]
Initialization Luna: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.29it/s]
Starting Trainer hyperrouter
Starting Trainer hyperrouter
Formatting inputs...Skip in lazy mode
Starting Trainer hyperrouter
Starting Trainer hyperrouter
Using /home/anonymous/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Using /home/anonymous/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/anonymous/.cache/torch_extensions/py39_cu121/fused_adam/build.ninja...
/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation.
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Using /home/anonymous/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
ninja: no work to do.
Loading extension module fused_adam...
Time to load fused_adam op: 1.5026905536651611 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 0.8030602931976318 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 0.10182714462280273 seconds
Using /home/anonymous/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/anonymous/.cache/torch_extensions/py39_cu121/fused_adam/build.ninja...
/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation.
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module fused_adam...
Time to load fused_adam op: 1.7020046710968018 seconds
Parameter Offload: Total persistent parameters: 1197232 in 534 params

Rate compute competition: 0.0689033189033189
Rate compute router policy: 0.9310966810966811
Step warm: 0


Rate compute competition: 0.0689033189033189
Rate compute router policy: 0.9310966810966811
Step warm: 0


Rate compute competition: 0.0689033189033189
Rate compute router policy: 0.9310966810966811
Step warm: 0

Rate compute competition: 0.0689033189033189
Rate compute router policy: 0.9310966810966811
Step warm: 0



Rate compute competition: 0.06938431938431938
Rate compute router policy: 0.9306156806156806
Step warm: 0


Rate compute competition: 0.06938431938431938
Rate compute router policy: 0.9306156806156806
Step warm: 0


Rate compute competition: 0.06938431938431938
Rate compute router policy: 0.9306156806156806
Step warm: 0


Rate compute competition: 0.06938431938431938
Rate compute router policy: 0.9306156806156806
Step warm: 0


Rate compute competition: 0.06872294372294373
Rate compute router policy: 0.9312770562770563
Step warm: 0


Rate compute competition: 0.06872294372294373
Rate compute router policy: 0.9312770562770563
Step warm: 0


Rate compute competition: 0.06872294372294373
Rate compute router policy: 0.9312770562770563
Step warm: 0


Rate compute competition: 0.06872294372294373
Rate compute router policy: 0.9312770562770563
Step warm: 0


Rate compute competition: 0.0707070707070707
Rate compute router policy: 0.9292929292929293
Step warm: 0


Rate compute competition: 0.0707070707070707
Rate compute router policy: 0.9292929292929293
Step warm: 0


Rate compute competition: 0.0707070707070707
Rate compute router policy: 0.9292929292929293
Step warm: 0


Rate compute competition: 0.0707070707070707
Rate compute router policy: 0.9292929292929293
Step warm: 0


Rate compute competition: 0.06601731601731602
Rate compute router policy: 0.933982683982684
Step warm: 0


Rate compute competition: 0.06601731601731602
Rate compute router policy: 0.933982683982684
Step warm: 0


Rate compute competition: 0.06601731601731602
Rate compute router policy: 0.933982683982684
Step warm: 0


Rate compute competition: 0.06601731601731602
Rate compute router policy: 0.933982683982684
Step warm: 0


Rate compute competition: 0.06968494468494468
Rate compute router policy: 0.9303150553150553
Step warm: 0


Rate compute competition: 0.06968494468494468
Rate compute router policy: 0.9303150553150553
Step warm: 0


Rate compute competition: 0.06968494468494468
Rate compute router policy: 0.9303150553150553
Step warm: 0


Rate compute competition: 0.06968494468494468
Rate compute router policy: 0.9303150553150553
Step warm: 0


Rate compute competition: 0.07311207311207311
Rate compute router policy: 0.9268879268879269
Step warm: 0


Rate compute competition: 0.07311207311207311
Rate compute router policy: 0.9268879268879269
Step warm: 0


Rate compute competition: 0.07311207311207311
Rate compute router policy: 0.9268879268879269
Step warm: 0


Rate compute competition: 0.07311207311207311
Rate compute router policy: 0.9268879268879269
Step warm: 0


Rate compute competition: 0.06752044252044252
Rate compute router policy: 0.9324795574795575
Step warm: 0


Rate compute competition: 0.06752044252044252
Rate compute router policy: 0.9324795574795575
Step warm: 0


Rate compute competition: 0.06752044252044252
Rate compute router policy: 0.9324795574795575
Step warm: 0

Rate compute competition: 0.06752044252044252
Rate compute router policy: 0.9324795574795575
Step warm: 0



Rate compute competition: 0.07215007215007214
Rate compute router policy: 0.9278499278499278
Step warm: 0


Rate compute competition: 0.07215007215007214
Rate compute router policy: 0.9278499278499278
Step warm: 0


Rate compute competition: 0.07215007215007214
Rate compute router policy: 0.9278499278499278
Step warm: 0


Rate compute competition: 0.07215007215007214
Rate compute router policy: 0.9278499278499278
Step warm: 0


Rate compute competition: 0.0674001924001924
Rate compute router policy: 0.9325998075998077
Step warm: 0


Rate compute competition: 0.0674001924001924
Rate compute router policy: 0.9325998075998077
Step warm: 0


Rate compute competition: 0.0674001924001924
Rate compute router policy: 0.9325998075998077
Step warm: 0


Rate compute competition: 0.0674001924001924
Rate compute router policy: 0.9325998075998077
Step warm: 0


Rate compute competition: 0.06962481962481963
Rate compute router policy: 0.9303751803751804
Step warm: 0


Rate compute competition: 0.06962481962481963
Rate compute router policy: 0.9303751803751804
Step warm: 0


Rate compute competition: 0.06962481962481963
Rate compute router policy: 0.9303751803751804
Step warm: 0


Rate compute competition: 0.06962481962481963
Rate compute router policy: 0.9303751803751804
Step warm: 0


Rate compute competition: 0.06896344396344396
Rate compute router policy: 0.931036556036556
Step warm: 0


Rate compute competition: 0.06896344396344396
Rate compute router policy: 0.931036556036556
Step warm: 0


Rate compute competition: 0.06896344396344396
Rate compute router policy: 0.931036556036556
Step warm: 0

Rate compute competition: 0.06896344396344396
Rate compute router policy: 0.931036556036556
Step warm: 0



Rate compute competition: 0.07287157287157287
Rate compute router policy: 0.9271284271284271
Step warm: 0


Rate compute competition: 0.07287157287157287
Rate compute router policy: 0.9271284271284271
Step warm: 0


Rate compute competition: 0.07287157287157287
Rate compute router policy: 0.9271284271284271
Step warm: 0


Rate compute competition: 0.07287157287157287
Rate compute router policy: 0.9271284271284271
Step warm: 0


Rate compute competition: 0.06914381914381915
Rate compute router policy: 0.9308561808561808
Step warm: 0


Rate compute competition: 0.06914381914381915
Rate compute router policy: 0.9308561808561808
Step warm: 0


Rate compute competition: 0.06914381914381915
Rate compute router policy: 0.9308561808561808
Step warm: 0

Rate compute competition: 0.06914381914381915
Rate compute router policy: 0.9308561808561808
Step warm: 0



Rate compute competition: 0.06655844155844155
Rate compute router policy: 0.9334415584415584
Step warm: 0


Rate compute competition: 0.06655844155844155
Rate compute router policy: 0.9334415584415584
Step warm: 0


Rate compute competition: 0.06655844155844155
Rate compute router policy: 0.9334415584415584
Step warm: 0


Rate compute competition: 0.06655844155844155
Rate compute router policy: 0.9334415584415584
Step warm: 0


Rate compute competition: 0.07052669552669552
Rate compute router policy: 0.9294733044733045
Step warm: 0


Rate compute competition: 0.07052669552669552
Rate compute router policy: 0.9294733044733045
Step warm: 0


Rate compute competition: 0.07052669552669552
Rate compute router policy: 0.9294733044733045
Step warm: 0


Rate compute competition: 0.07052669552669552
Rate compute router policy: 0.9294733044733045
Step warm: 0


Rate compute competition: 0.07028619528619529
Rate compute router policy: 0.9297138047138047
Step warm: 0


Rate compute competition: 0.07028619528619529
Rate compute router policy: 0.9297138047138047
Step warm: 0


Rate compute competition: 0.07028619528619529
Rate compute router policy: 0.9297138047138047
Step warm: 0


Rate compute competition: 0.07028619528619529
Rate compute router policy: 0.9297138047138047
Step warm: 0


Rate compute competition: 0.06854256854256854
Rate compute router policy: 0.9314574314574314
Step warm: 0


Rate compute competition: 0.06854256854256854
Rate compute router policy: 0.9314574314574314
Step warm: 0


Rate compute competition: 0.06854256854256854
Rate compute router policy: 0.9314574314574314
Step warm: 0

Rate compute competition: 0.06854256854256854
Rate compute router policy: 0.9314574314574314
Step warm: 0



Rate compute competition: 0.0732924482924483
Rate compute router policy: 0.9267075517075517
Step warm: 0


Rate compute competition: 0.0732924482924483
Rate compute router policy: 0.9267075517075517
Step warm: 0


Rate compute competition: 0.0732924482924483
Rate compute router policy: 0.9267075517075517
Step warm: 0


Rate compute competition: 0.0732924482924483
Rate compute router policy: 0.9267075517075517
Step warm: 0


Rate compute competition: 0.07016594516594517
Rate compute router policy: 0.9298340548340548
Step warm: 0


Rate compute competition: 0.07016594516594517
Rate compute router policy: 0.9298340548340548
Step warm: 0


Rate compute competition: 0.07016594516594517
Rate compute router policy: 0.9298340548340548
Step warm: 0


Rate compute competition: 0.07016594516594517
Rate compute router policy: 0.9298340548340548
Step warm: 0


Rate compute competition: 0.07202982202982203
Rate compute router policy: 0.927970177970178
Step warm: 0


Rate compute competition: 0.07202982202982203
Rate compute router policy: 0.927970177970178
Step warm: 0


Rate compute competition: 0.07202982202982203
Rate compute router policy: 0.927970177970178
Step warm: 0


Rate compute competition: 0.07202982202982203
Rate compute router policy: 0.927970177970178
Step warm: 0


Rate compute competition: 0.0692039442039442
Rate compute router policy: 0.9307960557960558
Step warm: 0


Rate compute competition: 0.0692039442039442
Rate compute router policy: 0.9307960557960558
Step warm: 0


Rate compute competition: 0.0692039442039442
Rate compute router policy: 0.9307960557960558
Step warm: 0


Rate compute competition: 0.0692039442039442
Rate compute router policy: 0.9307960557960558
Step warm: 0


Rate compute competition: 0.07016594516594517
Rate compute router policy: 0.9298340548340548
Step warm: 0


Rate compute competition: 0.07016594516594517
Rate compute router policy: 0.9298340548340548
Step warm: 0


Rate compute competition: 0.07016594516594517
Rate compute router policy: 0.9298340548340548
Step warm: 0


Rate compute competition: 0.07016594516594517
Rate compute router policy: 0.9298340548340548
Step warm: 0


Rate compute competition: 0.06908369408369408
Rate compute router policy: 0.9309163059163059
Step warm: 0


Rate compute competition: 0.06908369408369408
Rate compute router policy: 0.9309163059163059
Step warm: 0


Rate compute competition: 0.06908369408369408
Rate compute router policy: 0.9309163059163059
Step warm: 0


Rate compute competition: 0.06908369408369408
Rate compute router policy: 0.9309163059163059
Step warm: 0


Rate compute competition: 0.06896344396344396
Rate compute router policy: 0.931036556036556
Step warm: 0


Rate compute competition: 0.06896344396344396
Rate compute router policy: 0.931036556036556
Step warm: 0


Rate compute competition: 0.06896344396344396
Rate compute router policy: 0.931036556036556
Step warm: 0

Rate compute competition: 0.06896344396344396
Rate compute router policy: 0.931036556036556
Step warm: 0



Rate compute competition: 0.0689033189033189
Rate compute router policy: 0.9310966810966811
Step warm: 0


Rate compute competition: 0.0689033189033189
Rate compute router policy: 0.9310966810966811
Step warm: 0


Rate compute competition: 0.0689033189033189
Rate compute router policy: 0.9310966810966811
Step warm: 0


Rate compute competition: 0.0689033189033189
Rate compute router policy: 0.9310966810966811
Step warm: 0


Rate compute competition: 0.07112794612794612
Rate compute router policy: 0.9288720538720538
Step warm: 0


Rate compute competition: 0.07112794612794612
Rate compute router policy: 0.9288720538720538
Step warm: 0


Rate compute competition: 0.07112794612794612
Rate compute router policy: 0.9288720538720538
Step warm: 0


Rate compute competition: 0.07112794612794612
Rate compute router policy: 0.9288720538720538
Step warm: 0


Rate compute competition: 0.06932419432419433
Rate compute router policy: 0.9306758056758057
Step warm: 0


Rate compute competition: 0.06932419432419433
Rate compute router policy: 0.9306758056758057
Step warm: 0


Rate compute competition: 0.06932419432419433
Rate compute router policy: 0.9306758056758057
Step warm: 0


Rate compute competition: 0.06932419432419433
Rate compute router policy: 0.9306758056758057
Step warm: 0

  0%|                                                                                                                                                                                                                                                                           | 0/16632 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs0000000158240de80021ea2d'
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs0000000159830fdc0021ea2c'
OSError: [Errno 16] Device or resource busy: '.nfs000000015315dcf50021ea2e'
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs0000000158240df00021ea2f'
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs000000015315dcf00021ea30'
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
OSError: [Errno 16] Device or resource busy: '.nfs0000000158240dea0021ea31'
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs0000000159830fde0021ea32'
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs0000000159830fe00021ea33'
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs000000015315dced0021ea34'
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs0000000159830fdb0021ea35'
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs0000000159830fda0021ea36'
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs000000015315dcec0021ea37'
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs0000000158240dec0021ea38'
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs000000015315dcf30021ea39'
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs0000000159830fe20021ea3a'
Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 734, in rmtree
    _rmtree_safe_fd(fd, path, onerror)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 690, in _rmtree_safe_fd
    onerror(os.unlink, fullname, sys.exc_info())
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/shutil.py", line 688, in _rmtree_safe_fd
    os.unlink(entry.name, dir_fd=topfd)
OSError: [Errno 16] Device or resource busy: '.nfs0000000158240ded0021ea3b'
[rank3]: Traceback (most recent call last):
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/train_mem.py", line 11, in <module>
[rank3]:     train(attn_implementation="flash_attention_2")
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/train.py", line 1465, in train
[rank3]:     trainer.train()
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/transformers/trainer.py", line 1938, in train
[rank3]:     return inner_training_loop(
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 765, in _inner_training_loop
[rank3]:     tr_loss_step, ouput = self.training_step(model, inputs)
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 393, in training_step
[rank3]:     loss, ouput = self.compute_loss(model, inputs, return_outputs=True)
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 341, in compute_loss
[rank3]:     outputs = model(**inputs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank3]:     ret_val = func(*args, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1899, in forward
[rank3]:     loss = self.module(*inputs, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/language_model/llava_phi.py", line 89, in forward
[rank3]:     ) = self.prepare_inputs_labels_for_multimodal(
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/llava_arch.py", line 251, in prepare_inputs_labels_for_multimodal
[rank3]:     image_features, auxiliary_loss_clip, vision_id_experts, balance_losses_clip = self.get_model().get_vision_tower()(images, return_id_experts = kwargs['return_id_experts'])
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_encoder.py", line 113, in forward
[rank3]:     out_x, auxilarity_loss, vision_id_experts, balance_loss = self.vision_model( pixel_values = x,   return_id_experts = return_id_experts)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 275, in forward
[rank3]:     encoder_outputs, auxiliary_losses, stored_history_experts, balance_losses = self.encoder(inputs_embeds = hidden_states, return_id_experts = return_id_experts)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 180, in forward
[rank3]:     layer_outputs = encoder_layer(hidden_states = hidden_states)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 141, in forward
[rank3]:     results, auxiliary_loss, id_experts, balance_loss = self.moelayer(hidden_states, return_id_experts, is_vision=True)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/moe/competesmoev27.py", line 299, in forward
[rank3]:     output = self.compute_moe(
[rank3]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/moe/moe.py", line 159, in compute_moe
[rank3]:     results[batch_idx, token_idx] += weights[batch_idx, token_idx, topk_idx].unsqueeze(0).T * out_exp
[rank3]: RuntimeError: The size of tensor a (1152) must match the size of tensor b (1153) at non-singleton dimension 1
[rank2]: Traceback (most recent call last):
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/train_mem.py", line 11, in <module>
[rank2]:     train(attn_implementation="flash_attention_2")
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/train.py", line 1465, in train
[rank2]:     trainer.train()
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/transformers/trainer.py", line 1938, in train
[rank2]:     return inner_training_loop(
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 765, in _inner_training_loop
[rank2]:     tr_loss_step, ouput = self.training_step(model, inputs)
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 393, in training_step
[rank2]:     loss, ouput = self.compute_loss(model, inputs, return_outputs=True)
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 341, in compute_loss
[rank2]:     outputs = model(**inputs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank2]:     ret_val = func(*args, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1899, in forward
[rank2]:     loss = self.module(*inputs, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank2]:     result = forward_call(*args, **kwargs)
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/language_model/llava_phi.py", line 89, in forward
[rank2]:     ) = self.prepare_inputs_labels_for_multimodal(
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/llava_arch.py", line 251, in prepare_inputs_labels_for_multimodal
[rank2]:     image_features, auxiliary_loss_clip, vision_id_experts, balance_losses_clip = self.get_model().get_vision_tower()(images, return_id_experts = kwargs['return_id_experts'])
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank2]:     result = forward_call(*args, **kwargs)
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_encoder.py", line 113, in forward
[rank2]:     out_x, auxilarity_loss, vision_id_experts, balance_loss = self.vision_model( pixel_values = x,   return_id_experts = return_id_experts)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank2]:     result = forward_call(*args, **kwargs)
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 275, in forward
[rank2]:     encoder_outputs, auxiliary_losses, stored_history_experts, balance_losses = self.encoder(inputs_embeds = hidden_states, return_id_experts = return_id_experts)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank2]:     result = forward_call(*args, **kwargs)
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 180, in forward
[rank2]:     layer_outputs = encoder_layer(hidden_states = hidden_states)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank2]:     result = forward_call(*args, **kwargs)
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 141, in forward
[rank2]:     results, auxiliary_loss, id_experts, balance_loss = self.moelayer(hidden_states, return_id_experts, is_vision=True)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank2]:     result = forward_call(*args, **kwargs)
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/moe/competesmoev27.py", line 299, in forward
[rank2]:     output = self.compute_moe(
[rank2]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/moe/moe.py", line 159, in compute_moe
[rank2]:     results[batch_idx, token_idx] += weights[batch_idx, token_idx, topk_idx].unsqueeze(0).T * out_exp
[rank2]: RuntimeError: The size of tensor a (1152) must match the size of tensor b (1153) at non-singleton dimension 1
[rank1]: Traceback (most recent call last):
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/train_mem.py", line 11, in <module>
[rank1]:     train(attn_implementation="flash_attention_2")
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/train.py", line 1465, in train
[rank1]:     trainer.train()
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/transformers/trainer.py", line 1938, in train
[rank1]:     return inner_training_loop(
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 765, in _inner_training_loop
[rank1]:     tr_loss_step, ouput = self.training_step(model, inputs)
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 393, in training_step
[rank1]:     loss, ouput = self.compute_loss(model, inputs, return_outputs=True)
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 341, in compute_loss
[rank1]:     outputs = model(**inputs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank1]:     ret_val = func(*args, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1899, in forward
[rank1]:     loss = self.module(*inputs, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank1]:     result = forward_call(*args, **kwargs)
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/language_model/llava_phi.py", line 89, in forward
[rank1]:     ) = self.prepare_inputs_labels_for_multimodal(
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/llava_arch.py", line 251, in prepare_inputs_labels_for_multimodal
[rank1]:     image_features, auxiliary_loss_clip, vision_id_experts, balance_losses_clip = self.get_model().get_vision_tower()(images, return_id_experts = kwargs['return_id_experts'])
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank1]:     result = forward_call(*args, **kwargs)
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_encoder.py", line 113, in forward
[rank1]:     out_x, auxilarity_loss, vision_id_experts, balance_loss = self.vision_model( pixel_values = x,   return_id_experts = return_id_experts)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank1]:     result = forward_call(*args, **kwargs)
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 275, in forward
[rank1]:     encoder_outputs, auxiliary_losses, stored_history_experts, balance_losses = self.encoder(inputs_embeds = hidden_states, return_id_experts = return_id_experts)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank1]:     result = forward_call(*args, **kwargs)
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 180, in forward
[rank1]:     layer_outputs = encoder_layer(hidden_states = hidden_states)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank1]:     result = forward_call(*args, **kwargs)
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 141, in forward
[rank1]:     results, auxiliary_loss, id_experts, balance_loss = self.moelayer(hidden_states, return_id_experts, is_vision=True)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank1]:     result = forward_call(*args, **kwargs)
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/moe/competesmoev27.py", line 299, in forward
[rank1]:     output = self.compute_moe(
[rank1]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/moe/moe.py", line 159, in compute_moe
[rank1]:     results[batch_idx, token_idx] += weights[batch_idx, token_idx, topk_idx].unsqueeze(0).T * out_exp
[rank1]: RuntimeError: The size of tensor a (1152) must match the size of tensor b (1153) at non-singleton dimension 1
[rank0]: Traceback (most recent call last):
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/train_mem.py", line 11, in <module>
[rank0]:     train(attn_implementation="flash_attention_2")
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/train.py", line 1465, in train
[rank0]:     trainer.train()
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/transformers/trainer.py", line 1938, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 765, in _inner_training_loop
[rank0]:     tr_loss_step, ouput = self.training_step(model, inputs)
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 393, in training_step
[rank0]:     loss, ouput = self.compute_loss(model, inputs, return_outputs=True)
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/train/llava_trainer.py", line 341, in compute_loss
[rank0]:     outputs = model(**inputs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank0]:     ret_val = func(*args, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1899, in forward
[rank0]:     loss = self.module(*inputs, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/language_model/llava_phi.py", line 89, in forward
[rank0]:     ) = self.prepare_inputs_labels_for_multimodal(
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/llava_arch.py", line 251, in prepare_inputs_labels_for_multimodal
[rank0]:     image_features, auxiliary_loss_clip, vision_id_experts, balance_losses_clip = self.get_model().get_vision_tower()(images, return_id_experts = kwargs['return_id_experts'])
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_encoder.py", line 113, in forward
[rank0]:     out_x, auxilarity_loss, vision_id_experts, balance_loss = self.vision_model( pixel_values = x,   return_id_experts = return_id_experts)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 275, in forward
[rank0]:     encoder_outputs, auxiliary_losses, stored_history_experts, balance_losses = self.encoder(inputs_embeds = hidden_states, return_id_experts = return_id_experts)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 180, in forward
[rank0]:     layer_outputs = encoder_layer(hidden_states = hidden_states)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/multimodal_encoder/siglip_smoe.py", line 141, in forward
[rank0]:     results, auxiliary_loss, id_experts, balance_loss = self.moelayer(hidden_states, return_id_experts, is_vision=True)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/moe/competesmoev27.py", line 299, in forward
[rank0]:     output = self.compute_moe(
[rank0]:   File "/cm/shared/anonymous_H102/toolkitmoe/moe_model/model/moe/moe.py", line 159, in compute_moe
[rank0]:     results[batch_idx, token_idx] += weights[batch_idx, token_idx, topk_idx].unsqueeze(0).T * out_exp
[rank0]: RuntimeError: The size of tensor a (1152) must match the size of tensor b (1153) at non-singleton dimension 1
  0%|                                                                                                                                                                                                                                                                           | 0/16632 [00:08<?, ?it/s]
[2025-01-30 18:14:32,569] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 4130575
[2025-01-30 18:14:33,522] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 4130577
[2025-01-30 18:14:33,522] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 4130578
[2025-01-30 18:14:33,675] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 4130579
[2025-01-30 18:14:33,825] [ERROR] [launch.py:325:sigkill_handler] ['/home/anonymous/miniconda3/envs/moe/bin/python', '-u', 'moe_model/train/train_mem.py', '--local_rank=3', '--deepspeed', './scripts/zero3.json', '--model_name_or_path', '/cm/archive/anonymous/checkpoints/phi35-siglip224/pft', '--versio
n', 'phi35', '--data_path', '/cm/archive/anonymous/data/jsons/llava_v1_5_mix665k.json', '--image_folder', '/cm/archive/anonymous/data', '--vision_tower', 'google/siglip-so400m-patch14-224', '--vision_tower_dir', '/cm/archive/anonymous/checkpoints/phi35-siglip224/pft/clip.bin', '--scales', '1,3', '--norm
alization', 'true', '--pretrain_mm_mlp_adapter', '/cm/archive/anonymous/checkpoints/phi35-siglip224/pft/mm_projector.bin', '--mm_projector_type', 'moe', '--mlp_smoe', 'true', '--clip_smoe', 'true', '--moe_name', 'competesmoev27', '--num_experts', '4', '--num_selected', '2', '--warm_up', '0.0', '--ra
te_flip', '0.07', '--luna', 'true', '--sparse_upcycling', 'true', '--router_loss_coef', '0.01', '--balance_loss_coef', '0.01', '--router_z_loss_coef', '0.001', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--
group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', '/cm/archive/anonymous/checkpoints/Xphi35-siglip224/sft/Full_competesmoev27', '--num_train_epochs', '1', '--per_device_train_batch_size', '5', '--per_device_eval_batch_size', '1', '--gradient_accumulation_steps', '2', '--evaluation
_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '3328', '--save_total_limit', '16', '--learning_rate', '4e-6', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2048', '--gradient_checkp
ointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none', '--max_steps', '-1'] exits with return code = 1
Training failed. Restarting...
Staring stage sft
[2025-01-30 18:14:43,717] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-30 18:14:46,147] [WARNING] [runner.py:215:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2025-01-30 18:14:46,147] [INFO] [runner.py:607:main] cmd = /home/anonymous/miniconda3/envs/moe/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=29521 --enable_each_rank_log=None moe_model/train/train_mem.py --deepspee
d ./scripts/zero3.json --model_name_or_path /cm/archive/anonymous/checkpoints/phi35-siglip224/pft --version phi35 --data_path /cm/archive/anonymous/data/jsons/llava_v1_5_mix665k.json --image_folder /cm/archive/anonymous/data --vision_tower google/siglip-so400m-patch14-224 --vision_tower_dir /cm/archive/
anonymous/checkpoints/phi35-siglip224/pft/clip.bin --scales 1,3 --normalization true --pretrain_mm_mlp_adapter /cm/archive/anonymous/checkpoints/phi35-siglip224/pft/mm_projector.bin --mm_projector_type moe --mlp_smoe true --clip_smoe true --moe_name competesmoev27 --num_experts 4 --num_selected 2 --wa
rm_up 0.0 --rate_flip 0.07 --luna true --sparse_upcycling true --router_loss_coef 0.01 --balance_loss_coef 0.01 --router_z_loss_coef 0.001 --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True --ou
tput_dir /cm/archive/anonymous/checkpoints/Xphi35-siglip224/sft/Full_competesmoev27 --num_train_epochs 1 --per_device_train_batch_size 5 --per_device_eval_batch_size 1 --gradient_accumulation_steps 2 --evaluation_strategy no --save_strategy steps --save_steps 3328 --save_total_limit 16 --learning_ra
te 4e-6 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to none --max_steps -1
^CTraceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/runpy.py", line 188, in _run_module_as_main
    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/runpy.py", line 111, in _get_module_details
    __import__(pkg_name)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/__init__.py", line 25, in <module>
    from . import ops
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/ops/__init__.py", line 6, in <module>
    from . import adam
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/ops/adam/__init__.py", line 6, in <module>
    from .cpu_adam import DeepSpeedCPUAdam
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/ops/adam/cpu_adam.py", line 8, in <module>
    from deepspeed.utils import logger
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/utils/__init__.py", line 10, in <module>
    from .groups import *
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/utils/groups.py", line 28, in <module>
    from deepspeed import comm as dist
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/comm/__init__.py", line 7, in <module>
    from .comm import *
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/comm/comm.py", line 31, in <module>
    from deepspeed.comm.ccl import CCLBackend
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/comm/ccl.py", line 11, in <module>
    from deepspeed.ops.op_builder import NotImplementedBuilder
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/ops/op_builder/__init__.py", line 53, in <module>
    this_module.__dict__[member_name] = builder_closure(member_name)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/ops/op_builder/__init__.py", line 41, in builder_closure
    builder = get_accelerator().get_op_builder(member_name)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/accelerator/real_accelerator.py", line 170, in get_accelerator
    if torch.cuda.is_available():  #ignore-cuda
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/cuda/__init__.py", line 118, in is_available
    return torch._C._cuda_getDeviceCount() > 0
KeyboardInterrupt
^CTraceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/subprocess.py", line 1189, in wait
    return self._wait(timeout=timeout)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/subprocess.py", line 1933, in _wait
    (pid, sts) = self._try_wait(0)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/subprocess.py", line 1891, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/anonymous/miniconda3/envs/moe/bin/deepspeed", line 6, in <module>
    main()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/launcher/runner.py", line 623, in main
    result.wait()
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/subprocess.py", line 1202, in wait
    self._wait(timeout=sigint_timeout)
  File "/home/anonymous/miniconda3/envs/moe/lib/python3.9/subprocess.py", line 1927, in _wait
    time.sleep(delay)
KeyboardInterrupt
^C^C^C^C
(moe) anonymous@SPP00018465:/cm/shared/anonymous_H102/toolkitmoe$ ^C
(moe) anonymous@SPP00018465:/cm/shared/anonymous_H102/toolkitmoe$ ^C
(moe) anonymous@SPP00018465:/cm/shared/anonymous_H102/toolkitmoe$ ^C
(moe) anonymous@SPP00018465:/cm/shared/anonymous_H102/toolkitmoe$
