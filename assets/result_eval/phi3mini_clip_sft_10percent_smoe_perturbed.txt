(base) anonymous@ithndgx004:/cm/archive/anonymous/CUMO$ conda activate cumo
(cumo) anonymous@ithndgx004:/cm/archive/anonymous/CUMO$ bash /cm/archive/anonymous/CUMO/scripts/cumo/phi3mini/clip/sft_phi3mini.sh
[2024-10-07 00:49:53,110] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-07 00:49:59,223] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-10-07 00:49:59,300] [INFO] [runner.py:568:main] cmd = /cm/archive/anonymous/miniconda3/envs/cumo/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOi
BbNV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None cumo/train/train_mem.py --deepspeed ./scripts/zero3_offload.json --model_name_or_path /cm/archiv
e/anonymous/checkpoints/phi3mini-clip/pft --version phi3 --data_path /cm/archive/anonymous/data/jsons/llava_v1_5_mix665k_half.json --image_folder /cm/archive/anonymous/data --vision
_tower openai/clip-vit-large-patch14-336 --vision_tower_dir /cm/archive/anonymous/checkpoints/phi3mini-clip/pft/clip.bin --scales 1,3 --pretrain_mm_mlp_adapter /cm/archive/namnv
78/checkpoints/phi3mini-clip/pft/mm_projector.bin --mm_projector_type smoe_mlp --mlp_smoe smoe --clip_smoe smoe --num_experts 4 --num_selected 2 --balance_loss_coef 0.1 --rout
er_z_loss_coef 0.01 --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True
--output_dir /cm/archive/anonymous/CUMO/checkpoints/cumo-phi3-mini-sft-test1 --num_train_epochs 1 --per_device_train_batch_size 5 --per_device_eval_batch_size 4 --gradient_accum
ulation_steps 2 --evaluation_strategy no --save_strategy steps --save_steps 500 --save_total_limit 1 --learning_rate 4e-6 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_
type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to none
[2024-10-07 00:50:03,286] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-07 00:50:04,262] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [5]}
[2024-10-07 00:50:04,262] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0
[2024-10-07 00:50:04,262] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2024-10-07 00:50:04,262] [INFO] [launch.py:163:main] dist_world_size=1
[2024-10-07 00:50:04,262] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=5
[2024-10-07 00:50:04,272] [INFO] [launch.py:253:main] process 2040121 spawned with command: ['/cm/archive/anonymous/miniconda3/envs/cumo/bin/python', '-u', 'cumo/train/train_mem
.py', '--local_rank=0', '--deepspeed', './scripts/zero3_offload.json', '--model_name_or_path', '/cm/archive/anonymous/checkpoints/phi3mini-clip/pft', '--version', 'phi3', '--dat
a_path', '/cm/archive/anonymous/data/jsons/llava_v1_5_mix665k_half.json', '--image_folder', '/cm/archive/anonymous/data', '--vision_tower', 'openai/clip-vit-large-patch14-336', '-
-vision_tower_dir', '/cm/archive/anonymous/checkpoints/phi3mini-clip/pft/clip.bin', '--scales', '1,3', '--pretrain_mm_mlp_adapter', '/cm/archive/anonymous/checkpoints/phi3mini-cli
p/pft/mm_projector.bin', '--mm_projector_type', 'smoe_mlp', '--mlp_smoe', 'smoe', '--clip_smoe', 'smoe', '--num_experts', '4', '--num_selected', '2', '--balance_loss_coef', '0
.1', '--router_z_loss_coef', '0.01', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--
group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', '/cm/archive/anonymous/CUMO/checkpoints/cumo-phi3-mini-sft-test1', '--num_train_epochs', '1', '--per_device_
train_batch_size', '5', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '2', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '
500', '--save_total_limit', '1', '--learning_rate', '4e-6', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32'
, 'True', '--model_max_length', '2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none']
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-
cli` if you want to set the git credential as well.
Token is valid (permission: read).
Your token has been saved to /home/anonymous/.cache/huggingface/token
Login successful
/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed
 in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
[2024-10-07 00:50:14,862] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-07 00:50:15,448] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-10-07 00:50:15,448] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
=========================================
=============CLIP-vision_tower=========
=========================================
/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed
in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2024-10-07 00:50:22,853] [INFO] [partition_parameters.py:343:__exit__] finished initializing model - num_params = 588, num_elems = 4.14B
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.31s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Model: phi3
=========================================
=============CLIP-vision_tower=========
=========================================
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using MLP MoE
Loading weight MLP SMoE
Load weight vision tower /cm/archive/anonymous/checkpoints/phi3mini-clip/pft/clip.bin
Loading weight clip SMoE
Formatting inputs...Skip in lazy mode
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum vers
ion or higher.
Using /home/anonymous/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
^C[2024-10-07 01:05:11,666] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 2040121
Traceback (most recent call last):
  File "/cm/archive/anonymous/CUMO/cumo/train/train_mem.py", line 7, in <module>
    train(attn_implementation="flash_attention_2")
  File "/cm/archive/anonymous/CUMO/cumo/train/train.py", line 1309, in train
    trainer.train()
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/transformers/trainer.py", line 1885, in train
    return inner_training_loop(
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/transformers/trainer.py", line 2045, in _inner_training_loop
    model, self.optimizer, self.lr_scheduler = self.accelerator.prepare(
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/accelerate/accelerator.py", line 1291, in prepare
    result = self._prepare_deepspeed(*args)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/accelerate/accelerator.py", line 1758, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/__init__.py", line 176, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 307, in __init__
    self._configure_optimizer(optimizer, model_parameters)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1230, in _configure_optimizer
    basic_optimizer = self._configure_basic_optimizer(model_parameters)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1301, in _configure_basic_optimizer
    optimizer = DeepSpeedCPUAdam(model_parameters,
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/ops/adam/cpu_adam.py", line 94, in __init__
    self.ds_opt_adam = CPUAdamBuilder().load()
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/ops/op_builder/builder.py", line 479, in load
    return self.jit_load(verbose)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/ops/op_builder/builder.py", line 523, in jit_load
    op_module = load(name=self.name,
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/torch/utils/cpp_extension.py", line 1308, in load
    return _jit_compile(
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/torch/utils/cpp_extension.py", line 1724, in _jit_compile
    baton.wait()
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/torch/utils/file_baton.py", line 42, in wait
    time.sleep(self.wait_seconds)
KeyboardInterrupt
^CTraceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/subprocess.py", line 1189, in wait
[2024-10-07 01:05:11,856] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 2040121
    return self._wait(timeout=timeout)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/subprocess.py", line 1933, in _wait
    (pid, sts) = self._try_wait(0)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/subprocess.py", line 1891, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/cumo/bin/deepspeed", line 6, in <module>
    main()
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/launcher/runner.py", line 584, in main
    result.wait()
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/subprocess.py", line 1202, in wait
    self._wait(timeout=sigint_timeout)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/subprocess.py", line 1927, in _wait
    time.sleep(delay)
KeyboardInterrupt
^C[2024-10-07 01:05:12,029] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 2040121
^C[2024-10-07 01:05:12,202] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 2040121

(cumo) anonymous@ithndgx004:/cm/archive/anonymous/CUMO$ ^C
(cumo) anonymous@ithndgx004:/cm/archive/anonymous/CUMO$ ^C
(cumo) anonymous@ithndgx004:/cm/archive/anonymous/CUMO$ ^C
(cumo) anonymous@ithndgx004:/cm/archive/anonymous/CUMO$ [2024-10-07 01:05:15,011] [INFO] [launch.py:325:sigkill_handler] Main process received SIGINT, exiting
^C
(cumo) anonymous@ithndgx004:/cm/archive/anonymous/CUMO$ clear
(cumo) anonymous@ithndgx004:/cm/archive/anonymous/CUMO$ bash /cm/archive/anonymous/CUMO/scripts/cumo/phi3mini/clip/sft_phi3mini.sh
[2024-10-07 01:05:52,852] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-07 01:05:55,072] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-10-07 01:05:55,233] [INFO] [runner.py:568:main] cmd = /cm/archive/anonymous/miniconda3/envs/cumo/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOi
BbNV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None cumo/train/train_mem.py --deepspeed ./scripts/zero3_offload.json --model_name_or_path /cm/archiv
e/anonymous/checkpoints/phi3mini-clip/pft --version phi3 --data_path /cm/archive/anonymous/data/jsons/llava_v1_5_mix665k_half.json --image_folder /cm/archive/anonymous/data --vision
_tower openai/clip-vit-large-patch14-336 --vision_tower_dir /cm/archive/anonymous/checkpoints/phi3mini-clip/pft/clip.bin --scales 1,3 --pretrain_mm_mlp_adapter /cm/archive/namnv
78/checkpoints/phi3mini-clip/pft/mm_projector.bin --mm_projector_type smoe_mlp --mlp_smoe smoe --clip_smoe smoe --num_experts 4 --num_selected 2 --balance_loss_coef 0.1 --rout
er_z_loss_coef 0.01 --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True
--output_dir /cm/archive/anonymous/CUMO/checkpoints/cumo-phi3-mini-sft-test1 --num_train_epochs 1 --per_device_train_batch_size 5 --per_device_eval_batch_size 4 --gradient_accum
ulation_steps 2 --evaluation_strategy no --save_strategy steps --save_steps 500 --save_total_limit 1 --learning_rate 4e-6 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_
type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to none
[2024-10-07 01:05:58,490] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-07 01:05:59,289] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [5]}
[2024-10-07 01:05:59,289] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0
[2024-10-07 01:05:59,289] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2024-10-07 01:05:59,289] [INFO] [launch.py:163:main] dist_world_size=1
[2024-10-07 01:05:59,289] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=5
[2024-10-07 01:05:59,307] [INFO] [launch.py:253:main] process 2071468 spawned with command: ['/cm/archive/anonymous/miniconda3/envs/cumo/bin/python', '-u', 'cumo/train/train_mem
.py', '--local_rank=0', '--deepspeed', './scripts/zero3_offload.json', '--model_name_or_path', '/cm/archive/anonymous/checkpoints/phi3mini-clip/pft', '--version', 'phi3', '--dat
a_path', '/cm/archive/anonymous/data/jsons/llava_v1_5_mix665k_half.json', '--image_folder', '/cm/archive/anonymous/data', '--vision_tower', 'openai/clip-vit-large-patch14-336', '-
-vision_tower_dir', '/cm/archive/anonymous/checkpoints/phi3mini-clip/pft/clip.bin', '--scales', '1,3', '--pretrain_mm_mlp_adapter', '/cm/archive/anonymous/checkpoints/phi3mini-cli
p/pft/mm_projector.bin', '--mm_projector_type', 'smoe_mlp', '--mlp_smoe', 'smoe', '--clip_smoe', 'smoe', '--num_experts', '4', '--num_selected', '2', '--balance_loss_coef', '0
.1', '--router_z_loss_coef', '0.01', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--
group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', '/cm/archive/anonymous/CUMO/checkpoints/cumo-phi3-mini-sft-test1', '--num_train_epochs', '1', '--per_device_
train_batch_size', '5', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '2', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '
500', '--save_total_limit', '1', '--learning_rate', '4e-6', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32'
, 'True', '--model_max_length', '2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none']
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-
cli` if you want to set the git credential as well.
Token is valid (permission: read).
Your token has been saved to /home/anonymous/.cache/huggingface/token
Login successful
/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed
 in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
[2024-10-07 01:06:05,767] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-07 01:06:06,070] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-10-07 01:06:06,070] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
=========================================
=============CLIP-vision_tower=========
=========================================
/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed
in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2024-10-07 01:06:14,556] [INFO] [partition_parameters.py:343:__exit__] finished initializing model - num_params = 588, num_elems = 4.14B
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.40s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Model: phi3
=========================================
=============CLIP-vision_tower=========
=========================================
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using CLIP Encoder MoE Layer
Using MLP MoE
Loading weight MLP SMoE
Load weight vision tower /cm/archive/anonymous/checkpoints/phi3mini-clip/pft/clip.bin
Loading weight clip SMoE
Formatting inputs...Skip in lazy mode
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum vers
ion or higher.
Using /home/anonymous/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
^CTraceback (most recent call last):
  File "/cm/archive/anonymous/CUMO/cumo/train/train_mem.py", line 7, in <module>
[2024-10-07 01:08:43,286] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 2071468
    train(attn_implementation="flash_attention_2")
  File "/cm/archive/anonymous/CUMO/cumo/train/train.py", line 1309, in train
    trainer.train()
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/transformers/trainer.py", line 1885, in train
    return inner_training_loop(
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/transformers/trainer.py", line 2045, in _inner_training_loop
    model, self.optimizer, self.lr_scheduler = self.accelerator.prepare(
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/accelerate/accelerator.py", line 1291, in prepare
    result = self._prepare_deepspeed(*args)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/accelerate/accelerator.py", line 1758, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/__init__.py", line 176, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 307, in __init__
    self._configure_optimizer(optimizer, model_parameters)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1230, in _configure_optimizer
    basic_optimizer = self._configure_basic_optimizer(model_parameters)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1301, in _configure_basic_optimizer
    optimizer = DeepSpeedCPUAdam(model_parameters,
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/ops/adam/cpu_adam.py", line 94, in __init__
    self.ds_opt_adam = CPUAdamBuilder().load()
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/ops/op_builder/builder.py", line 479, in load
    return self.jit_load(verbose)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/ops/op_builder/builder.py", line 523, in jit_load
    op_module = load(name=self.name,
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/torch/utils/cpp_extension.py", line 1308, in load
    return _jit_compile(
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/torch/utils/cpp_extension.py", line 1724, in _jit_compile
    baton.wait()
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/torch/utils/file_baton.py", line 42, in wait
    time.sleep(self.wait_seconds)
KeyboardInterrupt
^CTraceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/subprocess.py", line 1189, in wait
[2024-10-07 01:08:43,520] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 2071468
    return self._wait(timeout=timeout)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/subprocess.py", line 1933, in _wait
    (pid, sts) = self._try_wait(0)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/subprocess.py", line 1891, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/cumo/bin/deepspeed", line 6, in <module>
    main()
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/launcher/runner.py", line 584, in main
    result.wait()
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/subprocess.py", line 1202, in wait
    self._wait(timeout=sigint_timeout)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/subprocess.py", line 1927, in _wait
    time.sleep(delay)
KeyboardInterrupt
^C[2024-10-07 01:08:43,696] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 2071468
^C[2024-10-07 01:08:43,857] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 2071468

(cumo) anonymous@ithndgx004:/cm/archive/anonymous/CUMO$ ^C
(cumo) anonymous@ithndgx004:/cm/archive/anonymous/CUMO$ [2024-10-07 01:08:45,411] [INFO] [launch.py:325:sigkill_handler] Main process received SIGINT, exiting
^C
(cumo) anonymous@ithndgx004:/cm/archive/anonymous/CUMO$ bash /cm/archive/anonymous/CUMO/scripts/cumo/phi3mini/clip/sft_phi3mini.sh
[2024-10-07 01:09:01,334] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-07 01:09:04,019] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-10-07 01:09:04,074] [INFO] [runner.py:568:main] cmd = /cm/archive/anonymous/miniconda3/envs/cumo/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOi
BbNV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None cumo/train/train_mem.py --deepspeed ./scripts/zero3_offload.json --model_name_or_path /cm/archiv
e/anonymous/checkpoints/phi3mini-clip/pft --version phi3 --data_path /cm/archive/anonymous/data/jsons/llava_v1_5_mix665k_half.json --image_folder /cm/archive/anonymous/data --vision
_tower openai/clip-vit-large-patch14-336 --vision_tower_dir /cm/archive/anonymous/checkpoints/phi3mini-clip/pft/clip.bin --scales 1,3 --pretrain_mm_mlp_adapter /cm/archive/namnv
78/checkpoints/phi3mini-clip/pft/mm_projector.bin --mm_projector_type smoe_mlp --mlp_smoe smoe --clip_smoe smoe --num_experts 4 --num_selected 2 --balance_loss_coef 0.1 --rout
er_z_loss_coef 0.01 --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True
--output_dir /cm/archive/anonymous/CUMO/checkpoints/cumo-phi3-mini-sft-test1 --num_train_epochs 1 --per_device_train_batch_size 5 --per_device_eval_batch_size 4 --gradient_accum
ulation_steps 2 --evaluation_strategy no --save_strategy steps --save_steps 500 --save_total_limit 1 --learning_rate 4e-6 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_
type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to none
[2024-10-07 01:09:07,247] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-07 01:09:08,054] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [5]}
[2024-10-07 01:09:08,055] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0
[2024-10-07 01:09:08,055] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2024-10-07 01:09:08,055] [INFO] [launch.py:163:main] dist_world_size=1
[2024-10-07 01:09:08,055] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=5
[2024-10-07 01:09:08,066] [INFO] [launch.py:253:main] process 2079351 spawned with command: ['/cm/archive/anonymous/miniconda3/envs/cumo/bin/python', '-u', 'cumo/train/train_mem
.py', '--local_rank=0', '--deepspeed', './scripts/zero3_offload.json', '--model_name_or_path', '/cm/archive/anonymous/checkpoints/phi3mini-clip/pft', '--version', 'phi3', '--dat
a_path', '/cm/archive/anonymous/data/jsons/llava_v1_5_mix665k_half.json', '--image_folder', '/cm/archive/anonymous/data', '--vision_tower', 'openai/clip-vit-large-patch14-336', '-
-vision_tower_dir', '/cm/archive/anonymous/checkpoints/phi3mini-clip/pft/clip.bin', '--scales', '1,3', '--pretrain_mm_mlp_adapter', '/cm/archive/anonymous/checkpoints/phi3mini-cli
p/pft/mm_projector.bin', '--mm_projector_type', 'smoe_mlp', '--mlp_smoe', 'smoe', '--clip_smoe', 'smoe', '--num_experts', '4', '--num_selected', '2', '--balance_loss_coef', '0
.1', '--router_z_loss_coef', '0.01', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--
group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', '/cm/archive/anonymous/CUMO/checkpoints/cumo-phi3-mini-sft-test1', '--num_train_epochs', '1', '--per_device_
train_batch_size', '5', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '2', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '
500', '--save_total_limit', '1', '--learning_rate', '4e-6', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32'
, 'True', '--model_max_length', '2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'none']
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-
cli` if you want to set the git credential as well.
Token is valid (permission: read).
Your token has been saved to /home/anonymous/.cache/huggingface/token
Login successful
/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed
 in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
[2024-10-07 01:09:15,371] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-07 01:09:15,655] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-10-07 01:09:15,655] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
=========================================
=============CLIP-vision_tower=========
=========================================
/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed
in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2024-10-07 01:09:23,115] [INFO] [partition_parameters.py:343:__exit__] finished initializing model - num_params = 588, num_elems = 4.14B
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.40s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Model: phi3
=========================================
=============CLIP-vision_tower=========
=========================================
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
Using MLP MoE
Loading weight MLP SMoE
Load weight vision tower /cm/archive/anonymous/checkpoints/phi3mini-clip/pft/clip.bin
Loading weight clip SMoE
Formatting inputs...Skip in lazy mode
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum vers
ion or higher.
Using /home/anonymous/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
^C[2024-10-07 01:10:38,590] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 2079351
Traceback (most recent call last):
  File "/cm/archive/anonymous/CUMO/cumo/train/train_mem.py", line 7, in <module>
    train(attn_implementation="flash_attention_2")
  File "/cm/archive/anonymous/CUMO/cumo/train/train.py", line 1309, in train
    trainer.train()
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/transformers/trainer.py", line 1885, in train
    return inner_training_loop(
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/transformers/trainer.py", line 2045, in _inner_training_loop
    model, self.optimizer, self.lr_scheduler = self.accelerator.prepare(
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/accelerate/accelerator.py", line 1291, in prepare
    result = self._prepare_deepspeed(*args)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/accelerate/accelerator.py", line 1758, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/__init__.py", line 176, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 307, in __init__
    self._configure_optimizer(optimizer, model_parameters)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1230, in _configure_optimizer
    basic_optimizer = self._configure_basic_optimizer(model_parameters)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1301, in _configure_basic_optimizer
    optimizer = DeepSpeedCPUAdam(model_parameters,
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/ops/adam/cpu_adam.py", line 94, in __init__
    self.ds_opt_adam = CPUAdamBuilder().load()
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/ops/op_builder/builder.py", line 479, in load
    return self.jit_load(verbose)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/ops/op_builder/builder.py", line 523, in jit_load
    op_module = load(name=self.name,
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/torch/utils/cpp_extension.py", line 1308, in load
    return _jit_compile(
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/torch/utils/cpp_extension.py", line 1724, in _jit_compile
    baton.wait()
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/torch/utils/file_baton.py", line 42, in wait
    time.sleep(self.wait_seconds)
KeyboardInterrupt
^CTraceback (most recent call last):
[2024-10-07 01:10:38,757] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 2079351
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/subprocess.py", line 1189, in wait
    return self._wait(timeout=timeout)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/subprocess.py", line 1933, in _wait
    (pid, sts) = self._try_wait(0)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/subprocess.py", line 1891, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/cumo/bin/deepspeed", line 6, in <module>
    main()
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/site-packages/deepspeed/launcher/runner.py", line 584, in main
    result.wait()
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/subprocess.py", line 1202, in wait
    self._wait(timeout=sigint_timeout)
  File "/cm/archive/anonymous/miniconda3/envs/cumo/lib/python3.9/subprocess.py", line 1927, in _wait
    time.sleep(delay)
KeyboardInterrupt

(cumo) anonymous@ithndgx004:/cm/archive/anonymous/CUMO$ [2024-10-07 01:10:40,861] [INFO] [launch.py:325:sigkill_handler] Main process received SIGINT, exiting
^C
(cumo) anonymous@ithndgx004:/cm/archive/anonymous/CUMO$ conda activate moe
(moe) anonymous@ithndgx004:/cm/archive/anonymous/CUMO$ cd /cm/archive/anonymous/toolkitmoe
(moe) anonymous@ithndgx004:/cm/archive/anonymous/toolkitmoe$ bash /cm/archive/anonymous/toolkitmoe/scripts/train/run_train_all.sh
Staring stage sft
/cm/archive/anonymous/phi3mini-clip/sft/ten_percent_smoe_perturbed
[2024-10-07 01:12:27,178] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-07 01:12:32,149] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-10-07 01:12:32,149] [INFO] [runner.py:568:main] cmd = /cm/archive/anonymous/miniconda3/envs/moe/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiB
bN119 --master_addr=127.0.0.1 --master_port=60001 --enable_each_rank_log=None moe_model/train/train_mem.py --deepspeed ./scripts/zero3_offload.json --model_name_or_path /cm/ar
chive/anonymous/checkpoints/phi3mini-clip/pft --version phi3 --data_path /cm/archive/anonymous/data/jsons/llava_v1_5_mix665k_half.json --image_folder /cm/archive/anonymous/data --vi
sion_tower openai/clip-vit-large-patch14-336 --vision_tower_dir /cm/archive/anonymous/checkpoints/phi3mini-clip/pft/clip.bin --scales 1,3 --pretrain_mm_mlp_adapter /cm/archive/n
amnv78/checkpoints/phi3mini-clip/pft/mm_projector.bin --mm_projector_type moe --mlp_smoe true --clip_smoe true --moe_name smoe_perturbed --num_experts 4 --num_selected 2 --bal
ance_loss_coef 0.1 --router_z_loss_coef 0.01 --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality
_length True --bf16 True --output_dir /cm/archive/anonymous/checkpoints/phi3mini-clip/sft/ten_percent_smoe_perturbed --num_train_epochs 1 --per_device_train_batch_size 5 --per_d
evice_eval_batch_size 4 --gradient_accumulation_steps 2 --evaluation_strategy no --save_strategy steps --save_steps 84 --save_total_limit 13 --learning_rate 4e-6 --weight_deca
y 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_prepr
ocess True --report_to none --max_steps 832 --topk_max 2 --topk_min 1
[2024-10-07 01:12:35,114] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-07 01:12:36,439] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [7]}
[2024-10-07 01:12:36,439] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0
[2024-10-07 01:12:36,439] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2024-10-07 01:12:36,439] [INFO] [launch.py:163:main] dist_world_size=1
[2024-10-07 01:12:36,440] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=7
[2024-10-07 01:12:36,455] [INFO] [launch.py:253:main] process 2086670 spawned with command: ['/cm/archive/anonymous/miniconda3/envs/moe/bin/python', '-u', 'moe_model/train/train
_mem.py', '--local_rank=0', '--deepspeed', './scripts/zero3_offload.json', '--model_name_or_path', '/cm/archive/anonymous/checkpoints/phi3mini-clip/pft', '--version', 'phi3', '-
-data_path', '/cm/archive/anonymous/data/jsons/llava_v1_5_mix665k_half.json', '--image_folder', '/cm/archive/anonymous/data', '--vision_tower', 'openai/clip-vit-large-patch14-336'
, '--vision_tower_dir', '/cm/archive/anonymous/checkpoints/phi3mini-clip/pft/clip.bin', '--scales', '1,3', '--pretrain_mm_mlp_adapter', '/cm/archive/anonymous/checkpoints/phi3mini
-clip/pft/mm_projector.bin', '--mm_projector_type', 'moe', '--mlp_smoe', 'true', '--clip_smoe', 'true', '--moe_name', 'smoe_perturbed', '--num_experts', '4', '--num_selected',
 '2', '--balance_loss_coef', '0.1', '--router_z_loss_coef', '0.01', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--
image_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', '/cm/archive/anonymous/checkpoints/phi3mini-clip/sft/ten_percent_smoe_perturb
ed', '--num_train_epochs', '1', '--per_device_train_batch_size', '5', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '2', '--evaluation_strategy', 'no',
 '--save_strategy', 'steps', '--save_steps', '84', '--save_total_limit', '13', '--learning_rate', '4e-6', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_typ
e', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess',
 'True', '--report_to', 'none', '--max_steps', '832', '--topk_max', '2', '--topk_min', '1']
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-
cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /home/anonymous/.cache/huggingface/token
Login successful
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed
in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
[2024-10-07 01:12:45,114] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-07 01:12:45,412] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-10-07 01:12:45,412] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
=========================================
=============CLIP-vision_tower=========
=========================================
[2024-10-07 01:12:52,757] [INFO] [partition_parameters.py:343:__exit__] finished initializing model - num_params = 588, num_elems = 4.14B
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.40s/it]
Model: phi3
=========================================
=============CLIP-vision_tower=========
=========================================
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
weight requires_grad: True
bias requires_grad: True
Loading weight MLP SMoE
Loading weight /cm/archive/anonymous/checkpoints/phi3mini-clip/pft/clip.bin SMoE
Formatting inputs...Skip in lazy mode
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum vers
ion or higher.
max_steps is given, it will override any value given in num_train_epochs
Using /home/anonymous/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
^C[2024-10-07 01:14:44,873] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 2086670
[rank0]: Traceback (most recent call last):
[rank0]:   File "/cm/archive/anonymous/toolkitmoe/moe_model/train/train_mem.py", line 11, in <module>
[rank0]:     train(attn_implementation="flash_attention_2")
[rank0]:   File "/cm/archive/anonymous/toolkitmoe/moe_model/train/train.py", line 1412, in train
[rank0]:     trainer.train()
[rank0]:   File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/transformers/trainer.py", line 1938, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/transformers/trainer.py", line 2098, in _inner_training_loop
[rank0]:     model, self.optimizer, self.lr_scheduler = self.accelerator.prepare(
[rank0]:   File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/accelerate/accelerator.py", line 1291, in prepare
[rank0]:     result = self._prepare_deepspeed(*args)
[rank0]:   File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/accelerate/accelerator.py", line 1758, in _prepare_deepspeed
[rank0]:     engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)
[rank0]:   File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/__init__.py", line 176, in initialize
[rank0]:     engine = DeepSpeedEngine(args=args,
[rank0]:   File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 307, in __init__
[rank0]:     self._configure_optimizer(optimizer, model_parameters)
[rank0]:   File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1230, in _configure_optimizer
[rank0]:     basic_optimizer = self._configure_basic_optimizer(model_parameters)
[rank0]:   File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1301, in _configure_basic_optimizer
[rank0]:     optimizer = DeepSpeedCPUAdam(model_parameters,
[rank0]:   File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/ops/adam/cpu_adam.py", line 94, in __init__
[rank0]:     self.ds_opt_adam = CPUAdamBuilder().load()
[rank0]:   File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/ops/op_builder/builder.py", line 479, in load
[rank0]:     return self.jit_load(verbose)
[rank0]:   File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/ops/op_builder/builder.py", line 523, in jit_load
[rank0]:     op_module = load(name=self.name,
[rank0]:   File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/utils/cpp_extension.py", line 1309, in load
[rank0]:     return _jit_compile(
[rank0]:   File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/utils/cpp_extension.py", line 1733, in _jit_compile
[rank0]:     baton.wait()
[rank0]:   File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/torch/utils/file_baton.py", line 42, in wait
[rank0]:     time.sleep(self.wait_seconds)
[rank0]: KeyboardInterrupt
^CTraceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/subprocess.py", line 1189, in wait
[2024-10-07 01:14:45,036] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 2086670
    return self._wait(timeout=timeout)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/subprocess.py", line 1933, in _wait
    (pid, sts) = self._try_wait(0)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/subprocess.py", line 1891, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/moe/bin/deepspeed", line 6, in <module>
    main()
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/launcher/runner.py", line 584, in main
    result.wait()
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/subprocess.py", line 1202, in wait
    self._wait(timeout=sigint_timeout)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/subprocess.py", line 1927, in _wait
    time.sleep(delay)
KeyboardInterrupt
^C[2024-10-07 01:14:45,208] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 2086670

(moe) anonymous@ithndgx004:/cm/archive/anonymous/toolkitmoe$ bash /cm/archive/anonymous/toolkitmoe/scripts/train/run_train_all.sh
Staring stage sft
/cm/archive/anonymous/phi3mini-clip/sft/ten_percent_smoe_perturbed
[2024-10-07 01:14:47,205] [INFO] [launch.py:325:sigkill_handler] Main process received SIGINT, exiting
[2024-10-07 01:14:49,332] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-07 01:14:52,086] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-10-07 01:14:52,086] [INFO] [runner.py:568:main] cmd = /cm/archive/anonymous/miniconda3/envs/moe/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiB
bN119 --master_addr=127.0.0.1 --master_port=60001 --enable_each_rank_log=None moe_model/train/train_mem.py --deepspeed ./scripts/zero3_offload.json --model_name_or_path /cm/ar
chive/anonymous/checkpoints/phi3mini-clip/pft --version phi3 --data_path /cm/archive/anonymous/data/jsons/llava_v1_5_mix665k_half.json --image_folder /cm/archive/anonymous/data --vi
sion_tower openai/clip-vit-large-patch14-336 --vision_tower_dir /cm/archive/anonymous/checkpoints/phi3mini-clip/pft/clip.bin --scales 1,3 --pretrain_mm_mlp_adapter /cm/archive/n
amnv78/checkpoints/phi3mini-clip/pft/mm_projector.bin --mm_projector_type moe --mlp_smoe true --clip_smoe true --moe_name smoe_perturbed --num_experts 4 --num_selected 2 --bal
ance_loss_coef 0.1 --router_z_loss_coef 0.01 --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality
_length True --bf16 True --output_dir /cm/archive/anonymous/checkpoints/phi3mini-clip/sft/ten_percent_smoe_perturbed --num_train_epochs 1 --per_device_train_batch_size 5 --per_d
evice_eval_batch_size 4 --gradient_accumulation_steps 2 --evaluation_strategy no --save_strategy steps --save_steps 84 --save_total_limit 13 --learning_rate 4e-6 --weight_deca
y 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_prepr
ocess True --report_to none --max_steps 832 --topk_max 2 --topk_min 1
[2024-10-07 01:14:54,558] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-07 01:14:55,712] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [7]}
[2024-10-07 01:14:55,712] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0
[2024-10-07 01:14:55,712] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2024-10-07 01:14:55,712] [INFO] [launch.py:163:main] dist_world_size=1
[2024-10-07 01:14:55,712] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=7
[2024-10-07 01:14:55,725] [INFO] [launch.py:253:main] process 2091514 spawned with command: ['/cm/archive/anonymous/miniconda3/envs/moe/bin/python', '-u', 'moe_model/train/train
_mem.py', '--local_rank=0', '--deepspeed', './scripts/zero3_offload.json', '--model_name_or_path', '/cm/archive/anonymous/checkpoints/phi3mini-clip/pft', '--version', 'phi3', '-
-data_path', '/cm/archive/anonymous/data/jsons/llava_v1_5_mix665k_half.json', '--image_folder', '/cm/archive/anonymous/data', '--vision_tower', 'openai/clip-vit-large-patch14-336'
, '--vision_tower_dir', '/cm/archive/anonymous/checkpoints/phi3mini-clip/pft/clip.bin', '--scales', '1,3', '--pretrain_mm_mlp_adapter', '/cm/archive/anonymous/checkpoints/phi3mini
-clip/pft/mm_projector.bin', '--mm_projector_type', 'moe', '--mlp_smoe', 'true', '--clip_smoe', 'true', '--moe_name', 'smoe_perturbed', '--num_experts', '4', '--num_selected',
 '2', '--balance_loss_coef', '0.1', '--router_z_loss_coef', '0.01', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--
image_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', '/cm/archive/anonymous/checkpoints/phi3mini-clip/sft/ten_percent_smoe_perturb
ed', '--num_train_epochs', '1', '--per_device_train_batch_size', '5', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '2', '--evaluation_strategy', 'no',
 '--save_strategy', 'steps', '--save_steps', '84', '--save_total_limit', '13', '--learning_rate', '4e-6', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_typ
e', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess',
 'True', '--report_to', 'none', '--max_steps', '832', '--topk_max', '2', '--topk_min', '1']
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-
cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /home/anonymous/.cache/huggingface/token
Login successful
/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed
in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
[2024-10-07 01:15:02,183] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-07 01:15:02,459] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-10-07 01:15:02,459] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
=========================================
=============CLIP-vision_tower=========
=========================================
[2024-10-07 01:15:09,672] [INFO] [partition_parameters.py:343:__exit__] finished initializing model - num_params = 588, num_elems = 4.14B
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.38s/it]
Model: phi3
=========================================
=============CLIP-vision_tower=========
=========================================
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
Using CLIP Encoder MoE Layer
weight requires_grad: True
bias requires_grad: True
weight requires_grad: True
bias requires_grad: True
Loading weight MLP SMoE
Loading weight /cm/archive/anonymous/checkpoints/phi3mini-clip/pft/clip.bin SMoE
Formatting inputs...Skip in lazy mode
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum vers
ion or higher.
max_steps is given, it will override any value given in num_train_epochs
Using /home/anonymous/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
^C[2024-10-07 09:35:03,321] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 2091514
^C[2024-10-07 09:35:03,517] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 2091514
Traceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/subprocess.py", line 1189, in wait
    return self._wait(timeout=timeout)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/subprocess.py", line 1933, in _wait
    (pid, sts) = self._try_wait(0)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/subprocess.py", line 1891, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/cm/archive/anonymous/miniconda3/envs/moe/bin/deepspeed", line 6, in <module>
    main()
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/site-packages/deepspeed/launcher/runner.py", line 584, in main
    result.wait()
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/subprocess.py", line 1202, in wait
    self._wait(timeout=sigint_timeout)
  File "/cm/archive/anonymous/miniconda3/envs/moe/lib/python3.9/subprocess.py", line 1927, in _wait
    time.sleep(delay)
KeyboardInterrupt
^C[2024-10-07 09:35:03,646] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 2091514

(moe) anonymous@ithndgx004:/cm/archive/anonymous/toolkitmoe$ ^C
(moe) anonymous@ithndgx004:/cm/archive/anonymous/toolkitmoe$ [2024-10-07 09:35:05,522] [INFO] [launch.py:325:sigkill_handler] Main process received SIGINT, exiting
^C
(moe) anonymous@ithndgx004:/cm/archive/anonymous/toolkitmoe$
